/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { BaseResource, CloudError } from "ms-rest-azure";
import * as moment from "moment";

export {

  BaseResource,
  CloudError
};

/**
 * Azure Data Factory top-level resource.
 */
export interface Resource extends BaseResource {
  /**
   * The resource identifier.
   */
  readonly id?: string;
  /**
   * The resource name.
   */
  readonly name?: string;
  /**
   * The resource type.
   */
  readonly type?: string;
  /**
   * The resource location.
   */
  location?: string;
  /**
   * The resource tags.
   */
  tags?: { [propertyName: string]: string };
  /**
   * Etag identifies change in the resource.
   */
  readonly eTag?: string;
}

/**
 * Azure Data Factory nested resource, which belongs to a factory.
 */
export interface SubResource extends BaseResource {
  /**
   * The resource identifier.
   */
  readonly id?: string;
  /**
   * The resource name.
   */
  readonly name?: string;
  /**
   * The resource type.
   */
  readonly type?: string;
  /**
   * Etag identifies change in the resource.
   */
  readonly etag?: string;
}

/**
 * Azure Data Factory expression definition.
 */
export interface Expression {
  /**
   * Expression value.
   */
  value: string;
}

/**
 * The base definition of a secret type.
 */
export interface SecretBase {
  /**
   * Polymorphic Discriminator
   */
  type: string;
}

/**
 * Azure Data Factory secure string definition. The string value will be masked with asterisks '*'
 * during Get or List API calls.
 */
export interface SecureString extends SecretBase {
  /**
   * Value of secure string.
   */
  value: string;
}

/**
 * Linked service reference type.
 */
export interface LinkedServiceReference {
  /**
   * Reference LinkedService name.
   */
  referenceName: string;
  /**
   * Arguments for LinkedService.
   */
  parameters?: { [propertyName: string]: any };
}

/**
 * Azure Key Vault secret reference.
 */
export interface AzureKeyVaultSecretReference extends SecretBase {
  /**
   * The Azure Key Vault linked service reference.
   */
  store: LinkedServiceReference;
  /**
   * The name of the secret in Azure Key Vault. Type: string (or Expression with resultType
   * string).
   */
  secretName: any;
  /**
   * The version of the secret in Azure Key Vault. The default value is the latest version of the
   * secret. Type: string (or Expression with resultType string).
   */
  secretVersion?: any;
}

/**
 * Identity properties of the factory resource.
 */
export interface FactoryIdentity {
  /**
   * The principal id of the identity.
   */
  readonly principalId?: string;
  /**
   * The client tenant id of the identity.
   */
  readonly tenantId?: string;
}

/**
 * Factory's git repo information.
 */
export interface FactoryRepoConfiguration {
  /**
   * Account name.
   */
  accountName: string;
  /**
   * Repository name.
   */
  repositoryName: string;
  /**
   * Collaboration branch.
   */
  collaborationBranch: string;
  /**
   * Root folder.
   */
  rootFolder: string;
  /**
   * Last commit id.
   */
  lastCommitId?: string;
  /**
   * Polymorphic Discriminator
   */
  type: string;
}

/**
 * Factory resource type.
 */
export interface Factory extends Resource {
  /**
   * Managed service identity of the factory.
   */
  identity?: FactoryIdentity;
  /**
   * Factory provisioning state, example Succeeded.
   */
  readonly provisioningState?: string;
  /**
   * Time the factory was created in ISO8601 format.
   */
  readonly createTime?: Date;
  /**
   * Version of the factory.
   */
  readonly version?: string;
  /**
   * Git repo information of the factory.
   */
  repoConfiguration?: FactoryRepoConfiguration;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Azure Data Factory nested object which serves as a compute resource for activities.
 */
export interface IntegrationRuntime {
  /**
   * Integration runtime description.
   */
  description?: string;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Integration runtime resource type.
 */
export interface IntegrationRuntimeResource extends SubResource {
  /**
   * Integration runtime properties.
   */
  properties: IntegrationRuntime;
}

/**
 * Integration runtime reference type.
 */
export interface IntegrationRuntimeReference {
  /**
   * Reference integration runtime name.
   */
  referenceName: string;
  /**
   * Arguments for integration runtime.
   */
  parameters?: { [propertyName: string]: any };
}

/**
 * Integration runtime status.
 */
export interface IntegrationRuntimeStatus {
  /**
   * The data factory name which the integration runtime belong to.
   */
  readonly dataFactoryName?: string;
  /**
   * The state of integration runtime. Possible values include: 'Initial', 'Stopped', 'Started',
   * 'Starting', 'Stopping', 'NeedRegistration', 'Online', 'Limited', 'Offline', 'AccessDenied'
   */
  readonly state?: string;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Integration runtime status response.
 */
export interface IntegrationRuntimeStatusResponse {
  /**
   * The integration runtime name.
   */
  readonly name?: string;
  /**
   * Integration runtime properties.
   */
  properties: IntegrationRuntimeStatus;
}

/**
 * A list of integration runtime status.
 */
export interface IntegrationRuntimeStatusListResponse {
  /**
   * List of integration runtime status.
   */
  value: IntegrationRuntimeStatusResponse[];
  /**
   * The link to the next page of results, if any remaining results exist.
   */
  nextLink?: string;
}

/**
 * Update integration runtime request.
 */
export interface UpdateIntegrationRuntimeRequest {
  /**
   * Enables or disables the auto-update feature of the self-hosted integration runtime. See
   * https://go.microsoft.com/fwlink/?linkid=854189. Possible values include: 'On', 'Off'
   */
  autoUpdate?: string;
  /**
   * The time offset (in hours) in the day, e.g., PT03H is 3 hours. The integration runtime auto
   * update will happen on that time.
   */
  updateDelayOffset?: string;
}

/**
 * Update integration runtime node request.
 */
export interface UpdateIntegrationRuntimeNodeRequest {
  /**
   * The number of concurrent jobs permitted to run on the integration runtime node. Values between
   * 1 and maxConcurrentJobs(inclusive) are allowed.
   */
  concurrentJobsLimit?: number;
}

/**
 * Data factory name for linked integration runtime request.
 */
export interface LinkedIntegrationRuntimeRequest {
  /**
   * The data factory name for linked integration runtime.
   */
  linkedFactoryName: string;
}

/**
 * The linked integration runtime information.
 */
export interface CreateLinkedIntegrationRuntimeRequest {
  /**
   * The name of the linked integration runtime.
   */
  name?: string;
  /**
   * The ID of the subscription that the linked integration runtime belongs to.
   */
  subscriptionId?: string;
  /**
   * The name of the data factory that the linked integration runtime belongs to.
   */
  dataFactoryName?: string;
  /**
   * The location of the data factory that the linked integration runtime belongs to.
   */
  dataFactoryLocation?: string;
}

/**
 * Definition of a single parameter for an entity.
 */
export interface ParameterSpecification {
  /**
   * Parameter type. Possible values include: 'Object', 'String', 'Int', 'Float', 'Bool', 'Array',
   * 'SecureString'
   */
  type: string;
  /**
   * Default value of parameter.
   */
  defaultValue?: any;
}

/**
 * The Azure Data Factory nested object which contains the information and credential which can be
 * used to connect with related store or compute resource.
 */
export interface LinkedService {
  /**
   * The integration runtime reference.
   */
  connectVia?: IntegrationRuntimeReference;
  /**
   * Linked service description.
   */
  description?: string;
  /**
   * Parameters for linked service.
   */
  parameters?: { [propertyName: string]: ParameterSpecification };
  /**
   * List of tags that can be used for describing the Dataset.
   */
  annotations?: any[];
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Linked service resource type.
 */
export interface LinkedServiceResource extends SubResource {
  /**
   * Properties of linked service.
   */
  properties: LinkedService;
}

/**
 * The folder that this Dataset is in. If not specified, Dataset will appear at the root level.
 */
export interface DatasetFolder {
  /**
   * The name of the folder that this Dataset is in.
   */
  name?: string;
}

/**
 * The Azure Data Factory nested object which identifies data within different data stores, such as
 * tables, files, folders, and documents.
 */
export interface Dataset {
  /**
   * Dataset description.
   */
  description?: string;
  /**
   * Columns that define the structure of the dataset. Type: array (or Expression with resultType
   * array), itemType: DatasetDataElement.
   */
  structure?: any;
  /**
   * Linked service reference.
   */
  linkedServiceName: LinkedServiceReference;
  /**
   * Parameters for dataset.
   */
  parameters?: { [propertyName: string]: ParameterSpecification };
  /**
   * List of tags that can be used for describing the Dataset.
   */
  annotations?: any[];
  /**
   * The folder that this Dataset is in. If not specified, Dataset will appear at the root level.
   */
  folder?: DatasetFolder;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Dataset resource type.
 */
export interface DatasetResource extends SubResource {
  /**
   * Dataset properties.
   */
  properties: Dataset;
}

/**
 * Activity dependency information.
 */
export interface ActivityDependency {
  /**
   * Activity name.
   */
  activity: string;
  /**
   * Match-Condition for the dependency.
   */
  dependencyConditions: string[];
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * User property.
 */
export interface UserProperty {
  /**
   * User property name.
   */
  name: string;
  /**
   * User property value. Type: string (or Expression with resultType string).
   */
  value: any;
}

/**
 * A pipeline activity.
 */
export interface Activity {
  /**
   * Activity name.
   */
  name: string;
  /**
   * Activity description.
   */
  description?: string;
  /**
   * Activity depends on condition.
   */
  dependsOn?: ActivityDependency[];
  /**
   * Activity user properties.
   */
  userProperties?: UserProperty[];
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Definition of a single variable for a Pipeline.
 */
export interface VariableSpecification {
  /**
   * Variable type. Possible values include: 'String', 'Bool', 'Array'
   */
  type: string;
  /**
   * Default value of variable.
   */
  defaultValue?: any;
}

/**
 * The folder that this Pipeline is in. If not specified, Pipeline will appear at the root level.
 */
export interface PipelineFolder {
  /**
   * The name of the folder that this Pipeline is in.
   */
  name?: string;
}

/**
 * Pipeline resource type.
 */
export interface PipelineResource extends SubResource {
  /**
   * The description of the pipeline.
   */
  description?: string;
  /**
   * List of activities in pipeline.
   */
  activities?: Activity[];
  /**
   * List of parameters for pipeline.
   */
  parameters?: { [propertyName: string]: ParameterSpecification };
  /**
   * List of variables for pipeline.
   */
  variables?: { [propertyName: string]: VariableSpecification };
  /**
   * The max number of concurrent runs for the pipeline.
   */
  concurrency?: number;
  /**
   * List of tags that can be used for describing the Pipeline.
   */
  annotations?: any[];
  /**
   * The folder that this Pipeline is in. If not specified, Pipeline will appear at the root level.
   */
  folder?: PipelineFolder;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Azure data factory nested object which contains information about creating pipeline run
 */
export interface Trigger {
  /**
   * Trigger description.
   */
  description?: string;
  /**
   * Indicates if trigger is running or not. Updated when Start/Stop APIs are called on the
   * Trigger. Possible values include: 'Started', 'Stopped', 'Disabled'
   */
  readonly runtimeState?: string;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Trigger resource type.
 */
export interface TriggerResource extends SubResource {
  /**
   * Properties of the trigger.
   */
  properties: Trigger;
}

/**
 * Response body with a run identifier.
 */
export interface CreateRunResponse {
  /**
   * Identifier of a run.
   */
  runId: string;
}

/**
 * Factory's VSTS repo information.
 */
export interface FactoryVSTSConfiguration extends FactoryRepoConfiguration {
  /**
   * VSTS project name.
   */
  projectName: string;
  /**
   * VSTS tenant id.
   */
  tenantId?: string;
}

/**
 * Factory's GitHub repo information.
 */
export interface FactoryGitHubConfiguration extends FactoryRepoConfiguration {
  /**
   * GitHub Enterprise host name. For example: https://github.mydomain.com
   */
  hostName?: string;
}

/**
 * Factory's git repo information.
 */
export interface FactoryRepoUpdate {
  /**
   * The factory resource id.
   */
  factoryResourceId?: string;
  /**
   * Git repo information of the factory.
   */
  repoConfiguration?: FactoryRepoConfiguration;
}

/**
 * Get GitHub access token request definition.
 */
export interface GitHubAccessTokenRequest {
  /**
   * GitHub access code.
   */
  gitHubAccessCode: string;
  /**
   * GitHub application client ID.
   */
  gitHubClientId?: string;
  /**
   * GitHub access token base URL.
   */
  gitHubAccessTokenBaseUrl: string;
}

/**
 * Get GitHub access token response definition.
 */
export interface GitHubAccessTokenResponse {
  /**
   * GitHub access token.
   */
  gitHubAccessToken?: string;
}

/**
 * Get Data Plane read only token request definition.
 */
export interface UserAccessPolicy {
  /**
   * The string with permissions for Data Plane access. Currently only 'r' is supported which
   * grants read only access.
   */
  permissions?: string;
  /**
   * The resource path to get access relative to factory. Currently only empty string is supported
   * which corresponds to the factory resource.
   */
  accessResourcePath?: string;
  /**
   * The name of the profile. Currently only the default is supported. The default value is
   * DefaultProfile.
   */
  profileName?: string;
  /**
   * Start time for the token. If not specified the current time will be used.
   */
  startTime?: string;
  /**
   * Expiration time for the token. Maximum duration for the token is eight hours and by default
   * the token will expire in eight hours.
   */
  expireTime?: string;
}

/**
 * Get Data Plane read only token response definition.
 */
export interface AccessPolicyResponse {
  /**
   * The user access policy.
   */
  policy?: UserAccessPolicy;
  /**
   * Data Plane read only access token.
   */
  accessToken?: string;
  /**
   * Data Plane service base URL.
   */
  dataPlaneUrl?: string;
}

/**
 * Pipeline reference type.
 */
export interface PipelineReference {
  /**
   * Reference pipeline name.
   */
  referenceName: string;
  /**
   * Reference name.
   */
  name?: string;
}

/**
 * Pipeline that needs to be triggered with the given parameters.
 */
export interface TriggerPipelineReference {
  /**
   * Pipeline reference.
   */
  pipelineReference?: PipelineReference;
  /**
   * Pipeline parameters.
   */
  parameters?: { [propertyName: string]: any };
}

/**
 * Parameters for updating a factory resource.
 */
export interface FactoryUpdateParameters {
  /**
   * The resource tags.
   */
  tags?: { [propertyName: string]: string };
  /**
   * Managed service identity of the factory.
   */
  identity?: FactoryIdentity;
}

/**
 * Dataset reference type.
 */
export interface DatasetReference {
  /**
   * Reference dataset name.
   */
  referenceName: string;
  /**
   * Arguments for dataset.
   */
  parameters?: { [propertyName: string]: any };
}

/**
 * Query filter option for listing runs.
 */
export interface RunQueryFilter {
  /**
   * Parameter name to be used for filter. The allowed operands to query pipeline runs are
   * PipelineName, RunStart, RunEnd and Status; to query activity runs are ActivityName,
   * ActivityRunStart, ActivityRunEnd, ActivityType and Status, and to query trigger runs are
   * TriggerName, TriggerRunTimestamp and Status. Possible values include: 'PipelineName',
   * 'Status', 'RunStart', 'RunEnd', 'ActivityName', 'ActivityRunStart', 'ActivityRunEnd',
   * 'ActivityType', 'TriggerName', 'TriggerRunTimestamp'
   */
  operand: string;
  /**
   * Operator to be used for filter. Possible values include: 'Equals', 'NotEquals', 'In', 'NotIn'
   */
  operator: string;
  /**
   * List of filter values.
   */
  values: string[];
}

/**
 * An object to provide order by options for listing runs.
 */
export interface RunQueryOrderBy {
  /**
   * Parameter name to be used for order by. The allowed parameters to order by for pipeline runs
   * are PipelineName, RunStart, RunEnd and Status; for activity runs are ActivityName,
   * ActivityRunStart, ActivityRunEnd and Status; for trigger runs are TriggerName,
   * TriggerRunTimestamp and Status. Possible values include: 'RunStart', 'RunEnd', 'PipelineName',
   * 'Status', 'ActivityName', 'ActivityRunStart', 'ActivityRunEnd', 'TriggerName',
   * 'TriggerRunTimestamp'
   */
  orderBy: string;
  /**
   * Sorting order of the parameter. Possible values include: 'ASC', 'DESC'
   */
  order: string;
}

/**
 * Query parameters for listing runs.
 */
export interface RunFilterParameters {
  /**
   * The continuation token for getting the next page of results. Null for first page.
   */
  continuationToken?: string;
  /**
   * The time at or after which the run event was updated in 'ISO 8601' format.
   */
  lastUpdatedAfter: Date;
  /**
   * The time at or before which the run event was updated in 'ISO 8601' format.
   */
  lastUpdatedBefore: Date;
  /**
   * List of filters.
   */
  filters?: RunQueryFilter[];
  /**
   * List of OrderBy option.
   */
  orderBy?: RunQueryOrderBy[];
}

/**
 * Provides entity name and id that started the pipeline run.
 */
export interface PipelineRunInvokedBy {
  /**
   * Name of the entity that started the pipeline run.
   */
  readonly name?: string;
  /**
   * The ID of the entity that started the run.
   */
  readonly id?: string;
  /**
   * The type of the entity that started the run.
   */
  readonly invokedByType?: string;
}

/**
 * Information about a pipeline run.
 */
export interface PipelineRun {
  /**
   * Identifier of a run.
   */
  readonly runId?: string;
  /**
   * The pipeline name.
   */
  readonly pipelineName?: string;
  /**
   * The full or partial list of parameter name, value pair used in the pipeline run.
   */
  readonly parameters?: { [propertyName: string]: string };
  /**
   * Entity that started the pipeline run.
   */
  readonly invokedBy?: PipelineRunInvokedBy;
  /**
   * The last updated timestamp for the pipeline run event in ISO8601 format.
   */
  readonly lastUpdated?: Date;
  /**
   * The start time of a pipeline run in ISO8601 format.
   */
  readonly runStart?: Date;
  /**
   * The end time of a pipeline run in ISO8601 format.
   */
  readonly runEnd?: Date;
  /**
   * The duration of a pipeline run.
   */
  readonly durationInMs?: number;
  /**
   * The status of a pipeline run.
   */
  readonly status?: string;
  /**
   * The message from a pipeline run.
   */
  readonly message?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A list pipeline runs.
 */
export interface PipelineRunsQueryResponse {
  /**
   * List of pipeline runs.
   */
  value: PipelineRun[];
  /**
   * The continuation token for getting the next page of results, if any remaining results exist,
   * null otherwise.
   */
  continuationToken?: string;
}

/**
 * Information about an activity run in a pipeline.
 */
export interface ActivityRun {
  /**
   * The name of the pipeline.
   */
  readonly pipelineName?: string;
  /**
   * The id of the pipeline run.
   */
  readonly pipelineRunId?: string;
  /**
   * The name of the activity.
   */
  readonly activityName?: string;
  /**
   * The type of the activity.
   */
  readonly activityType?: string;
  /**
   * The id of the activity run.
   */
  readonly activityRunId?: string;
  /**
   * The name of the compute linked service.
   */
  readonly linkedServiceName?: string;
  /**
   * The status of the activity run.
   */
  readonly status?: string;
  /**
   * The start time of the activity run in 'ISO 8601' format.
   */
  readonly activityRunStart?: Date;
  /**
   * The end time of the activity run in 'ISO 8601' format.
   */
  readonly activityRunEnd?: Date;
  /**
   * The duration of the activity run.
   */
  readonly durationInMs?: number;
  /**
   * The input for the activity.
   */
  readonly input?: any;
  /**
   * The output for the activity.
   */
  readonly output?: any;
  /**
   * The error if any from the activity run.
   */
  readonly error?: any;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A list activity runs.
 */
export interface ActivityRunsQueryResponse {
  /**
   * List of activity runs.
   */
  value: ActivityRun[];
  /**
   * The continuation token for getting the next page of results, if any remaining results exist,
   * null otherwise.
   */
  continuationToken?: string;
}

/**
 * Trigger runs.
 */
export interface TriggerRun {
  /**
   * Trigger run id.
   */
  readonly triggerRunId?: string;
  /**
   * Trigger name.
   */
  readonly triggerName?: string;
  /**
   * Trigger type.
   */
  readonly triggerType?: string;
  /**
   * Trigger run start time.
   */
  readonly triggerRunTimestamp?: Date;
  /**
   * Trigger run status. Possible values include: 'Succeeded', 'Failed', 'Inprogress'
   */
  readonly status?: string;
  /**
   * Trigger error message.
   */
  readonly message?: string;
  /**
   * List of property name and value related to trigger run. Name, value pair depends on type of
   * trigger.
   */
  readonly properties?: { [propertyName: string]: string };
  /**
   * List of pipeline name and run Id triggered by the trigger run.
   */
  readonly triggeredPipelines?: { [propertyName: string]: string };
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A list of trigger runs.
 */
export interface TriggerRunsQueryResponse {
  /**
   * List of trigger runs.
   */
  value: TriggerRun[];
  /**
   * The continuation token for getting the next page of results, if any remaining results exist,
   * null otherwise.
   */
  continuationToken?: string;
}

/**
 * Rerun tumbling window trigger Parameters.
 */
export interface RerunTumblingWindowTriggerActionParameters {
  /**
   * The start time for the time period for which restatement is initiated. Only UTC time is
   * currently supported.
   */
  startTime: Date;
  /**
   * The end time for the time period for which restatement is initiated. Only UTC time is
   * currently supported.
   */
  endTime: Date;
  /**
   * The max number of parallel time windows (ready for execution) for which a rerun is triggered.
   */
  maxConcurrency: number;
}

/**
 * Trigger that schedules pipeline reruns for all fixed time interval windows from a requested
 * start time to requested end time.
 */
export interface RerunTumblingWindowTrigger extends Trigger {
  /**
   * The parent trigger reference.
   */
  parentTrigger?: any;
  /**
   * The start time for the time period for which restatement is initiated. Only UTC time is
   * currently supported.
   */
  requestedStartTime: Date;
  /**
   * The end time for the time period for which restatement is initiated. Only UTC time is
   * currently supported.
   */
  requestedEndTime: Date;
  /**
   * The max number of parallel time windows (ready for execution) for which a rerun is triggered.
   */
  maxConcurrency: number;
}

/**
 * RerunTrigger resource type.
 */
export interface RerunTriggerResource extends SubResource {
  /**
   * Properties of the rerun trigger.
   */
  properties: RerunTumblingWindowTrigger;
}

/**
 * Metadata associated with the operation.
 */
export interface OperationDisplay {
  /**
   * The description of the operation.
   */
  description?: string;
  /**
   * The name of the provider.
   */
  provider?: string;
  /**
   * The name of the resource type on which the operation is performed.
   */
  resource?: string;
  /**
   * The type of operation: get, read, delete, etc.
   */
  operation?: string;
}

/**
 * Details about an operation related to logs.
 */
export interface OperationLogSpecification {
  /**
   * The name of the log category.
   */
  name?: string;
  /**
   * Localized display name.
   */
  displayName?: string;
  /**
   * Blobs created in the customer storage account, per hour.
   */
  blobDuration?: string;
}

/**
 * Defines how often data for a metric becomes available.
 */
export interface OperationMetricAvailability {
  /**
   * The granularity for the metric.
   */
  timeGrain?: string;
  /**
   * Blob created in the customer storage account, per hour.
   */
  blobDuration?: string;
}

/**
 * Defines the metric dimension.
 */
export interface OperationMetricDimension {
  /**
   * The name of the dimension for the metric.
   */
  name?: string;
  /**
   * The display name of the metric dimension.
   */
  displayName?: string;
  /**
   * Whether the dimension should be exported to Azure Monitor.
   */
  toBeExportedForShoebox?: boolean;
}

/**
 * Details about an operation related to metrics.
 */
export interface OperationMetricSpecification {
  /**
   * The name of the metric.
   */
  name?: string;
  /**
   * Localized display name of the metric.
   */
  displayName?: string;
  /**
   * The description of the metric.
   */
  displayDescription?: string;
  /**
   * The unit that the metric is measured in.
   */
  unit?: string;
  /**
   * The type of metric aggregation.
   */
  aggregationType?: string;
  /**
   * Whether or not the service is using regional MDM accounts.
   */
  enableRegionalMdmAccount?: string;
  /**
   * The name of the MDM account.
   */
  sourceMdmAccount?: string;
  /**
   * The name of the MDM namespace.
   */
  sourceMdmNamespace?: string;
  /**
   * Defines how often data for metrics becomes available.
   */
  availabilities?: OperationMetricAvailability[];
  /**
   * Defines the metric dimension.
   */
  dimensions?: OperationMetricDimension[];
}

/**
 * Details about a service operation.
 */
export interface OperationServiceSpecification {
  /**
   * Details about operations related to logs.
   */
  logSpecifications?: OperationLogSpecification[];
  /**
   * Details about operations related to metrics.
   */
  metricSpecifications?: OperationMetricSpecification[];
}

/**
 * Azure Data Factory API operation definition.
 */
export interface Operation {
  /**
   * Operation name: {provider}/{resource}/{operation}
   */
  name?: string;
  /**
   * The intended executor of the operation.
   */
  origin?: string;
  /**
   * Metadata associated with the operation.
   */
  display?: OperationDisplay;
  /**
   * Details about a service operation.
   */
  serviceSpecification?: OperationServiceSpecification;
}

/**
 * The request payload of get SSIS object metadata.
 */
export interface GetSsisObjectMetadataRequest {
  /**
   * Metadata path.
   */
  metadataPath?: string;
}

/**
 * The status of the operation.
 */
export interface SsisObjectMetadataStatusResponse {
  /**
   * The status of the operation.
   */
  status?: string;
  /**
   * The operation name.
   */
  name?: string;
  /**
   * The operation properties.
   */
  properties?: string;
  /**
   * The operation error message.
   */
  error?: string;
}

/**
 * Referenced dependency.
 */
export interface DependencyReference {
  /**
   * Polymorphic Discriminator
   */
  type: string;
}

/**
 * Self referenced tumbling window trigger dependency.
 */
export interface SelfDependencyTumblingWindowTriggerReference extends DependencyReference {
  /**
   * Timespan applied to the start time of a tumbling window when evaluating dependency.
   */
  offset: string;
  /**
   * The size of the window when evaluating the dependency. If undefined the frequency of the
   * tumbling window will be used.
   */
  size?: string;
}

/**
 * Trigger reference type.
 */
export interface TriggerReference {
  /**
   * Reference trigger name.
   */
  referenceName: string;
}

/**
 * Trigger referenced dependency.
 */
export interface TriggerDependencyReference extends DependencyReference {
  /**
   * Referenced trigger.
   */
  referenceTrigger: TriggerReference;
}

/**
 * Referenced tumbling window trigger dependency.
 */
export interface TumblingWindowTriggerDependencyReference extends TriggerDependencyReference {
  /**
   * Timespan applied to the start time of a tumbling window when evaluating dependency.
   */
  offset?: string;
  /**
   * The size of the window when evaluating the dependency. If undefined the frequency of the
   * tumbling window will be used.
   */
  size?: string;
}

/**
 * Execution policy for an activity.
 */
export interface RetryPolicy {
  /**
   * Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with resultType
   * integer), minimum: 0.
   */
  count?: any;
  /**
   * Interval between retries in seconds. Default is 30.
   */
  intervalInSeconds?: number;
}

/**
 * Trigger that schedules pipeline runs for all fixed time interval windows from a start time
 * without gaps and also supports backfill scenarios (when start time is in the past).
 */
export interface TumblingWindowTrigger extends Trigger {
  /**
   * Pipeline for which runs are created when an event is fired for trigger window that is ready.
   */
  pipelineProperty: TriggerPipelineReference;
  /**
   * The frequency of the time windows. Possible values include: 'Minute', 'Hour'
   */
  frequency: string;
  /**
   * The interval of the time windows. The minimum interval allowed is 15 Minutes.
   */
  interval: number;
  /**
   * The start time for the time period for the trigger during which events are fired for windows
   * that are ready. Only UTC time is currently supported.
   */
  startTime: Date;
  /**
   * The end time for the time period for the trigger during which events are fired for windows
   * that are ready. Only UTC time is currently supported.
   */
  endTime?: Date;
  /**
   * Specifies how long the trigger waits past due time before triggering new run. It doesn't alter
   * window start and end time. The default is 0. Type: string (or Expression with resultType
   * string), pattern: ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  delay?: any;
  /**
   * The max number of parallel time windows (ready for execution) for which a new run is
   * triggered.
   */
  maxConcurrency: number;
  /**
   * Retry policy that will be applied for failed pipeline runs.
   */
  retryPolicy?: RetryPolicy;
  /**
   * Triggers that this trigger depends on. Only tumbling window triggers are supported.
   */
  dependsOn?: DependencyReference[];
}

/**
 * Base class for all triggers that support one to many model for trigger to pipeline.
 */
export interface MultiplePipelineTrigger extends Trigger {
  /**
   * Pipelines that need to be started.
   */
  pipelines?: TriggerPipelineReference[];
}

/**
 * Trigger that runs every time a Blob event occurs.
 */
export interface BlobEventsTrigger extends MultiplePipelineTrigger {
  /**
   * The blob path must begin with the pattern provided for trigger to fire. For example,
   * '/records/blobs/december/' will only fire the trigger for blobs in the december folder under
   * the records container. At least one of these must be provided: blobPathBeginsWith,
   * blobPathEndsWith.
   */
  blobPathBeginsWith?: string;
  /**
   * The blob path must end with the pattern provided for trigger to fire. For example,
   * 'december/boxes.csv' will only fire the trigger for blobs named boxes in a december folder. At
   * least one of these must be provided: blobPathBeginsWith, blobPathEndsWith.
   */
  blobPathEndsWith?: string;
  /**
   * The type of events that cause this trigger to fire.
   */
  events: string[];
  /**
   * The ARM resource ID of the Storage Account.
   */
  scope: string;
}

/**
 * Trigger that runs every time the selected Blob container changes.
 */
export interface BlobTrigger extends MultiplePipelineTrigger {
  /**
   * The path of the container/folder that will trigger the pipeline.
   */
  folderPath: string;
  /**
   * The max number of parallel files to handle when it is triggered.
   */
  maxConcurrency: number;
  /**
   * The Azure Storage linked service reference.
   */
  linkedService: LinkedServiceReference;
}

/**
 * The recurrence schedule occurrence.
 */
export interface RecurrenceScheduleOccurrence {
  /**
   * The day of the week. Possible values include: 'Sunday', 'Monday', 'Tuesday', 'Wednesday',
   * 'Thursday', 'Friday', 'Saturday'
   */
  day?: string;
  /**
   * The occurrence.
   */
  occurrence?: number;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * The recurrence schedule.
 */
export interface RecurrenceSchedule {
  /**
   * The minutes.
   */
  minutes?: number[];
  /**
   * The hours.
   */
  hours?: number[];
  /**
   * The days of the week.
   */
  weekDays?: string[];
  /**
   * The month days.
   */
  monthDays?: number[];
  /**
   * The monthly occurrences.
   */
  monthlyOccurrences?: RecurrenceScheduleOccurrence[];
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * The workflow trigger recurrence.
 */
export interface ScheduleTriggerRecurrence {
  /**
   * The frequency. Possible values include: 'NotSpecified', 'Minute', 'Hour', 'Day', 'Week',
   * 'Month', 'Year'
   */
  frequency?: string;
  /**
   * The interval.
   */
  interval?: number;
  /**
   * The start time.
   */
  startTime?: Date;
  /**
   * The end time.
   */
  endTime?: Date;
  /**
   * The time zone.
   */
  timeZone?: string;
  /**
   * The recurrence schedule.
   */
  schedule?: RecurrenceSchedule;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Trigger that creates pipeline runs periodically, on schedule.
 */
export interface ScheduleTrigger extends MultiplePipelineTrigger {
  /**
   * Recurrence schedule configuration.
   */
  recurrence: ScheduleTriggerRecurrence;
}

/**
 * Responsys linked service.
 */
export interface ResponsysLinkedService extends LinkedService {
  /**
   * The endpoint of the Responsys server.
   */
  endpoint: any;
  /**
   * The client ID associated with the Responsys application. Type: string (or Expression with
   * resultType string).
   */
  clientId: any;
  /**
   * The client secret associated with the Responsys application. Type: string (or Expression with
   * resultType string).
   */
  clientSecret?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true. Type: boolean (or Expression with resultType boolean).
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true. Type: boolean (or
   * Expression with resultType boolean).
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true. Type: boolean (or Expression with resultType boolean).
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure Databricks linked service.
 */
export interface AzureDatabricksLinkedService extends LinkedService {
  /**
   * <REGION>.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or
   * Expression with resultType string).
   */
  domain: any;
  /**
   * Access token for databricks REST API. Refer to
   * https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression
   * with resultType string).
   */
  accessToken: SecretBase;
  /**
   * The id of an existing cluster that will be used for all runs of this job. Type: string (or
   * Expression with resultType string).
   */
  existingClusterId?: any;
  /**
   * The Spark version of new cluster. Type: string (or Expression with resultType string).
   */
  newClusterVersion?: any;
  /**
   * Number of worker nodes that new cluster should have. A string formatted Int32, like '1' means
   * numOfWorker is 1 or '1:10' means auto-scale from 1 as min and 10 as max. Type: string (or
   * Expression with resultType string).
   */
  newClusterNumOfWorker?: any;
  /**
   * The node types of new cluster. Type: string (or Expression with resultType string).
   */
  newClusterNodeType?: any;
  /**
   * A set of optional, user-specified Spark configuration key-value pairs.
   */
  newClusterSparkConf?: { [propertyName: string]: any };
  /**
   * A set of optional, user-specified Spark environment variables key-value pairs.
   */
  newClusterSparkEnvVars?: { [propertyName: string]: any };
  /**
   * Additional tags for cluster resources.
   */
  newClusterCustomTags?: { [propertyName: string]: any };
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure Data Lake Analytics linked service.
 */
export interface AzureDataLakeAnalyticsLinkedService extends LinkedService {
  /**
   * The Azure Data Lake Analytics account name. Type: string (or Expression with resultType
   * string).
   */
  accountName: any;
  /**
   * The ID of the application used to authenticate against the Azure Data Lake Analytics account.
   * Type: string (or Expression with resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The Key of the application used to authenticate against the Azure Data Lake Analytics account.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant: any;
  /**
   * Data Lake Analytics account subscription ID (if different from Data Factory account). Type:
   * string (or Expression with resultType string).
   */
  subscriptionId?: any;
  /**
   * Data Lake Analytics account resource group name (if different from Data Factory account).
   * Type: string (or Expression with resultType string).
   */
  resourceGroupName?: any;
  /**
   * Azure Data Lake Analytics URI Type: string (or Expression with resultType string).
   */
  dataLakeAnalyticsUri?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Custom script action to run on HDI ondemand cluster once it's up.
 */
export interface ScriptAction {
  /**
   * The user provided name of the script action.
   */
  name: string;
  /**
   * The URI for the script action.
   */
  uri: string;
  /**
   * The node types on which the script action should be executed.
   */
  roles: any;
  /**
   * The parameters for the script action.
   */
  parameters?: string;
}

/**
 * HDInsight ondemand linked service.
 */
export interface HDInsightOnDemandLinkedService extends LinkedService {
  /**
   * Number of worker/data nodes in the cluster. Suggestion value: 4. Type: string (or Expression
   * with resultType string).
   */
  clusterSize: any;
  /**
   * The allowed idle time for the on-demand HDInsight cluster. Specifies how long the on-demand
   * HDInsight cluster stays alive after completion of an activity run if there are no other active
   * jobs in the cluster. The minimum value is 5 mins. Type: string (or Expression with resultType
   * string).
   */
  timeToLive: any;
  /**
   * Version of the HDInsight cluster.  Type: string (or Expression with resultType string).
   */
  version: any;
  /**
   * Azure Storage linked service to be used by the on-demand cluster for storing and processing
   * data.
   */
  linkedServiceName: LinkedServiceReference;
  /**
   * The customer’s subscription to host the cluster. Type: string (or Expression with resultType
   * string).
   */
  hostSubscriptionId: any;
  /**
   * The service principal id for the hostSubscriptionId. Type: string (or Expression with
   * resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The key for the service principal id.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The Tenant id/name to which the service principal belongs. Type: string (or Expression with
   * resultType string).
   */
  tenant: any;
  /**
   * The resource group where the cluster belongs. Type: string (or Expression with resultType
   * string).
   */
  clusterResourceGroup: any;
  /**
   * The prefix of cluster name, postfix will be distinct with timestamp. Type: string (or
   * Expression with resultType string).
   */
  clusterNamePrefix?: any;
  /**
   * The username to access the cluster. Type: string (or Expression with resultType string).
   */
  clusterUserName?: any;
  /**
   * The password to access the cluster.
   */
  clusterPassword?: SecretBase;
  /**
   * The username to SSH remotely connect to cluster’s node (for Linux). Type: string (or
   * Expression with resultType string).
   */
  clusterSshUserName?: any;
  /**
   * The password to SSH remotely connect cluster’s node (for Linux).
   */
  clusterSshPassword?: SecretBase;
  /**
   * Specifies additional storage accounts for the HDInsight linked service so that the Data
   * Factory service can register them on your behalf.
   */
  additionalLinkedServiceNames?: LinkedServiceReference[];
  /**
   * The name of Azure SQL linked service that point to the HCatalog database. The on-demand
   * HDInsight cluster is created by using the Azure SQL database as the metastore.
   */
  hcatalogLinkedServiceName?: LinkedServiceReference;
  /**
   * The cluster type. Type: string (or Expression with resultType string).
   */
  clusterType?: any;
  /**
   * The version of spark if the cluster type is 'spark'. Type: string (or Expression with
   * resultType string).
   */
  sparkVersion?: any;
  /**
   * Specifies the core configuration parameters (as in core-site.xml) for the HDInsight cluster to
   * be created.
   */
  coreConfiguration?: any;
  /**
   * Specifies the HBase configuration parameters (hbase-site.xml) for the HDInsight cluster.
   */
  hBaseConfiguration?: any;
  /**
   * Specifies the HDFS configuration parameters (hdfs-site.xml) for the HDInsight cluster.
   */
  hdfsConfiguration?: any;
  /**
   * Specifies the hive configuration parameters (hive-site.xml) for the HDInsight cluster.
   */
  hiveConfiguration?: any;
  /**
   * Specifies the MapReduce configuration parameters (mapred-site.xml) for the HDInsight cluster.
   */
  mapReduceConfiguration?: any;
  /**
   * Specifies the Oozie configuration parameters (oozie-site.xml) for the HDInsight cluster.
   */
  oozieConfiguration?: any;
  /**
   * Specifies the Storm configuration parameters (storm-site.xml) for the HDInsight cluster.
   */
  stormConfiguration?: any;
  /**
   * Specifies the Yarn configuration parameters (yarn-site.xml) for the HDInsight cluster.
   */
  yarnConfiguration?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * Specifies the size of the head node for the HDInsight cluster.
   */
  headNodeSize?: any;
  /**
   * Specifies the size of the data node for the HDInsight cluster.
   */
  dataNodeSize?: any;
  /**
   * Specifies the size of the Zoo Keeper node for the HDInsight cluster.
   */
  zookeeperNodeSize?: any;
  /**
   * Custom script actions to run on HDI ondemand cluster once it's up. Please refer to
   * https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-cluster-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fr-server%2FTOC.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json#understanding-script-actions.
   */
  scriptActions?: ScriptAction[];
}

/**
 * Salesforce Marketing Cloud linked service.
 */
export interface SalesforceMarketingCloudLinkedService extends LinkedService {
  /**
   * The client ID associated with the Salesforce Marketing Cloud application. Type: string (or
   * Expression with resultType string).
   */
  clientId: any;
  /**
   * The client secret associated with the Salesforce Marketing Cloud application. Type: string (or
   * Expression with resultType string).
   */
  clientSecret?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true. Type: boolean (or Expression with resultType boolean).
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true. Type: boolean (or
   * Expression with resultType boolean).
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true. Type: boolean (or Expression with resultType boolean).
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Netezza linked service.
 */
export interface NetezzaLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  pwd?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Vertica linked service.
 */
export interface VerticaLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  pwd?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Zoho server linked service.
 */
export interface ZohoLinkedService extends LinkedService {
  /**
   * The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private)
   */
  endpoint: any;
  /**
   * The access token for Zoho authentication.
   */
  accessToken?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Xero Service linked service.
 */
export interface XeroLinkedService extends LinkedService {
  /**
   * The endpoint of the Xero server. (i.e. api.xero.com)
   */
  host: any;
  /**
   * The consumer key associated with the Xero application.
   */
  consumerKey?: SecretBase;
  /**
   * The private key from the .pem file that was generated for your Xero private application. You
   * must include all the text from the .pem file, including the Unix line endings(
   * ).
   */
  privateKey?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Square Service linked service.
 */
export interface SquareLinkedService extends LinkedService {
  /**
   * The URL of the Square instance. (i.e. mystore.mysquare.com)
   */
  host: any;
  /**
   * The client ID associated with your Square application.
   */
  clientId: any;
  /**
   * The client secret associated with your Square application.
   */
  clientSecret?: SecretBase;
  /**
   * The redirect URL assigned in the Square application dashboard. (i.e. http://localhost:2500)
   */
  redirectUri: any;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Spark Server linked service.
 */
export interface SparkLinkedService extends LinkedService {
  /**
   * IP address or host name of the Spark server
   */
  host: any;
  /**
   * The TCP port that the Spark server uses to listen for client connections.
   */
  port: any;
  /**
   * The type of Spark server. Possible values include: 'SharkServer', 'SharkServer2',
   * 'SparkThriftServer'
   */
  serverType?: string;
  /**
   * The transport protocol to use in the Thrift layer. Possible values include: 'Binary', 'SASL',
   * 'HTTP '
   */
  thriftTransportProtocol?: string;
  /**
   * The authentication method used to access the Spark server. Possible values include:
   * 'Anonymous', 'Username', 'UsernameAndPassword', 'WindowsAzureHDInsightService'
   */
  authenticationType: string;
  /**
   * The user name that you use to access Spark Server.
   */
  username?: any;
  /**
   * The password corresponding to the user name that you provided in the Username field
   */
  password?: SecretBase;
  /**
   * The partial URL corresponding to the Spark server.
   */
  httpPath?: any;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Shopify Service linked service.
 */
export interface ShopifyLinkedService extends LinkedService {
  /**
   * The endpoint of the Shopify server. (i.e. mystore.myshopify.com)
   */
  host: any;
  /**
   * The API access token that can be used to access Shopify’s data. The token won't expire if it
   * is offline mode.
   */
  accessToken?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * ServiceNow server linked service.
 */
export interface ServiceNowLinkedService extends LinkedService {
  /**
   * The endpoint of the ServiceNow server. (i.e. <instance>.service-now.com)
   */
  endpoint: any;
  /**
   * The authentication type to use. Possible values include: 'Basic', 'OAuth2'
   */
  authenticationType: string;
  /**
   * The user name used to connect to the ServiceNow server for Basic and OAuth2 authentication.
   */
  username?: any;
  /**
   * The password corresponding to the user name for Basic and OAuth2 authentication.
   */
  password?: SecretBase;
  /**
   * The client id for OAuth2 authentication.
   */
  clientId?: any;
  /**
   * The client secret for OAuth2 authentication.
   */
  clientSecret?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * QuickBooks server linked service.
 */
export interface QuickBooksLinkedService extends LinkedService {
  /**
   * The endpoint of the QuickBooks server. (i.e. quickbooks.api.intuit.com)
   */
  endpoint: any;
  /**
   * The company ID of the QuickBooks company to authorize.
   */
  companyId: any;
  /**
   * The consumer key for OAuth 1.0 authentication.
   */
  consumerKey: any;
  /**
   * The consumer secret for OAuth 1.0 authentication.
   */
  consumerSecret: SecretBase;
  /**
   * The access token for OAuth 1.0 authentication.
   */
  accessToken: SecretBase;
  /**
   * The access token secret for OAuth 1.0 authentication.
   */
  accessTokenSecret: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Presto server linked service.
 */
export interface PrestoLinkedService extends LinkedService {
  /**
   * The IP address or host name of the Presto server. (i.e. 192.168.222.160)
   */
  host: any;
  /**
   * The version of the Presto server. (i.e. 0.148-t)
   */
  serverVersion: any;
  /**
   * The catalog context for all request against the server.
   */
  catalog: any;
  /**
   * The TCP port that the Presto server uses to listen for client connections. The default value
   * is 8080.
   */
  port?: any;
  /**
   * The authentication mechanism used to connect to the Presto server. Possible values include:
   * 'Anonymous', 'LDAP'
   */
  authenticationType: string;
  /**
   * The user name used to connect to the Presto server.
   */
  username?: any;
  /**
   * The password corresponding to the user name.
   */
  password?: SecretBase;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The local time zone used by the connection. Valid values for this option are specified in the
   * IANA Time Zone Database. The default value is the system time zone.
   */
  timeZoneID?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Phoenix server linked service.
 */
export interface PhoenixLinkedService extends LinkedService {
  /**
   * The IP address or host name of the Phoenix server. (i.e. 192.168.222.160)
   */
  host: any;
  /**
   * The TCP port that the Phoenix server uses to listen for client connections. The default value
   * is 8765.
   */
  port?: any;
  /**
   * The partial URL corresponding to the Phoenix server. (i.e. /gateway/sandbox/phoenix/version).
   * The default value is hbasephoenix if using WindowsAzureHDInsightService.
   */
  httpPath?: any;
  /**
   * The authentication mechanism used to connect to the Phoenix server. Possible values include:
   * 'Anonymous', 'UsernameAndPassword', 'WindowsAzureHDInsightService'
   */
  authenticationType: string;
  /**
   * The user name used to connect to the Phoenix server.
   */
  username?: any;
  /**
   * The password corresponding to the user name.
   */
  password?: SecretBase;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Paypal Service linked service.
 */
export interface PaypalLinkedService extends LinkedService {
  /**
   * The URL of the PayPal instance. (i.e. api.sandbox.paypal.com)
   */
  host: any;
  /**
   * The client ID associated with your PayPal application.
   */
  clientId: any;
  /**
   * The client secret associated with your PayPal application.
   */
  clientSecret?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Marketo server linked service.
 */
export interface MarketoLinkedService extends LinkedService {
  /**
   * The endpoint of the Marketo server. (i.e. 123-ABC-321.mktorest.com)
   */
  endpoint: any;
  /**
   * The client Id of your Marketo service.
   */
  clientId: any;
  /**
   * The client secret of your Marketo service.
   */
  clientSecret?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * MariaDB server linked service.
 */
export interface MariaDBLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  pwd?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Magento server linked service.
 */
export interface MagentoLinkedService extends LinkedService {
  /**
   * The URL of the Magento instance. (i.e. 192.168.222.110/magento3)
   */
  host: any;
  /**
   * The access token from Magento.
   */
  accessToken?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Jira Service linked service.
 */
export interface JiraLinkedService extends LinkedService {
  /**
   * The IP address or host name of the Jira service. (e.g. jira.example.com)
   */
  host: any;
  /**
   * The TCP port that the Jira server uses to listen for client connections. The default value is
   * 443 if connecting through HTTPS, or 8080 if connecting through HTTP.
   */
  port?: any;
  /**
   * The user name that you use to access Jira Service.
   */
  username: any;
  /**
   * The password corresponding to the user name that you provided in the username field.
   */
  password?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Impala server linked service.
 */
export interface ImpalaLinkedService extends LinkedService {
  /**
   * The IP address or host name of the Impala server. (i.e. 192.168.222.160)
   */
  host: any;
  /**
   * The TCP port that the Impala server uses to listen for client connections. The default value
   * is 21050.
   */
  port?: any;
  /**
   * The authentication type to use. Possible values include: 'Anonymous', 'SASLUsername',
   * 'UsernameAndPassword'
   */
  authenticationType: string;
  /**
   * The user name used to access the Impala server. The default value is anonymous when using
   * SASLUsername.
   */
  username?: any;
  /**
   * The password corresponding to the user name when using UsernameAndPassword.
   */
  password?: SecretBase;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Hubspot Service linked service.
 */
export interface HubspotLinkedService extends LinkedService {
  /**
   * The client ID associated with your Hubspot application.
   */
  clientId: any;
  /**
   * The client secret associated with your Hubspot application.
   */
  clientSecret?: SecretBase;
  /**
   * The access token obtained when initially authenticating your OAuth integration.
   */
  accessToken?: SecretBase;
  /**
   * The refresh token obtained when initially authenticating your OAuth integration.
   */
  refreshToken?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Hive Server linked service.
 */
export interface HiveLinkedService extends LinkedService {
  /**
   * IP address or host name of the Hive server, separated by ';' for multiple hosts (only when
   * serviceDiscoveryMode is enable).
   */
  host: any;
  /**
   * The TCP port that the Hive server uses to listen for client connections.
   */
  port?: any;
  /**
   * The type of Hive server. Possible values include: 'HiveServer1', 'HiveServer2',
   * 'HiveThriftServer'
   */
  serverType?: string;
  /**
   * The transport protocol to use in the Thrift layer. Possible values include: 'Binary', 'SASL',
   * 'HTTP '
   */
  thriftTransportProtocol?: string;
  /**
   * The authentication method used to access the Hive server. Possible values include:
   * 'Anonymous', 'Username', 'UsernameAndPassword', 'WindowsAzureHDInsightService'
   */
  authenticationType: string;
  /**
   * true to indicate using the ZooKeeper service, false not.
   */
  serviceDiscoveryMode?: any;
  /**
   * The namespace on ZooKeeper under which Hive Server 2 nodes are added.
   */
  zooKeeperNameSpace?: any;
  /**
   * Specifies whether the driver uses native HiveQL queries,or converts them into an equivalent
   * form in HiveQL.
   */
  useNativeQuery?: any;
  /**
   * The user name that you use to access Hive Server.
   */
  username?: any;
  /**
   * The password corresponding to the user name that you provided in the Username field
   */
  password?: SecretBase;
  /**
   * The partial URL corresponding to the Hive server.
   */
  httpPath?: any;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * HBase server linked service.
 */
export interface HBaseLinkedService extends LinkedService {
  /**
   * The IP address or host name of the HBase server. (i.e. 192.168.222.160)
   */
  host: any;
  /**
   * The TCP port that the HBase instance uses to listen for client connections. The default value
   * is 9090.
   */
  port?: any;
  /**
   * The partial URL corresponding to the HBase server. (i.e. /gateway/sandbox/hbase/version)
   */
  httpPath?: any;
  /**
   * The authentication mechanism to use to connect to the HBase server. Possible values include:
   * 'Anonymous', 'Basic'
   */
  authenticationType: string;
  /**
   * The user name used to connect to the HBase instance.
   */
  username?: any;
  /**
   * The password corresponding to the user name.
   */
  password?: SecretBase;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false.
   */
  enableSsl?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to require a CA-issued SSL certificate name to match the host name of the
   * server when connecting over SSL. The default value is false.
   */
  allowHostNameCNMismatch?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false.
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Greenplum Database linked service.
 */
export interface GreenplumLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  pwd?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Google BigQuery service linked service.
 */
export interface GoogleBigQueryLinkedService extends LinkedService {
  /**
   * The default BigQuery project to query against.
   */
  project: any;
  /**
   * A comma-separated list of public BigQuery projects to access.
   */
  additionalProjects?: any;
  /**
   * Whether to request access to Google Drive. Allowing Google Drive access enables support for
   * federated tables that combine BigQuery data with data from Google Drive. The default value is
   * false.
   */
  requestGoogleDriveScope?: any;
  /**
   * The OAuth 2.0 authentication mechanism used for authentication. ServiceAuthentication can only
   * be used on self-hosted IR. Possible values include: 'ServiceAuthentication',
   * 'UserAuthentication'
   */
  authenticationType: string;
  /**
   * The refresh token obtained from Google for authorizing access to BigQuery for
   * UserAuthentication.
   */
  refreshToken?: SecretBase;
  /**
   * The client id of the google application used to acquire the refresh token.
   */
  clientId?: SecretBase;
  /**
   * The client secret of the google application used to acquire the refresh token.
   */
  clientSecret?: SecretBase;
  /**
   * The service account email ID that is used for ServiceAuthentication and can only be used on
   * self-hosted IR.
   */
  email?: any;
  /**
   * The full path to the .p12 key file that is used to authenticate the service account email
   * address and can only be used on self-hosted IR.
   */
  keyFilePath?: any;
  /**
   * The full path of the .pem file containing trusted CA certificates for verifying the server
   * when connecting over SSL. This property can only be set when using SSL on self-hosted IR. The
   * default value is the cacerts.pem file installed with the IR.
   */
  trustedCertPath?: any;
  /**
   * Specifies whether to use a CA certificate from the system trust store or from a specified PEM
   * file. The default value is false.
   */
  useSystemTrustStore?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Eloqua server linked service.
 */
export interface EloquaLinkedService extends LinkedService {
  /**
   * The endpoint of the Eloqua server. (i.e. eloqua.example.com)
   */
  endpoint: any;
  /**
   * The site name and user name of your Eloqua account in the form: sitename/username. (i.e.
   * Eloqua/Alice)
   */
  username: any;
  /**
   * The password corresponding to the user name.
   */
  password?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Drill server linked service.
 */
export interface DrillLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  pwd?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Couchbase server linked service.
 */
export interface CouchbaseLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of credString in connection string.
   */
  credString?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Concur Service linked service.
 */
export interface ConcurLinkedService extends LinkedService {
  /**
   * Application client_id supplied by Concur App Management.
   */
  clientId: any;
  /**
   * The user name that you use to access Concur Service.
   */
  username: any;
  /**
   * The password corresponding to the user name that you provided in the username field.
   */
  password?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure PostgreSQL linked service.
 */
export interface AzurePostgreSqlLinkedService extends LinkedService {
  /**
   * An ODBC connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Amazon Marketplace Web Service linked service.
 */
export interface AmazonMWSLinkedService extends LinkedService {
  /**
   * The endpoint of the Amazon MWS server, (i.e. mws.amazonservices.com)
   */
  endpoint: any;
  /**
   * The Amazon Marketplace ID you want to retrieve data from. To retrieve data from multiple
   * Marketplace IDs, separate them with a comma (,). (i.e. A2EUQ1WTGCTBG2)
   */
  marketplaceID: any;
  /**
   * The Amazon seller ID.
   */
  sellerID: any;
  /**
   * The Amazon MWS authentication token.
   */
  mwsAuthToken?: SecretBase;
  /**
   * The access key id used to access data.
   */
  accessKeyId: any;
  /**
   * The secret key used to access data.
   */
  secretKey?: SecretBase;
  /**
   * Specifies whether the data source endpoints are encrypted using HTTPS. The default value is
   * true.
   */
  useEncryptedEndpoints?: any;
  /**
   * Specifies whether to require the host name in the server's certificate to match the host name
   * of the server when connecting over SSL. The default value is true.
   */
  useHostVerification?: any;
  /**
   * Specifies whether to verify the identity of the server when connecting over SSL. The default
   * value is true.
   */
  usePeerVerification?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * SAP HANA Linked Service.
 */
export interface SapHanaLinkedService extends LinkedService {
  /**
   * Host name of the SAP HANA server. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * The authentication type to be used to connect to the SAP HANA server. Possible values include:
   * 'Basic', 'Windows'
   */
  authenticationType?: string;
  /**
   * Username to access the SAP HANA server. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password to access the SAP HANA server.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * SAP Business Warehouse Linked Service.
 */
export interface SapBWLinkedService extends LinkedService {
  /**
   * Host name of the SAP BW instance. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * System number of the BW system. (Usually a two-digit decimal number represented as a string.)
   * Type: string (or Expression with resultType string).
   */
  systemNumber: any;
  /**
   * Client ID of the client on the BW system. (Usually a three-digit decimal number represented as
   * a string) Type: string (or Expression with resultType string).
   */
  clientId: any;
  /**
   * Username to access the SAP BW server. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password to access the SAP BW server.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * A linked service for an SSH File Transfer Protocol (SFTP) server.
 */
export interface SftpServerLinkedService extends LinkedService {
  /**
   * The SFTP server host name. Type: string (or Expression with resultType string).
   */
  host: any;
  /**
   * The TCP port number that the SFTP server uses to listen for client connections. Default value
   * is 22. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  port?: any;
  /**
   * The authentication type to be used to connect to the FTP server. Possible values include:
   * 'Basic', 'SshPublicKey'
   */
  authenticationType?: string;
  /**
   * The username used to log on to the SFTP server. Type: string (or Expression with resultType
   * string).
   */
  userName?: any;
  /**
   * Password to logon the SFTP server for Basic authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * The SSH private key file path for SshPublicKey authentication. Only valid for on-premises
   * copy. For on-premises copy with SshPublicKey authentication, either PrivateKeyPath or
   * PrivateKeyContent should be specified. SSH private key should be OpenSSH format. Type: string
   * (or Expression with resultType string).
   */
  privateKeyPath?: any;
  /**
   * Base64 encoded SSH private key content for SshPublicKey authentication. For on-premises copy
   * with SshPublicKey authentication, either PrivateKeyPath or PrivateKeyContent should be
   * specified. SSH private key should be OpenSSH format.
   */
  privateKeyContent?: SecretBase;
  /**
   * The password to decrypt the SSH private key if the SSH private key is encrypted.
   */
  passPhrase?: SecretBase;
  /**
   * If true, skip the SSH host key validation. Default value is false. Type: boolean (or
   * Expression with resultType boolean).
   */
  skipHostKeyValidation?: any;
  /**
   * The host key finger-print of the SFTP server. When SkipHostKeyValidation is false,
   * HostKeyFingerprint should be specified. Type: string (or Expression with resultType string).
   */
  hostKeyFingerprint?: any;
}

/**
 * A FTP server Linked Service.
 */
export interface FtpServerLinkedService extends LinkedService {
  /**
   * Host name of the FTP server. Type: string (or Expression with resultType string).
   */
  host: any;
  /**
   * The TCP port number that the FTP server uses to listen for client connections. Default value
   * is 21. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  port?: any;
  /**
   * The authentication type to be used to connect to the FTP server. Possible values include:
   * 'Basic', 'Anonymous'
   */
  authenticationType?: string;
  /**
   * Username to logon the FTP server. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password to logon the FTP server.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * If true, connect to the FTP server over SSL/TLS channel. Default value is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  enableSsl?: any;
  /**
   * If true, validate the FTP server SSL certificate when connect over SSL/TLS channel. Default
   * value is true. Type: boolean (or Expression with resultType boolean).
   */
  enableServerCertificateValidation?: any;
}

/**
 * Linked service for an HTTP source.
 */
export interface HttpLinkedService extends LinkedService {
  /**
   * The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type: string (or Expression
   * with resultType string).
   */
  url: any;
  /**
   * The authentication type to be used to connect to the HTTP server. Possible values include:
   * 'Basic', 'Anonymous', 'Digest', 'Windows', 'ClientCertificate'
   */
  authenticationType?: string;
  /**
   * User name for Basic, Digest, or Windows authentication. Type: string (or Expression with
   * resultType string).
   */
  userName?: any;
  /**
   * Password for Basic, Digest, Windows, or ClientCertificate with EmbeddedCertData
   * authentication.
   */
  password?: SecretBase;
  /**
   * Base64 encoded certificate data for ClientCertificate authentication. For on-premises copy
   * with ClientCertificate authentication, either CertThumbprint or EmbeddedCertData/Password
   * should be specified. Type: string (or Expression with resultType string).
   */
  embeddedCertData?: any;
  /**
   * Thumbprint of certificate for ClientCertificate authentication. Only valid for on-premises
   * copy. For on-premises copy with ClientCertificate authentication, either CertThumbprint or
   * EmbeddedCertData/Password should be specified. Type: string (or Expression with resultType
   * string).
   */
  certThumbprint?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * If true, validate the HTTPS server SSL certificate. Default value is true. Type: boolean (or
   * Expression with resultType boolean).
   */
  enableServerCertificateValidation?: any;
}

/**
 * Linked service for Windows Azure Search Service.
 */
export interface AzureSearchLinkedService extends LinkedService {
  /**
   * URL for Azure Search service. Type: string (or Expression with resultType string).
   */
  url: any;
  /**
   * Admin Key for Azure Search service
   */
  key?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Custom linked service.
 */
export interface CustomDataSourceLinkedService extends LinkedService {
  /**
   * Custom linked service properties.
   */
  typeProperties: any;
}

/**
 * Linked service for Amazon Redshift.
 */
export interface AmazonRedshiftLinkedService extends LinkedService {
  /**
   * The name of the Amazon Redshift server. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * The username of the Amazon Redshift source. Type: string (or Expression with resultType
   * string).
   */
  username?: any;
  /**
   * The password of the Amazon Redshift source.
   */
  password?: SecretBase;
  /**
   * The database name of the Amazon Redshift source. Type: string (or Expression with resultType
   * string).
   */
  database: any;
  /**
   * The TCP port number that the Amazon Redshift server uses to listen for client connections. The
   * default value is 5439. Type: integer (or Expression with resultType integer).
   */
  port?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for Amazon S3.
 */
export interface AmazonS3LinkedService extends LinkedService {
  /**
   * The access key identifier of the Amazon S3 Identity and Access Management (IAM) user. Type:
   * string (or Expression with resultType string).
   */
  accessKeyId?: any;
  /**
   * The secret access key of the Amazon S3 Identity and Access Management (IAM) user.
   */
  secretAccessKey?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for SAP ERP Central Component(SAP ECC).
 */
export interface SapEccLinkedService extends LinkedService {
  /**
   * The URL of SAP ECC OData API. For example,
   * '[https://hostname:port/sap/opu/odata/sap/servicename/]'. Type: string (or Expression with
   * resultType string).
   */
  url: string;
  /**
   * The username for Basic authentication. Type: string (or Expression with resultType string).
   */
  username?: string;
  /**
   * The password for Basic authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Either encryptedCredential or username/password must
   * be provided. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: string;
}

/**
 * Linked service for SAP Cloud for Customer.
 */
export interface SapCloudForCustomerLinkedService extends LinkedService {
  /**
   * The URL of SAP Cloud for Customer OData API. For example,
   * '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with
   * resultType string).
   */
  url: any;
  /**
   * The username for Basic authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * The password for Basic authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Either encryptedCredential or username/password must
   * be provided. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for Salesforce.
 */
export interface SalesforceLinkedService extends LinkedService {
  /**
   * The URL of Salesforce instance. Default is 'https://login.salesforce.com'. To copy data from
   * sandbox, specify 'https://test.salesforce.com'. To copy data from custom domain, specify, for
   * example, 'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType
   * string).
   */
  environmentUrl?: any;
  /**
   * The username for Basic authentication of the Salesforce instance. Type: string (or Expression
   * with resultType string).
   */
  username?: any;
  /**
   * The password for Basic authentication of the Salesforce instance.
   */
  password?: SecretBase;
  /**
   * The security token is required to remotely access Salesforce instance.
   */
  securityToken?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure Data Lake Store linked service.
 */
export interface AzureDataLakeStoreLinkedService extends LinkedService {
  /**
   * Data Lake Store service URI. Type: string (or Expression with resultType string).
   */
  dataLakeStoreUri: any;
  /**
   * The ID of the application used to authenticate against the Azure Data Lake Store account.
   * Type: string (or Expression with resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The Key of the application used to authenticate against the Azure Data Lake Store account.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant?: any;
  /**
   * Data Lake Store account name. Type: string (or Expression with resultType string).
   */
  accountName?: any;
  /**
   * Data Lake Store account subscription ID (if different from Data Factory account). Type: string
   * (or Expression with resultType string).
   */
  subscriptionId?: any;
  /**
   * Data Lake Store account resource group name (if different from Data Factory account). Type:
   * string (or Expression with resultType string).
   */
  resourceGroupName?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for MongoDb data source.
 */
export interface MongoDbLinkedService extends LinkedService {
  /**
   * The IP address or server name of the MongoDB server. Type: string (or Expression with
   * resultType string).
   */
  server: any;
  /**
   * The authentication type to be used to connect to the MongoDB database. Possible values
   * include: 'Basic', 'Anonymous'
   */
  authenticationType?: string;
  /**
   * The name of the MongoDB database that you want to access. Type: string (or Expression with
   * resultType string).
   */
  databaseName: any;
  /**
   * Username for authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * Password for authentication.
   */
  password?: SecretBase;
  /**
   * Database to verify the username and password. Type: string (or Expression with resultType
   * string).
   */
  authSource?: any;
  /**
   * The TCP port number that the MongoDB server uses to listen for client connections. The default
   * value is 27017. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  port?: any;
  /**
   * Specifies whether the connections to the server are encrypted using SSL. The default value is
   * false. Type: boolean (or Expression with resultType boolean).
   */
  enableSsl?: any;
  /**
   * Specifies whether to allow self-signed certificates from the server. The default value is
   * false. Type: boolean (or Expression with resultType boolean).
   */
  allowSelfSignedServerCert?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for Cassandra data source.
 */
export interface CassandraLinkedService extends LinkedService {
  /**
   * Host name for connection. Type: string (or Expression with resultType string).
   */
  host: any;
  /**
   * AuthenticationType to be used for connection. Type: string (or Expression with resultType
   * string).
   */
  authenticationType?: any;
  /**
   * The port for the connection. Type: integer (or Expression with resultType integer).
   */
  port?: any;
  /**
   * Username for authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * Password for authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Base definition of WebLinkedServiceTypeProperties, this typeProperties is polymorphic based on
 * authenticationType, so not flattened in SDK models.
 */
export interface WebLinkedServiceTypeProperties {
  /**
   * The URL of the web service endpoint, e.g. http://www.microsoft.com . Type: string (or
   * Expression with resultType string).
   */
  url: any;
  /**
   * Polymorphic Discriminator
   */
  authenticationType: string;
}

/**
 * A WebLinkedService that uses client certificate based authentication to communicate with an HTTP
 * endpoint. This scheme follows mutual authentication; the server must also provide valid
 * credentials to the client.
 */
export interface WebClientCertificateAuthentication extends WebLinkedServiceTypeProperties {
  /**
   * Base64-encoded contents of a PFX file.
   */
  pfx: SecretBase;
  /**
   * Password for the PFX file.
   */
  password: SecretBase;
}

/**
 * A WebLinkedService that uses basic authentication to communicate with an HTTP endpoint.
 */
export interface WebBasicAuthentication extends WebLinkedServiceTypeProperties {
  /**
   * User name for Basic authentication. Type: string (or Expression with resultType string).
   */
  username: any;
  /**
   * The password for Basic authentication.
   */
  password: SecretBase;
}

/**
 * A WebLinkedService that uses anonymous authentication to communicate with an HTTP endpoint.
 */
export interface WebAnonymousAuthentication extends WebLinkedServiceTypeProperties {
}

/**
 * Web linked service.
 */
export interface WebLinkedService extends LinkedService {
  /**
   * Web linked service properties.
   */
  typeProperties: WebLinkedServiceTypeProperties;
}

/**
 * Open Data Protocol (OData) linked service.
 */
export interface ODataLinkedService extends LinkedService {
  /**
   * The URL of the OData service endpoint. Type: string (or Expression with resultType string).
   */
  url: any;
  /**
   * Type of authentication used to connect to the OData service. Possible values include: 'Basic',
   * 'Anonymous'
   */
  authenticationType?: string;
  /**
   * User name of the OData service. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password of the OData service.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Hadoop Distributed File System (HDFS) linked service.
 */
export interface HdfsLinkedService extends LinkedService {
  /**
   * The URL of the HDFS service endpoint, e.g. http://myhostname:50070/webhdfs/v1 . Type: string
   * (or Expression with resultType string).
   */
  url: any;
  /**
   * Type of authentication used to connect to the HDFS. Possible values are: Anonymous and
   * Windows. Type: string (or Expression with resultType string).
   */
  authenticationType?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * User name for Windows authentication. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password for Windows authentication.
   */
  password?: SecretBase;
}

/**
 * Open Database Connectivity (ODBC) linked service.
 */
export interface OdbcLinkedService extends LinkedService {
  /**
   * The non-access credential portion of the connection string as well as an optional encrypted
   * credential. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * Type of authentication used to connect to the ODBC data store. Possible values are: Anonymous
   * and Basic. Type: string (or Expression with resultType string).
   */
  authenticationType?: any;
  /**
   * The access credential portion of the connection string specified in driver-specific
   * property-value format.
   */
  credential?: SecretBase;
  /**
   * User name for Basic authentication. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * Password for Basic authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure ML Web Service linked service.
 */
export interface AzureMLLinkedService extends LinkedService {
  /**
   * The Batch Execution REST URL for an Azure ML Web Service endpoint. Type: string (or Expression
   * with resultType string).
   */
  mlEndpoint: any;
  /**
   * The API key for accessing the Azure ML model endpoint.
   */
  apiKey: SecretBase;
  /**
   * The Update Resource REST URL for an Azure ML Web Service endpoint. Type: string (or Expression
   * with resultType string).
   */
  updateResourceEndpoint?: any;
  /**
   * The ID of the service principal used to authenticate against the ARM-based
   * updateResourceEndpoint of an Azure ML web service. Type: string (or Expression with resultType
   * string).
   */
  servicePrincipalId?: any;
  /**
   * The key of the service principal used to authenticate against the ARM-based
   * updateResourceEndpoint of an Azure ML web service.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for Teradata data source.
 */
export interface TeradataLinkedService extends LinkedService {
  /**
   * Server name for connection. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * AuthenticationType to be used for connection. Possible values include: 'Basic', 'Windows'
   */
  authenticationType?: string;
  /**
   * Username for authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * Password for authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for DB2 data source.
 */
export interface Db2LinkedService extends LinkedService {
  /**
   * Server name for connection. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * Database name for connection. Type: string (or Expression with resultType string).
   */
  database: any;
  /**
   * AuthenticationType to be used for connection. Possible values include: 'Basic'
   */
  authenticationType?: string;
  /**
   * Username for authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * Password for authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for Sybase data source.
 */
export interface SybaseLinkedService extends LinkedService {
  /**
   * Server name for connection. Type: string (or Expression with resultType string).
   */
  server: any;
  /**
   * Database name for connection. Type: string (or Expression with resultType string).
   */
  database: any;
  /**
   * Schema name for connection. Type: string (or Expression with resultType string).
   */
  schema?: any;
  /**
   * AuthenticationType to be used for connection. Possible values include: 'Basic', 'Windows'
   */
  authenticationType?: string;
  /**
   * Username for authentication. Type: string (or Expression with resultType string).
   */
  username?: any;
  /**
   * Password for authentication.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for PostgreSQL data source.
 */
export interface PostgreSqlLinkedService extends LinkedService {
  /**
   * The connection string.
   */
  connectionString: SecretBase;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Linked service for MySQL data source.
 */
export interface MySqlLinkedService extends LinkedService {
  /**
   * The connection string.
   */
  connectionString: SecretBase;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure MySQL database linked service.
 */
export interface AzureMySqlLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Oracle database.
 */
export interface OracleLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * File system linked service.
 */
export interface FileServerLinkedService extends LinkedService {
  /**
   * Host name of the server. Type: string (or Expression with resultType string).
   */
  host: any;
  /**
   * User ID to logon the server. Type: string (or Expression with resultType string).
   */
  userId?: any;
  /**
   * Password to logon the server.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * HDInsight linked service.
 */
export interface HDInsightLinkedService extends LinkedService {
  /**
   * HDInsight cluster URI. Type: string (or Expression with resultType string).
   */
  clusterUri: any;
  /**
   * HDInsight cluster user name. Type: string (or Expression with resultType string).
   */
  userName?: any;
  /**
   * HDInsight cluster password.
   */
  password?: SecretBase;
  /**
   * The Azure Storage linked service reference.
   */
  linkedServiceName?: LinkedServiceReference;
  /**
   * A reference to the Azure SQL linked service that points to the HCatalog database.
   */
  hcatalogLinkedServiceName?: LinkedServiceReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
  /**
   * Specify if the HDInsight is created with ESP (Enterprise Security Package). Type: Boolean.
   */
  isEspEnabled?: any;
}

/**
 * Dynamics linked service.
 */
export interface DynamicsLinkedService extends LinkedService {
  /**
   * The deployment type of the Dynamics instance. 'Online' for Dynamics Online and
   * 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or Expression with
   * resultType string).
   */
  deploymentType: any;
  /**
   * The host name of the on-premises Dynamics server. The property is required for on-prem and not
   * allowed for online. Type: string (or Expression with resultType string).
   */
  hostName?: any;
  /**
   * The port of on-premises Dynamics server. The property is required for on-prem and not allowed
   * for online. Default is 443. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  port?: any;
  /**
   * The URL to the Microsoft Dynamics server. The property is required for on-line and not allowed
   * for on-prem. Type: string (or Expression with resultType string).
   */
  serviceUri?: any;
  /**
   * The organization name of the Dynamics instance. The property is required for on-prem and
   * required for online when there are more than one Dynamics instances associated with the user.
   * Type: string (or Expression with resultType string).
   */
  organizationName?: any;
  /**
   * The authentication type to connect to Dynamics server. 'Office365' for online scenario, 'Ifd'
   * for on-premises with Ifd scenario. Type: string (or Expression with resultType string).
   */
  authenticationType: any;
  /**
   * User name to access the Dynamics instance. Type: string (or Expression with resultType
   * string).
   */
  username: any;
  /**
   * Password to access the Dynamics instance.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Microsoft Azure Cosmos Database (CosmosDB) linked service.
 */
export interface CosmosDbLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The Azure key vault secret reference of accountKey in connection string.
   */
  accountKey?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure Key Vault linked service.
 */
export interface AzureKeyVaultLinkedService extends LinkedService {
  /**
   * The base URL of the Azure Key Vault. e.g. https://myakv.vault.azure.net Type: string (or
   * Expression with resultType string).
   */
  baseUrl: any;
}

/**
 * Azure Batch linked service.
 */
export interface AzureBatchLinkedService extends LinkedService {
  /**
   * The Azure Batch account name. Type: string (or Expression with resultType string).
   */
  accountName: any;
  /**
   * The Azure Batch account access key.
   */
  accessKey?: SecretBase;
  /**
   * The Azure Batch URI. Type: string (or Expression with resultType string).
   */
  batchUri: any;
  /**
   * The Azure Batch pool name. Type: string (or Expression with resultType string).
   */
  poolName: any;
  /**
   * The Azure Storage linked service reference.
   */
  linkedServiceName: LinkedServiceReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Microsoft Azure SQL Database linked service.
 */
export interface AzureSqlDatabaseLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The ID of the service principal used to authenticate against Azure SQL Database. Type: string
   * (or Expression with resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The key of the service principal used to authenticate against Azure SQL Database.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * SQL Server linked service.
 */
export interface SqlServerLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The on-premises Windows authentication user name. Type: string (or Expression with resultType
   * string).
   */
  userName?: any;
  /**
   * The on-premises Windows authentication password.
   */
  password?: SecretBase;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * Azure SQL Data Warehouse linked service.
 */
export interface AzureSqlDWLinkedService extends LinkedService {
  /**
   * The connection string. Type: string, SecureString or AzureKeyVaultSecretReference. Type:
   * string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString: any;
  /**
   * The Azure key vault secret reference of password in connection string.
   */
  password?: AzureKeyVaultSecretReference;
  /**
   * The ID of the service principal used to authenticate against Azure SQL Data Warehouse. Type:
   * string (or Expression with resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The key of the service principal used to authenticate against Azure SQL Data Warehouse.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: any;
}

/**
 * The azure table storage linked service.
 */
export interface AzureTableStorageLinkedService extends LinkedService {
  /**
   * The connection string. It is mutually exclusive with sasUri property. Type: string,
   * SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of accountKey in connection string.
   */
  accountKey?: AzureKeyVaultSecretReference;
  /**
   * SAS URI of the Azure Storage resource. It is mutually exclusive with connectionString
   * property. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  sasUri?: any;
  /**
   * The Azure key vault secret reference of sasToken in sas uri.
   */
  sasToken?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: string;
}

/**
 * The azure blob storage linked service.
 */
export interface AzureBlobStorageLinkedService extends LinkedService {
  /**
   * The connection string. It is mutually exclusive with sasUri, serviceEndpoint property. Type:
   * string, SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of accountKey in connection string.
   */
  accountKey?: AzureKeyVaultSecretReference;
  /**
   * SAS URI of the Azure Blob Storage resource. It is mutually exclusive with connectionString,
   * serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  sasUri?: any;
  /**
   * The Azure key vault secret reference of sasToken in sas uri.
   */
  sasToken?: AzureKeyVaultSecretReference;
  /**
   * Blob service endpoint of the Azure Blob Storage resource. It is mutually exclusive with
   * connectionString, sasUri property.
   */
  serviceEndpoint?: string;
  /**
   * The ID of the service principal used to authenticate against Azure SQL Data Warehouse. Type:
   * string (or Expression with resultType string).
   */
  servicePrincipalId?: any;
  /**
   * The key of the service principal used to authenticate against Azure SQL Data Warehouse.
   */
  servicePrincipalKey?: SecretBase;
  /**
   * The name or ID of the tenant to which the service principal belongs. Type: string (or
   * Expression with resultType string).
   */
  tenant?: any;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: string;
}

/**
 * The storage account linked service.
 */
export interface AzureStorageLinkedService extends LinkedService {
  /**
   * The connection string. It is mutually exclusive with sasUri property. Type: string,
   * SecureString or AzureKeyVaultSecretReference.
   */
  connectionString?: any;
  /**
   * The Azure key vault secret reference of accountKey in connection string.
   */
  accountKey?: AzureKeyVaultSecretReference;
  /**
   * SAS URI of the Azure Storage resource. It is mutually exclusive with connectionString
   * property. Type: string, SecureString or AzureKeyVaultSecretReference.
   */
  sasUri?: any;
  /**
   * The Azure key vault secret reference of sasToken in sas uri.
   */
  sasToken?: AzureKeyVaultSecretReference;
  /**
   * The encrypted credential used for authentication. Credentials are encrypted using the
   * integration runtime credential manager. Type: string (or Expression with resultType string).
   */
  encryptedCredential?: string;
}

/**
 * Responsys dataset.
 */
export interface ResponsysObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Salesforce Marketing Cloud dataset.
 */
export interface SalesforceMarketingCloudObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Vertica dataset.
 */
export interface VerticaTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Netezza dataset.
 */
export interface NetezzaTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Zoho server dataset.
 */
export interface ZohoObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Xero Service dataset.
 */
export interface XeroObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Square Service dataset.
 */
export interface SquareObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Spark Server dataset.
 */
export interface SparkObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Shopify Service dataset.
 */
export interface ShopifyObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * ServiceNow server dataset.
 */
export interface ServiceNowObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * QuickBooks server dataset.
 */
export interface QuickBooksObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Presto server dataset.
 */
export interface PrestoObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Phoenix server dataset.
 */
export interface PhoenixObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Paypal Service dataset.
 */
export interface PaypalObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Marketo server dataset.
 */
export interface MarketoObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * MariaDB server dataset.
 */
export interface MariaDBTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Magento server dataset.
 */
export interface MagentoObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Jira Service dataset.
 */
export interface JiraObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Impala server dataset.
 */
export interface ImpalaObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Hubspot Service dataset.
 */
export interface HubspotObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Hive Server dataset.
 */
export interface HiveObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * HBase server dataset.
 */
export interface HBaseObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Greenplum Database dataset.
 */
export interface GreenplumTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Google BigQuery service dataset.
 */
export interface GoogleBigQueryObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Eloqua server dataset.
 */
export interface EloquaObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Drill server dataset.
 */
export interface DrillTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Couchbase server dataset.
 */
export interface CouchbaseTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Concur Service dataset.
 */
export interface ConcurObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Azure PostgreSQL dataset.
 */
export interface AzurePostgreSqlTableDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * Amazon Marketplace Web Service dataset.
 */
export interface AmazonMWSObjectDataset extends Dataset {
  /**
   * The table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * The compression method used on a dataset.
 */
export interface DatasetCompression {
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * The ZipDeflate compression method used on a dataset.
 */
export interface DatasetZipDeflateCompression extends DatasetCompression {
  /**
   * The ZipDeflate compression level. Possible values include: 'Optimal', 'Fastest'
   */
  level?: string;
}

/**
 * The Deflate compression method used on a dataset.
 */
export interface DatasetDeflateCompression extends DatasetCompression {
  /**
   * The Deflate compression level. Possible values include: 'Optimal', 'Fastest'
   */
  level?: string;
}

/**
 * The GZip compression method used on a dataset.
 */
export interface DatasetGZipCompression extends DatasetCompression {
  /**
   * The GZip compression level. Possible values include: 'Optimal', 'Fastest'
   */
  level?: string;
}

/**
 * The BZip2 compression method used on a dataset.
 */
export interface DatasetBZip2Compression extends DatasetCompression {
}

/**
 * The format definition of a storage.
 */
export interface DatasetStorageFormat {
  /**
   * Serializer. Type: string (or Expression with resultType string).
   */
  serializer?: any;
  /**
   * Deserializer. Type: string (or Expression with resultType string).
   */
  deserializer?: any;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * The data stored in Parquet format.
 */
export interface ParquetFormat extends DatasetStorageFormat {
}

/**
 * The data stored in Optimized Row Columnar (ORC) format.
 */
export interface OrcFormat extends DatasetStorageFormat {
}

/**
 * The data stored in Avro format.
 */
export interface AvroFormat extends DatasetStorageFormat {
}

/**
 * The data stored in JSON format.
 */
export interface JsonFormat extends DatasetStorageFormat {
  /**
   * File pattern of JSON. To be more specific, the way of separating a collection of JSON objects.
   * The default value is 'setOfObjects'. It is case-sensitive. Possible values include:
   * 'setOfObjects', 'arrayOfObjects'
   */
  filePattern?: string;
  /**
   * The character used to separate nesting levels. Default value is '.' (dot). Type: string (or
   * Expression with resultType string).
   */
  nestingSeparator?: any;
  /**
   * The code page name of the preferred encoding. If not provided, the default value is 'utf-8',
   * unless the byte order mark (BOM) denotes another Unicode encoding. The full list of supported
   * values can be found in the 'Name' column of the table of encodings in the following reference:
   * https://go.microsoft.com/fwlink/?linkid=861078. Type: string (or Expression with resultType
   * string).
   */
  encodingName?: any;
  /**
   * The JSONPath of the JSON array element to be flattened. Example: "$.ArrayPath". Type: string
   * (or Expression with resultType string).
   */
  jsonNodeReference?: any;
  /**
   * The JSONPath definition for each column mapping with a customized column name to extract data
   * from JSON file. For fields under root object, start with "$"; for fields inside the array
   * chosen by jsonNodeReference property, start from the array element. Example: {"Column1":
   * "$.Column1Path", "Column2": "Column2PathInArray"}. Type: object (or Expression with resultType
   * object).
   */
  jsonPathDefinition?: any;
}

/**
 * The data stored in text format.
 */
export interface TextFormat extends DatasetStorageFormat {
  /**
   * The column delimiter. Type: string (or Expression with resultType string).
   */
  columnDelimiter?: any;
  /**
   * The row delimiter. Type: string (or Expression with resultType string).
   */
  rowDelimiter?: any;
  /**
   * The escape character. Type: string (or Expression with resultType string).
   */
  escapeChar?: any;
  /**
   * The quote character. Type: string (or Expression with resultType string).
   */
  quoteChar?: any;
  /**
   * The null value string. Type: string (or Expression with resultType string).
   */
  nullValue?: any;
  /**
   * The code page name of the preferred encoding. If miss, the default value is ΓÇ£utf-8ΓÇ¥,
   * unless BOM denotes another Unicode encoding. Refer to the ΓÇ£NameΓÇ¥ column of the table in
   * the following link to set supported values:
   * https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
   * resultType string).
   */
  encodingName?: any;
  /**
   * Treat empty column values in the text file as null. The default value is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  treatEmptyAsNull?: any;
  /**
   * The number of lines/rows to be skipped when parsing text files. The default value is 0. Type:
   * integer (or Expression with resultType integer).
   */
  skipLineCount?: any;
  /**
   * When used as input, treat the first row of data as headers. When used as output,write the
   * headers into the output as the first row of data. The default value is false. Type: boolean
   * (or Expression with resultType boolean).
   */
  firstRowAsHeader?: any;
}

/**
 * A file in an HTTP web server.
 */
export interface HttpDataset extends Dataset {
  /**
   * The relative URL based on the URL in the HttpLinkedService refers to an HTTP file Type: string
   * (or Expression with resultType string).
   */
  relativeUrl?: any;
  /**
   * The HTTP method for the HTTP request. Type: string (or Expression with resultType string).
   */
  requestMethod?: any;
  /**
   * The body for the HTTP request. Type: string (or Expression with resultType string).
   */
  requestBody?: any;
  /**
   * The headers for the HTTP Request. e.g. request-header-name-1:request-header-value-1
   * ...
   * request-header-name-n:request-header-value-n Type: string (or Expression with resultType
   * string).
   */
  additionalHeaders?: any;
  /**
   * The format of files.
   */
  format?: DatasetStorageFormat;
  /**
   * The data compression method used on files.
   */
  compression?: DatasetCompression;
}

/**
 * The Azure Search Index.
 */
export interface AzureSearchIndexDataset extends Dataset {
  /**
   * The name of the Azure Search Index. Type: string (or Expression with resultType string).
   */
  indexName: any;
}

/**
 * The dataset points to a HTML table in the web page.
 */
export interface WebTableDataset extends Dataset {
  /**
   * The zero-based index of the table in the web page. Type: integer (or Expression with
   * resultType integer), minimum: 0.
   */
  index: any;
  /**
   * The relative URL to the web page from the linked service URL. Type: string (or Expression with
   * resultType string).
   */
  path?: any;
}

/**
 * The on-premises SQL Server dataset.
 */
export interface SqlServerTableDataset extends Dataset {
  /**
   * The table name of the SQL Server dataset. Type: string (or Expression with resultType string).
   */
  tableName: any;
}

/**
 * The path of the SAP ECC OData entity.
 */
export interface SapEccResourceDataset extends Dataset {
  /**
   * The path of the SAP ECC OData entity. Type: string (or Expression with resultType string).
   */
  path: string;
}

/**
 * The path of the SAP Cloud for Customer OData entity.
 */
export interface SapCloudForCustomerResourceDataset extends Dataset {
  /**
   * The path of the SAP Cloud for Customer OData entity. Type: string (or Expression with
   * resultType string).
   */
  path: any;
}

/**
 * The Salesforce object dataset.
 */
export interface SalesforceObjectDataset extends Dataset {
  /**
   * The Salesforce object API name. Type: string (or Expression with resultType string).
   */
  objectApiName?: any;
}

/**
 * The relational table dataset.
 */
export interface RelationalTableDataset extends Dataset {
  /**
   * The relational table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * The Azure MySQL database dataset.
 */
export interface AzureMySqlTableDataset extends Dataset {
  /**
   * The Azure MySQL database table name. Type: string (or Expression with resultType string).
   */
  tableName?: any;
}

/**
 * The on-premises Oracle database dataset.
 */
export interface OracleTableDataset extends Dataset {
  /**
   * The table name of the on-premises Oracle database. Type: string (or Expression with resultType
   * string).
   */
  tableName: any;
}

/**
 * The Open Data Protocol (OData) resource dataset.
 */
export interface ODataResourceDataset extends Dataset {
  /**
   * The OData resource path. Type: string (or Expression with resultType string).
   */
  path?: any;
}

/**
 * The MongoDB database dataset.
 */
export interface MongoDbCollectionDataset extends Dataset {
  /**
   * The table name of the MongoDB database. Type: string (or Expression with resultType string).
   */
  collectionName: any;
}

/**
 * An on-premises file system dataset.
 */
export interface FileShareDataset extends Dataset {
  /**
   * The path of the on-premises file system. Type: string (or Expression with resultType string).
   */
  folderPath?: any;
  /**
   * The name of the on-premises file system. Type: string (or Expression with resultType string).
   */
  fileName?: any;
  /**
   * The format of the files.
   */
  format?: DatasetStorageFormat;
  /**
   * Specify a filter to be used to select a subset of files in the folderPath rather than all
   * files. Type: string (or Expression with resultType string).
   */
  fileFilter?: any;
  /**
   * The data compression method used for the file system.
   */
  compression?: DatasetCompression;
}

/**
 * Azure Data Lake Store dataset.
 */
export interface AzureDataLakeStoreDataset extends Dataset {
  /**
   * Path to the folder in the Azure Data Lake Store. Type: string (or Expression with resultType
   * string).
   */
  folderPath: any;
  /**
   * The name of the file in the Azure Data Lake Store. Type: string (or Expression with resultType
   * string).
   */
  fileName?: any;
  /**
   * The format of the Data Lake Store.
   */
  format?: DatasetStorageFormat;
  /**
   * The data compression method used for the item(s) in the Azure Data Lake Store.
   */
  compression?: DatasetCompression;
}

/**
 * The Dynamics entity dataset.
 */
export interface DynamicsEntityDataset extends Dataset {
  /**
   * The logical name of the entity. Type: string (or Expression with resultType string).
   */
  entityName?: any;
}

/**
 * Microsoft Azure Document Database Collection dataset.
 */
export interface DocumentDbCollectionDataset extends Dataset {
  /**
   * Document Database collection name. Type: string (or Expression with resultType string).
   */
  collectionName: any;
}

/**
 * The custom dataset.
 */
export interface CustomDataset extends Dataset {
  /**
   * Custom dataset properties.
   */
  typeProperties: any;
}

/**
 * The Cassandra database dataset.
 */
export interface CassandraTableDataset extends Dataset {
  /**
   * The table name of the Cassandra database. Type: string (or Expression with resultType string).
   */
  tableName?: any;
  /**
   * The keyspace of the Cassandra database. Type: string (or Expression with resultType string).
   */
  keyspace?: any;
}

/**
 * The Azure SQL Data Warehouse dataset.
 */
export interface AzureSqlDWTableDataset extends Dataset {
  /**
   * The table name of the Azure SQL Data Warehouse. Type: string (or Expression with resultType
   * string).
   */
  tableName: any;
}

/**
 * The Azure SQL Server database dataset.
 */
export interface AzureSqlTableDataset extends Dataset {
  /**
   * The table name of the Azure SQL database. Type: string (or Expression with resultType string).
   */
  tableName: any;
}

/**
 * The Azure Table storage dataset.
 */
export interface AzureTableDataset extends Dataset {
  /**
   * The table name of the Azure Table storage. Type: string (or Expression with resultType
   * string).
   */
  tableName: any;
}

/**
 * The Azure Blob storage.
 */
export interface AzureBlobDataset extends Dataset {
  /**
   * The path of the Azure Blob storage. Type: string (or Expression with resultType string).
   */
  folderPath?: any;
  /**
   * The root of blob path. Type: string (or Expression with resultType string).
   */
  tableRootLocation?: any;
  /**
   * The name of the Azure Blob. Type: string (or Expression with resultType string).
   */
  fileName?: any;
  /**
   * The format of the Azure Blob storage.
   */
  format?: DatasetStorageFormat;
  /**
   * The data compression method used for the blob storage.
   */
  compression?: DatasetCompression;
}

/**
 * A single Amazon Simple Storage Service (S3) object or a set of S3 objects.
 */
export interface AmazonS3Dataset extends Dataset {
  /**
   * The name of the Amazon S3 bucket. Type: string (or Expression with resultType string).
   */
  bucketName: any;
  /**
   * The key of the Amazon S3 object. Type: string (or Expression with resultType string).
   */
  key?: any;
  /**
   * The prefix filter for the S3 object name. Type: string (or Expression with resultType string).
   */
  prefix?: any;
  /**
   * The version for the S3 object. Type: string (or Expression with resultType string).
   */
  version?: any;
  /**
   * The format of files.
   */
  format?: DatasetStorageFormat;
  /**
   * The data compression method used for the Amazon S3 object.
   */
  compression?: DatasetCompression;
}

/**
 * Execution policy for an activity.
 */
export interface ActivityPolicy {
  /**
   * Specifies the timeout for the activity to run. The default timeout is 7 days. Type: string (or
   * Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  timeout?: any;
  /**
   * Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with resultType
   * integer), minimum: 0.
   */
  retry?: any;
  /**
   * Interval between each retry attempt (in seconds). The default is 30 sec.
   */
  retryIntervalInSeconds?: number;
  /**
   * When set to true, Input from activity is considered as secure and will not be logged to
   * monitoring.
   */
  secureInput?: boolean;
  /**
   * When set to true, Output from activity is considered as secure and will not be logged to
   * monitoring.
   */
  secureOutput?: boolean;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Base class for all execution activities.
 */
export interface ExecutionActivity extends Activity {
  /**
   * Linked service reference.
   */
  linkedServiceName?: LinkedServiceReference;
  /**
   * Activity policy.
   */
  policy?: ActivityPolicy;
}

/**
 * DatabricksSparkPython activity.
 */
export interface DatabricksSparkPythonActivity extends ExecutionActivity {
  /**
   * The URI of the Python file to be executed. DBFS paths are supported. Type: string (or
   * Expression with resultType string).
   */
  pythonFile: any;
  /**
   * Command line parameters that will be passed to the Python file.
   */
  parameters?: any[];
  /**
   * A list of libraries to be installed on the cluster that will execute the job.
   */
  libraries?: { [propertyName: string]: any }[];
}

/**
 * DatabricksSparkJar activity.
 */
export interface DatabricksSparkJarActivity extends ExecutionActivity {
  /**
   * The full name of the class containing the main method to be executed. This class must be
   * contained in a JAR provided as a library. Type: string (or Expression with resultType string).
   */
  mainClassName: any;
  /**
   * Parameters that will be passed to the main method.
   */
  parameters?: any[];
  /**
   * A list of libraries to be installed on the cluster that will execute the job.
   */
  libraries?: { [propertyName: string]: any }[];
}

/**
 * DatabricksNotebook activity.
 */
export interface DatabricksNotebookActivity extends ExecutionActivity {
  /**
   * The absolute path of the notebook to be run in the Databricks Workspace. This path must begin
   * with a slash. Type: string (or Expression with resultType string).
   */
  notebookPath: any;
  /**
   * Base parameters to be used for each run of this job.If the notebook takes a parameter that is
   * not specified, the default value from the notebook will be used.
   */
  baseParameters?: { [propertyName: string]: any };
  /**
   * A list of libraries to be installed on the cluster that will execute the job.
   */
  libraries?: { [propertyName: string]: any }[];
}

/**
 * Data Lake Analytics U-SQL activity.
 */
export interface DataLakeAnalyticsUSQLActivity extends ExecutionActivity {
  /**
   * Case-sensitive path to folder that contains the U-SQL script. Type: string (or Expression with
   * resultType string).
   */
  scriptPath: any;
  /**
   * Script linked service reference.
   */
  scriptLinkedService: LinkedServiceReference;
  /**
   * The maximum number of nodes simultaneously used to run the job. Default value is 1. Type:
   * integer (or Expression with resultType integer), minimum: 1.
   */
  degreeOfParallelism?: any;
  /**
   * Determines which jobs out of all that are queued should be selected to run first. The lower
   * the number, the higher the priority. Default value is 1000. Type: integer (or Expression with
   * resultType integer), minimum: 1.
   */
  priority?: any;
  /**
   * Parameters for U-SQL job request.
   */
  parameters?: { [propertyName: string]: any };
  /**
   * Runtime version of the U-SQL engine to use. Type: string (or Expression with resultType
   * string).
   */
  runtimeVersion?: any;
  /**
   * Compilation mode of U-SQL. Must be one of these values : Semantic, Full and SingleBox. Type:
   * string (or Expression with resultType string).
   */
  compilationMode?: any;
}

/**
 * Azure ML Update Resource management activity.
 */
export interface AzureMLUpdateResourceActivity extends ExecutionActivity {
  /**
   * Name of the Trained Model module in the Web Service experiment to be updated. Type: string (or
   * Expression with resultType string).
   */
  trainedModelName: any;
  /**
   * Name of Azure Storage linked service holding the .ilearner file that will be uploaded by the
   * update operation.
   */
  trainedModelLinkedServiceName: LinkedServiceReference;
  /**
   * The relative file path in trainedModelLinkedService to represent the .ilearner file that will
   * be uploaded by the update operation.  Type: string (or Expression with resultType string).
   */
  trainedModelFilePath: any;
}

/**
 * Azure ML WebService Input/Output file
 */
export interface AzureMLWebServiceFile {
  /**
   * The relative file path, including container name, in the Azure Blob Storage specified by the
   * LinkedService. Type: string (or Expression with resultType string).
   */
  filePath: any;
  /**
   * Reference to an Azure Storage LinkedService, where Azure ML WebService Input/Output file
   * located.
   */
  linkedServiceName: LinkedServiceReference;
}

/**
 * Azure ML Batch Execution activity.
 */
export interface AzureMLBatchExecutionActivity extends ExecutionActivity {
  /**
   * Key,Value pairs to be passed to the Azure ML Batch Execution Service endpoint. Keys must match
   * the names of web service parameters defined in the published Azure ML web service. Values will
   * be passed in the GlobalParameters property of the Azure ML batch execution request.
   */
  globalParameters?: { [propertyName: string]: any };
  /**
   * Key,Value pairs, mapping the names of Azure ML endpoint's Web Service Outputs to
   * AzureMLWebServiceFile objects specifying the output Blob locations. This information will be
   * passed in the WebServiceOutputs property of the Azure ML batch execution request.
   */
  webServiceOutputs?: { [propertyName: string]: AzureMLWebServiceFile };
  /**
   * Key,Value pairs, mapping the names of Azure ML endpoint's Web Service Inputs to
   * AzureMLWebServiceFile objects specifying the input Blob locations.. This information will be
   * passed in the WebServiceInputs property of the Azure ML batch execution request.
   */
  webServiceInputs?: { [propertyName: string]: AzureMLWebServiceFile };
}

/**
 * Activity to get metadata of dataset
 */
export interface GetMetadataActivity extends ExecutionActivity {
  /**
   * GetMetadata activity dataset reference.
   */
  dataset: DatasetReference;
  /**
   * Fields of metadata to get from dataset.
   */
  fieldList?: any[];
}

/**
 * Web activity authentication properties.
 */
export interface WebActivityAuthentication {
  /**
   * Web activity authentication (Basic/ClientCertificate/MSI)
   */
  type: string;
  /**
   * Base64-encoded contents of a PFX file.
   */
  pfx?: SecureString;
  /**
   * Web activity authentication user name for basic authentication.
   */
  username?: string;
  /**
   * Password for the PFX file or basic authentication.
   */
  password?: SecureString;
  /**
   * Resource for which Azure Auth token will be requested when using MSI Authentication.
   */
  resource?: string;
}

/**
 * Web activity.
 */
export interface WebActivity extends ExecutionActivity {
  /**
   * Rest API method for target endpoint. Possible values include: 'GET', 'POST', 'PUT', 'DELETE'
   */
  method: string;
  /**
   * Web activity target endpoint and path. Type: string (or Expression with resultType string).
   */
  url: any;
  /**
   * Represents the headers that will be sent to the request. For example, to set the language and
   * type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
   * "application/json" }. Type: string (or Expression with resultType string).
   */
  headers?: any;
  /**
   * Represents the payload that will be sent to the endpoint. Required for POST/PUT method, not
   * allowed for GET method Type: string (or Expression with resultType string).
   */
  body?: any;
  /**
   * Authentication method used for calling the endpoint.
   */
  authentication?: WebActivityAuthentication;
  /**
   * List of datasets passed to web endpoint.
   */
  datasets?: DatasetReference[];
  /**
   * List of linked services passed to web endpoint.
   */
  linkedServices?: LinkedServiceReference[];
}

/**
 * The Amazon S3 settings needed for the interim Amazon S3 when copying from Amazon Redshift with
 * unload. With this, data from Amazon Redshift source will be unloaded into S3 first and then
 * copied into the targeted sink from the interim S3.
 */
export interface RedshiftUnloadSettings {
  /**
   * The name of the Amazon S3 linked service which will be used for the unload operation when
   * copying from the Amazon Redshift source.
   */
  s3LinkedServiceName: LinkedServiceReference;
  /**
   * The bucket of the interim Amazon S3 which will be used to store the unloaded data from Amazon
   * Redshift source. The bucket must be in the same region as the Amazon Redshift source. Type:
   * string (or Expression with resultType string).
   */
  bucketName: any;
}

/**
 * A copy activity source.
 */
export interface CopySource {
  /**
   * Source retry count. Type: integer (or Expression with resultType integer).
   */
  sourceRetryCount?: any;
  /**
   * Source retry wait. Type: string (or Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  sourceRetryWait?: any;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A copy activity source for Amazon Redshift Source.
 */
export interface AmazonRedshiftSource extends CopySource {
  /**
   * Database query. Type: string (or Expression with resultType string).
   */
  query?: any;
  /**
   * The Amazon S3 settings needed for the interim Amazon S3 when copying from Amazon Redshift with
   * unload. With this, data from Amazon Redshift source will be unloaded into S3 first and then
   * copied into the targeted sink from the interim S3.
   */
  redshiftUnloadSettings?: RedshiftUnloadSettings;
}

/**
 * A copy activity Responsys source.
 */
export interface ResponsysSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Salesforce Marketing Cloud source.
 */
export interface SalesforceMarketingCloudSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Vertica source.
 */
export interface VerticaSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Netezza source.
 */
export interface NetezzaSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Zoho server source.
 */
export interface ZohoSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Xero Service source.
 */
export interface XeroSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Square Service source.
 */
export interface SquareSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Spark Server source.
 */
export interface SparkSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Shopify Service source.
 */
export interface ShopifySource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity ServiceNow server source.
 */
export interface ServiceNowSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity QuickBooks server source.
 */
export interface QuickBooksSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Presto server source.
 */
export interface PrestoSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Phoenix server source.
 */
export interface PhoenixSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Paypal Service source.
 */
export interface PaypalSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Marketo server source.
 */
export interface MarketoSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity MariaDB server source.
 */
export interface MariaDBSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Magento server source.
 */
export interface MagentoSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Jira Service source.
 */
export interface JiraSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Impala server source.
 */
export interface ImpalaSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Hubspot Service source.
 */
export interface HubspotSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Hive Server source.
 */
export interface HiveSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity HBase server source.
 */
export interface HBaseSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Greenplum Database source.
 */
export interface GreenplumSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Google BigQuery service source.
 */
export interface GoogleBigQuerySource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Eloqua server source.
 */
export interface EloquaSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Drill server source.
 */
export interface DrillSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Couchbase server source.
 */
export interface CouchbaseSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Concur Service source.
 */
export interface ConcurSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Azure PostgreSQL source.
 */
export interface AzurePostgreSqlSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Amazon Marketplace Web Service source.
 */
export interface AmazonMWSSource extends CopySource {
  /**
   * A query to retrieve data from source. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity source for an HTTP file.
 */
export interface HttpSource extends CopySource {
  /**
   * Specifies the timeout for a HTTP client to get HTTP response from HTTP server. The default
   * value is equivalent to System.Net.HttpWebRequest.Timeout. Type: string (or Expression with
   * resultType string), pattern: ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  httpRequestTimeout?: any;
}

/**
 * A copy activity Azure Data Lake source.
 */
export interface AzureDataLakeStoreSource extends CopySource {
  /**
   * If true, files under the folder path will be read recursively. Default is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  recursive?: any;
}

/**
 * A copy activity source for a MongoDB database.
 */
export interface MongoDbSource extends CopySource {
  /**
   * Database query. Should be a SQL-92 query expression. Type: string (or Expression with
   * resultType string).
   */
  query?: any;
}

/**
 * A copy activity source for a Cassandra database.
 */
export interface CassandraSource extends CopySource {
  /**
   * Database query. Should be a SQL-92 query expression or Cassandra Query Language (CQL) command.
   * Type: string (or Expression with resultType string).
   */
  query?: any;
  /**
   * The consistency level specifies how many Cassandra servers must respond to a read request
   * before returning data to the client application. Cassandra checks the specified number of
   * Cassandra servers for data to satisfy the read request. Must be one of
   * cassandraSourceReadConsistencyLevels. The default value is 'ONE'. It is case-insensitive.
   * Possible values include: 'ALL', 'EACH_QUORUM', 'QUORUM', 'LOCAL_QUORUM', 'ONE', 'TWO',
   * 'THREE', 'LOCAL_ONE', 'SERIAL', 'LOCAL_SERIAL'
   */
  consistencyLevel?: string;
}

/**
 * A copy activity source for web page table.
 */
export interface WebSource extends CopySource {
}

/**
 * A copy activity Oracle source.
 */
export interface OracleSource extends CopySource {
  /**
   * Oracle reader query. Type: string (or Expression with resultType string).
   */
  oracleReaderQuery?: any;
  /**
   * Query timeout. Type: string (or Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  queryTimeout?: any;
}

/**
 * A copy activity Azure MySQL source.
 */
export interface AzureMySqlSource extends CopySource {
  /**
   * Database query. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * Distcp settings.
 */
export interface DistcpSettings {
  /**
   * Specifies the Yarn ResourceManager endpoint. Type: string (or Expression with resultType
   * string).
   */
  resourceManagerEndpoint: any;
  /**
   * Specifies an existing folder path which will be used to store temp Distcp command script. The
   * script file is generated by ADF and will be removed after Copy job finished. Type: string (or
   * Expression with resultType string).
   */
  tempScriptPath: any;
  /**
   * Specifies the Distcp options. Type: string (or Expression with resultType string).
   */
  distcpOptions?: any;
}

/**
 * A copy activity HDFS source.
 */
export interface HdfsSource extends CopySource {
  /**
   * If true, files under the folder path will be read recursively. Default is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  recursive?: any;
  /**
   * Specifies Distcp-related settings.
   */
  distcpSettings?: DistcpSettings;
}

/**
 * A copy activity file system source.
 */
export interface FileSystemSource extends CopySource {
  /**
   * If true, files under the folder path will be read recursively. Default is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  recursive?: any;
}

/**
 * A copy activity SQL Data Warehouse source.
 */
export interface SqlDWSource extends CopySource {
  /**
   * SQL Data Warehouse reader query. Type: string (or Expression with resultType string).
   */
  sqlReaderQuery?: any;
  /**
   * Name of the stored procedure for a SQL Data Warehouse source. This cannot be used at the same
   * time as SqlReaderQuery. Type: string (or Expression with resultType string).
   */
  sqlReaderStoredProcedureName?: any;
  /**
   * Value and type setting for stored procedure parameters. Example: "{Parameter1: {value: "1",
   * type: "int"}}". Type: object (or Expression with resultType object), itemType:
   * StoredProcedureParameter.
   */
  storedProcedureParameters?: any;
}

/**
 * SQL stored procedure parameter.
 */
export interface StoredProcedureParameter {
  /**
   * Stored procedure parameter value. Type: string (or Expression with resultType string).
   */
  value?: any;
  /**
   * Stored procedure parameter type. Possible values include: 'String', 'Int', 'Decimal', 'Guid',
   * 'Boolean', 'Date'
   */
  type?: string;
}

/**
 * A copy activity SQL source.
 */
export interface SqlSource extends CopySource {
  /**
   * SQL reader query. Type: string (or Expression with resultType string).
   */
  sqlReaderQuery?: any;
  /**
   * Name of the stored procedure for a SQL Database source. This cannot be used at the same time
   * as SqlReaderQuery. Type: string (or Expression with resultType string).
   */
  sqlReaderStoredProcedureName?: any;
  /**
   * Value and type setting for stored procedure parameters. Example: "{Parameter1: {value: "1",
   * type: "int"}}".
   */
  storedProcedureParameters?: { [propertyName: string]: StoredProcedureParameter };
}

/**
 * A copy activity source for SAP ECC source.
 */
export interface SapEccSource extends CopySource {
  /**
   * SAP ECC OData query. For example, "$top=1". Type: string (or Expression with resultType
   * string).
   */
  query?: string;
}

/**
 * A copy activity source for SAP Cloud for Customer source.
 */
export interface SapCloudForCustomerSource extends CopySource {
  /**
   * SAP Cloud for Customer OData query. For example, "$top=1". Type: string (or Expression with
   * resultType string).
   */
  query?: any;
}

/**
 * A copy activity Salesforce source.
 */
export interface SalesforceSource extends CopySource {
  /**
   * Database query. Type: string (or Expression with resultType string).
   */
  query?: any;
  /**
   * The read behavior for the operation. Default is Query. Possible values include: 'Query',
   * 'QueryAll'
   */
  readBehavior?: string;
}

/**
 * A copy activity source for various relational databases.
 */
export interface RelationalSource extends CopySource {
  /**
   * Database query. Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Dynamics source.
 */
export interface DynamicsSource extends CopySource {
  /**
   * FetchXML is a proprietary query language that is used in Microsoft Dynamics (online &
   * on-premises). Type: string (or Expression with resultType string).
   */
  query?: any;
}

/**
 * A copy activity Document Database Collection source.
 */
export interface DocumentDbCollectionSource extends CopySource {
  /**
   * Documents query. Type: string (or Expression with resultType string).
   */
  query?: any;
  /**
   * Nested properties separator. Type: string (or Expression with resultType string).
   */
  nestingSeparator?: any;
}

/**
 * A copy activity Azure Blob source.
 */
export interface BlobSource extends CopySource {
  /**
   * Treat empty as null. Type: boolean (or Expression with resultType boolean).
   */
  treatEmptyAsNull?: any;
  /**
   * Number of header lines to skip from each blob. Type: integer (or Expression with resultType
   * integer).
   */
  skipHeaderLineCount?: any;
  /**
   * If true, files under the folder path will be read recursively. Default is true. Type: boolean
   * (or Expression with resultType boolean).
   */
  recursive?: any;
}

/**
 * A copy activity Azure Table source.
 */
export interface AzureTableSource extends CopySource {
  /**
   * Azure Table source query. Type: string (or Expression with resultType string).
   */
  azureTableSourceQuery?: any;
  /**
   * Azure Table source ignore table not found. Type: boolean (or Expression with resultType
   * boolean).
   */
  azureTableSourceIgnoreTableNotFound?: any;
}

/**
 * Lookup activity.
 */
export interface LookupActivity extends ExecutionActivity {
  /**
   * Dataset-specific source properties, same as copy activity source.
   */
  source: CopySource;
  /**
   * Lookup activity dataset reference.
   */
  dataset: DatasetReference;
  /**
   * Whether to return first row or all rows. Default value is true. Type: boolean (or Expression
   * with resultType boolean).
   */
  firstRowOnly?: any;
}

/**
 * Log storage settings.
 */
export interface LogStorageSettings {
  /**
   * Log storage linked service reference.
   */
  linkedServiceName: LinkedServiceReference;
  /**
   * The path to storage for storing detailed logs of activity execution. Type: string (or
   * Expression with resultType string).
   */
  path?: any;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Delete activity.
 */
export interface DeleteActivity extends ExecutionActivity {
  /**
   * If true, files or sub-folders under current folder path will be deleted recursively. Default
   * is false. Type: boolean (or Expression with resultType boolean).
   */
  recursive?: any;
  /**
   * The max concurrent connections to connect data source at the same time.
   */
  maxConcurrentConnections?: number;
  /**
   * Whether to record detailed logs of delete-activity execution. Default value is false. Type:
   * boolean (or Expression with resultType boolean).
   */
  enableLogging?: any;
  /**
   * Log storage settings customer need to provide when enableLogging is true.
   */
  logStorageSettings?: LogStorageSettings;
  /**
   * Delete activity dataset reference.
   */
  dataset: DatasetReference;
}

/**
 * SQL stored procedure activity type.
 */
export interface SqlServerStoredProcedureActivity extends ExecutionActivity {
  /**
   * Stored procedure name. Type: string (or Expression with resultType string).
   */
  storedProcedureName: any;
  /**
   * Value and type setting for stored procedure parameters. Example: "{Parameter1: {value: "1",
   * type: "int"}}".
   */
  storedProcedureParameters?: { [propertyName: string]: StoredProcedureParameter };
}

/**
 * Reference objects for custom activity
 */
export interface CustomActivityReferenceObject {
  /**
   * Linked service references.
   */
  linkedServices?: LinkedServiceReference[];
  /**
   * Dataset references.
   */
  datasets?: DatasetReference[];
}

/**
 * Custom activity type.
 */
export interface CustomActivity extends ExecutionActivity {
  /**
   * Command for custom activity Type: string (or Expression with resultType string).
   */
  command: any;
  /**
   * Resource linked service reference.
   */
  resourceLinkedService?: LinkedServiceReference;
  /**
   * Folder path for resource files Type: string (or Expression with resultType string).
   */
  folderPath?: any;
  /**
   * Reference objects
   */
  referenceObjects?: CustomActivityReferenceObject;
  /**
   * User defined property bag. There is no restriction on the keys or values that can be used. The
   * user specified custom activity has the full responsibility to consume and interpret the
   * content defined.
   */
  extendedProperties?: { [propertyName: string]: any };
}

/**
 * SSIS property override.
 */
export interface SSISPropertyOverride {
  /**
   * SSIS package property override value. Type: string (or Expression with resultType string).
   */
  value: any;
  /**
   * Whether SSIS package property override value is sensitive data. Value will be encrypted in
   * SSISDB if it is true
   */
  isSensitive?: boolean;
}

/**
 * SSIS execution parameter.
 */
export interface SSISExecutionParameter {
  /**
   * SSIS package execution parameter value. Type: string (or Expression with resultType string).
   */
  value: any;
}

/**
 * SSIS package location.
 */
export interface SSISPackageLocation {
  /**
   * The SSIS package path.
   */
  packagePath: string;
}

/**
 * Execute SSIS package activity.
 */
export interface ExecuteSSISPackageActivity extends ExecutionActivity {
  /**
   * SSIS package location.
   */
  packageLocation: SSISPackageLocation;
  /**
   * Specifies the runtime to execute SSIS package. Possible values include: 'x64', 'x86'
   */
  runtime?: string;
  /**
   * The logging level of SSIS package execution.
   */
  loggingLevel?: string;
  /**
   * The environment path to execute the SSIS package.
   */
  environmentPath?: string;
  /**
   * The integration runtime reference.
   */
  connectVia: IntegrationRuntimeReference;
  /**
   * The project level parameters to execute the SSIS package.
   */
  projectParameters?: { [propertyName: string]: SSISExecutionParameter };
  /**
   * The package level parameters to execute the SSIS package.
   */
  packageParameters?: { [propertyName: string]: SSISExecutionParameter };
  /**
   * The project level connection managers to execute the SSIS package.
   */
  projectConnectionManagers?: { [propertyName: string]: { [propertyName: string]: SSISExecutionParameter } };
  /**
   * The package level connection managers to execute the SSIS package.
   */
  packageConnectionManagers?: { [propertyName: string]: { [propertyName: string]: SSISExecutionParameter } };
  /**
   * The property overrides to execute the SSIS package.
   */
  propertyOverrides?: { [propertyName: string]: SSISPropertyOverride };
}

/**
 * HDInsight Spark activity.
 */
export interface HDInsightSparkActivity extends ExecutionActivity {
  /**
   * The root path in 'sparkJobLinkedService' for all the job’s files. Type: string (or Expression
   * with resultType string).
   */
  rootPath: any;
  /**
   * The relative path to the root folder of the code/package to be executed. Type: string (or
   * Expression with resultType string).
   */
  entryFilePath: any;
  /**
   * The user-specified arguments to HDInsightSparkActivity.
   */
  argumentsProperty?: any[];
  /**
   * Debug info option. Possible values include: 'None', 'Always', 'Failure'
   */
  getDebugInfo?: string;
  /**
   * The storage linked service for uploading the entry file and dependencies, and for receiving
   * logs.
   */
  sparkJobLinkedService?: LinkedServiceReference;
  /**
   * The application's Java/Spark main class.
   */
  className?: string;
  /**
   * The user to impersonate that will execute the job. Type: string (or Expression with resultType
   * string).
   */
  proxyUser?: any;
  /**
   * Spark configuration property.
   */
  sparkConfig?: { [propertyName: string]: any };
}

/**
 * HDInsight streaming activity type.
 */
export interface HDInsightStreamingActivity extends ExecutionActivity {
  /**
   * Storage linked service references.
   */
  storageLinkedServices?: LinkedServiceReference[];
  /**
   * User specified arguments to HDInsightActivity.
   */
  argumentsProperty?: any[];
  /**
   * Debug info option. Possible values include: 'None', 'Always', 'Failure'
   */
  getDebugInfo?: string;
  /**
   * Mapper executable name. Type: string (or Expression with resultType string).
   */
  mapper: any;
  /**
   * Reducer executable name. Type: string (or Expression with resultType string).
   */
  reducer: any;
  /**
   * Input blob path. Type: string (or Expression with resultType string).
   */
  input: any;
  /**
   * Output blob path. Type: string (or Expression with resultType string).
   */
  output: any;
  /**
   * Paths to streaming job files. Can be directories.
   */
  filePaths: any[];
  /**
   * Linked service reference where the files are located.
   */
  fileLinkedService?: LinkedServiceReference;
  /**
   * Combiner executable name. Type: string (or Expression with resultType string).
   */
  combiner?: any;
  /**
   * Command line environment values.
   */
  commandEnvironment?: any[];
  /**
   * Allows user to specify defines for streaming job request.
   */
  defines?: { [propertyName: string]: any };
}

/**
 * HDInsight MapReduce activity type.
 */
export interface HDInsightMapReduceActivity extends ExecutionActivity {
  /**
   * Storage linked service references.
   */
  storageLinkedServices?: LinkedServiceReference[];
  /**
   * User specified arguments to HDInsightActivity.
   */
  argumentsProperty?: any[];
  /**
   * Debug info option. Possible values include: 'None', 'Always', 'Failure'
   */
  getDebugInfo?: string;
  /**
   * Class name. Type: string (or Expression with resultType string).
   */
  className: any;
  /**
   * Jar path. Type: string (or Expression with resultType string).
   */
  jarFilePath: any;
  /**
   * Jar linked service reference.
   */
  jarLinkedService?: LinkedServiceReference;
  /**
   * Jar libs.
   */
  jarLibs?: any[];
  /**
   * Allows user to specify defines for the MapReduce job request.
   */
  defines?: { [propertyName: string]: any };
}

/**
 * HDInsight Pig activity type.
 */
export interface HDInsightPigActivity extends ExecutionActivity {
  /**
   * Storage linked service references.
   */
  storageLinkedServices?: LinkedServiceReference[];
  /**
   * User specified arguments to HDInsightActivity.
   */
  argumentsProperty?: any[];
  /**
   * Debug info option. Possible values include: 'None', 'Always', 'Failure'
   */
  getDebugInfo?: string;
  /**
   * Script path. Type: string (or Expression with resultType string).
   */
  scriptPath?: any;
  /**
   * Script linked service reference.
   */
  scriptLinkedService?: LinkedServiceReference;
  /**
   * Allows user to specify defines for Pig job request.
   */
  defines?: { [propertyName: string]: any };
}

/**
 * HDInsight Hive activity type.
 */
export interface HDInsightHiveActivity extends ExecutionActivity {
  /**
   * Storage linked service references.
   */
  storageLinkedServices?: LinkedServiceReference[];
  /**
   * User specified arguments to HDInsightActivity.
   */
  argumentsProperty?: any[];
  /**
   * Debug info option. Possible values include: 'None', 'Always', 'Failure'
   */
  getDebugInfo?: string;
  /**
   * Script path. Type: string (or Expression with resultType string).
   */
  scriptPath?: any;
  /**
   * Script linked service reference.
   */
  scriptLinkedService?: LinkedServiceReference;
  /**
   * Allows user to specify defines for Hive job request.
   */
  defines?: { [propertyName: string]: any };
  /**
   * User specified arguments under hivevar namespace.
   */
  variables?: any[];
  /**
   * Query timeout value (in minutes).  Effective when the HDInsight cluster is with ESP
   * (Enterprise Security Package)
   */
  queryTimeout?: number;
}

/**
 * Redirect incompatible row settings
 */
export interface RedirectIncompatibleRowSettings {
  /**
   * Name of the Azure Storage, Storage SAS, or Azure Data Lake Store linked service used for
   * redirecting incompatible row. Must be specified if redirectIncompatibleRowSettings is
   * specified. Type: string (or Expression with resultType string).
   */
  linkedServiceName: any;
  /**
   * The path for storing the redirect incompatible row data. Type: string (or Expression with
   * resultType string).
   */
  path?: any;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Staging settings.
 */
export interface StagingSettings {
  /**
   * Staging linked service reference.
   */
  linkedServiceName: LinkedServiceReference;
  /**
   * The path to storage for storing the interim data. Type: string (or Expression with resultType
   * string).
   */
  path?: any;
  /**
   * Specifies whether to use compression when copying data via an interim staging. Default value
   * is false. Type: boolean (or Expression with resultType boolean).
   */
  enableCompression?: any;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A copy activity translator.
 */
export interface CopyTranslator {
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A copy activity tabular translator.
 */
export interface TabularTranslator extends CopyTranslator {
  /**
   * Column mappings. Example: "UserId: MyUserId, Group: MyGroup, Name: MyName" Type: string (or
   * Expression with resultType string).
   */
  columnMappings?: any;
  /**
   * The schema mapping to map between tabular data and hierarchical data. Example: {"Column1":
   * "$.Column1", "Column2": "$.Column2.Property1", "Column3": "$.Column2.Property2"}. Type: object
   * (or Expression with resultType object).
   */
  schemaMapping?: any;
}

/**
 * A copy activity sink.
 */
export interface CopySink {
  /**
   * Write batch size. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  writeBatchSize?: any;
  /**
   * Write batch timeout. Type: string (or Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  writeBatchTimeout?: any;
  /**
   * Sink retry count. Type: integer (or Expression with resultType integer).
   */
  sinkRetryCount?: any;
  /**
   * Sink retry wait. Type: string (or Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  sinkRetryWait?: any;
  /**
   * Polymorphic Discriminator
   */
  type: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A copy activity Salesforce sink.
 */
export interface SalesforceSink extends CopySink {
  /**
   * The write behavior for the operation. Default is Insert. Possible values include: 'Insert',
   * 'Upsert'
   */
  writeBehavior?: string;
  /**
   * The name of the external ID field for upsert operation. Default value is 'Id' column. Type:
   * string (or Expression with resultType string).
   */
  externalIdFieldName?: any;
  /**
   * The flag indicating whether or not to ignore null values from input dataset (except key
   * fields) during write operation. Default value is false. If set it to true, it means ADF will
   * leave the data in the destination object unchanged when doing upsert/update operation and
   * insert defined default value when doing insert operation, versus ADF will update the data in
   * the destination object to NULL when doing upsert/update operation and insert NULL value when
   * doing insert operation. Type: boolean (or Expression with resultType boolean).
   */
  ignoreNullValues?: any;
}

/**
 * A copy activity Dynamics sink.
 */
export interface DynamicsSink extends CopySink {
  /**
   * The flag indicating whether ignore null values from input dataset (except key fields) during
   * write operation. Default is false. Type: boolean (or Expression with resultType boolean).
   */
  ignoreNullValues?: any;
}

/**
 * A copy activity ODBC sink.
 */
export interface OdbcSink extends CopySink {
  /**
   * A query to execute before starting the copy. Type: string (or Expression with resultType
   * string).
   */
  preCopyScript?: any;
}

/**
 * A copy activity Azure Search Index sink.
 */
export interface AzureSearchIndexSink extends CopySink {
  /**
   * Specify the write behavior when upserting documents into Azure Search Index. Possible values
   * include: 'Merge', 'Upload'
   */
  writeBehavior?: string;
}

/**
 * A copy activity Azure Data Lake Store sink.
 */
export interface AzureDataLakeStoreSink extends CopySink {
  /**
   * The type of copy behavior for copy sink. Possible values include: 'PreserveHierarchy',
   * 'FlattenHierarchy', 'MergeFiles'
   */
  copyBehavior?: string;
}

/**
 * A copy activity Oracle sink.
 */
export interface OracleSink extends CopySink {
  /**
   * SQL pre-copy script. Type: string (or Expression with resultType string).
   */
  preCopyScript?: any;
}

/**
 * PolyBase settings.
 */
export interface PolybaseSettings {
  /**
   * Reject type. Possible values include: 'value', 'percentage'
   */
  rejectType?: string;
  /**
   * Specifies the value or the percentage of rows that can be rejected before the query fails.
   * Type: number (or Expression with resultType number), minimum: 0.
   */
  rejectValue?: any;
  /**
   * Determines the number of rows to attempt to retrieve before the PolyBase recalculates the
   * percentage of rejected rows. Type: integer (or Expression with resultType integer), minimum:
   * 0.
   */
  rejectSampleValue?: any;
  /**
   * Specifies how to handle missing values in delimited text files when PolyBase retrieves data
   * from the text file. Type: boolean (or Expression with resultType boolean).
   */
  useTypeDefault?: any;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * A copy activity SQL Data Warehouse sink.
 */
export interface SqlDWSink extends CopySink {
  /**
   * SQL pre-copy script. Type: string (or Expression with resultType string).
   */
  preCopyScript?: any;
  /**
   * Indicates to use PolyBase to copy data into SQL Data Warehouse when applicable. Type: boolean
   * (or Expression with resultType boolean).
   */
  allowPolyBase?: any;
  /**
   * Specifies PolyBase-related settings when allowPolyBase is true.
   */
  polyBaseSettings?: PolybaseSettings;
}

/**
 * A copy activity SQL sink.
 */
export interface SqlSink extends CopySink {
  /**
   * SQL writer stored procedure name. Type: string (or Expression with resultType string).
   */
  sqlWriterStoredProcedureName?: any;
  /**
   * SQL writer table type. Type: string (or Expression with resultType string).
   */
  sqlWriterTableType?: any;
  /**
   * SQL pre-copy script. Type: string (or Expression with resultType string).
   */
  preCopyScript?: any;
  /**
   * SQL stored procedure parameters.
   */
  storedProcedureParameters?: { [propertyName: string]: StoredProcedureParameter };
}

/**
 * A copy activity Document Database Collection sink.
 */
export interface DocumentDbCollectionSink extends CopySink {
  /**
   * Nested properties separator. Default is . (dot). Type: string (or Expression with resultType
   * string).
   */
  nestingSeparator?: any;
}

/**
 * A copy activity file system sink.
 */
export interface FileSystemSink extends CopySink {
  /**
   * The type of copy behavior for copy sink. Possible values include: 'PreserveHierarchy',
   * 'FlattenHierarchy', 'MergeFiles'
   */
  copyBehavior?: string;
}

/**
 * A copy activity Azure Blob sink.
 */
export interface BlobSink extends CopySink {
  /**
   * Blob writer overwrite files. Type: boolean (or Expression with resultType boolean).
   */
  blobWriterOverwriteFiles?: any;
  /**
   * Blob writer date time format. Type: string (or Expression with resultType string).
   */
  blobWriterDateTimeFormat?: any;
  /**
   * Blob writer add header. Type: boolean (or Expression with resultType boolean).
   */
  blobWriterAddHeader?: any;
  /**
   * The type of copy behavior for copy sink. Possible values include: 'PreserveHierarchy',
   * 'FlattenHierarchy', 'MergeFiles'
   */
  copyBehavior?: string;
}

/**
 * A copy activity Azure Table sink.
 */
export interface AzureTableSink extends CopySink {
  /**
   * Azure Table default partition key value. Type: string (or Expression with resultType string).
   */
  azureTableDefaultPartitionKeyValue?: any;
  /**
   * Azure Table partition key name. Type: string (or Expression with resultType string).
   */
  azureTablePartitionKeyName?: any;
  /**
   * Azure Table row key name. Type: string (or Expression with resultType string).
   */
  azureTableRowKeyName?: any;
  /**
   * Azure Table insert type. Type: string (or Expression with resultType string).
   */
  azureTableInsertType?: any;
}

/**
 * A copy activity Azure Queue sink.
 */
export interface AzureQueueSink extends CopySink {
}

/**
 * A copy activity SAP Cloud for Customer sink.
 */
export interface SapCloudForCustomerSink extends CopySink {
  /**
   * The write behavior for the operation. Default is 'Insert'. Possible values include: 'Insert',
   * 'Update'
   */
  writeBehavior?: string;
}

/**
 * Copy activity.
 */
export interface CopyActivity extends ExecutionActivity {
  /**
   * Copy activity source.
   */
  source: CopySource;
  /**
   * Copy activity sink.
   */
  sink: CopySink;
  /**
   * Copy activity translator. If not specified, tabular translator is used.
   */
  translator?: CopyTranslator;
  /**
   * Specifies whether to copy data via an interim staging. Default value is false. Type: boolean
   * (or Expression with resultType boolean).
   */
  enableStaging?: any;
  /**
   * Specifies interim staging settings when EnableStaging is true.
   */
  stagingSettings?: StagingSettings;
  /**
   * Maximum number of concurrent sessions opened on the source or sink to avoid overloading the
   * data store. Type: integer (or Expression with resultType integer), minimum: 0.
   */
  parallelCopies?: any;
  /**
   * Maximum number of data integration units that can be used to perform this data movement. Type:
   * integer (or Expression with resultType integer), minimum: 0.
   */
  dataIntegrationUnits?: any;
  /**
   * Whether to skip incompatible row. Default value is false. Type: boolean (or Expression with
   * resultType boolean).
   */
  enableSkipIncompatibleRow?: any;
  /**
   * Redirect incompatible row settings when EnableSkipIncompatibleRow is true.
   */
  redirectIncompatibleRowSettings?: RedirectIncompatibleRowSettings;
  /**
   * List of inputs for the activity.
   */
  inputs?: DatasetReference[];
  /**
   * List of outputs for the activity.
   */
  outputs?: DatasetReference[];
}

/**
 * Base class for all control activities like IfCondition, ForEach , Until.
 */
export interface ControlActivity extends Activity {
}

/**
 * Append value for a Variable of type Array.
 */
export interface AppendVariableActivity extends ControlActivity {
  /**
   * Name of the variable whose value needs to be appended to.
   */
  variableName?: string;
  /**
   * Value to be appended. Could be a static value or Expression
   */
  value?: any;
}

/**
 * Set value for a Variable.
 */
export interface SetVariableActivity extends ControlActivity {
  /**
   * Name of the variable whose value needs to be set.
   */
  variableName?: string;
  /**
   * Value to be set. Could be a static value or Expression
   */
  value?: any;
}

/**
 * Filter and return results from input array based on the conditions.
 */
export interface FilterActivity extends ControlActivity {
  /**
   * Input array on which filter should be applied.
   */
  items: Expression;
  /**
   * Condition to be used for filtering the input.
   */
  condition: Expression;
}

/**
 * This activity executes inner activities until the specified boolean expression results to true
 * or timeout is reached, whichever is earlier.
 */
export interface UntilActivity extends ControlActivity {
  /**
   * An expression that would evaluate to Boolean. The loop will continue until this expression
   * evaluates to true
   */
  expression: Expression;
  /**
   * Specifies the timeout for the activity to run. If there is no value specified, it takes the
   * value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or Expression with
   * resultType string), pattern: ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type:
   * string (or Expression with resultType string), pattern:
   * ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
   */
  timeout?: any;
  /**
   * List of activities to execute.
   */
  activities: Activity[];
}

/**
 * This activity suspends pipeline execution for the specified interval.
 */
export interface WaitActivity extends ControlActivity {
  /**
   * Duration in seconds.
   */
  waitTimeInSeconds: number;
}

/**
 * This activity is used for iterating over a collection and execute given activities.
 */
export interface ForEachActivity extends ControlActivity {
  /**
   * Should the loop be executed in sequence or in parallel (max 50)
   */
  isSequential?: boolean;
  /**
   * Batch count to be used for controlling the number of parallel execution (when isSequential is
   * set to false).
   */
  batchCount?: number;
  /**
   * Collection to iterate.
   */
  items: Expression;
  /**
   * List of activities to execute .
   */
  activities: Activity[];
}

/**
 * This activity evaluates a boolean expression and executes either the activities under the
 * ifTrueActivities property or the ifFalseActivities property depending on the result of the
 * expression.
 */
export interface IfConditionActivity extends ControlActivity {
  /**
   * An expression that would evaluate to Boolean. This is used to determine the block of
   * activities (ifTrueActivities or ifFalseActivities) that will be executed.
   */
  expression: Expression;
  /**
   * List of activities to execute if expression is evaluated to true. This is an optional property
   * and if not provided, the activity will exit without any action.
   */
  ifTrueActivities?: Activity[];
  /**
   * List of activities to execute if expression is evaluated to false. This is an optional
   * property and if not provided, the activity will exit without any action.
   */
  ifFalseActivities?: Activity[];
}

/**
 * Execute pipeline activity.
 */
export interface ExecutePipelineActivity extends ControlActivity {
  /**
   * Pipeline reference.
   */
  pipelineProperty: PipelineReference;
  /**
   * Pipeline parameters.
   */
  parameters?: { [propertyName: string]: any };
  /**
   * Defines whether activity execution will wait for the dependent pipeline execution to finish.
   * Default is false.
   */
  waitOnCompletion?: boolean;
}

/**
 * The linked integration runtime information.
 */
export interface LinkedIntegrationRuntime {
  /**
   * The name of the linked integration runtime.
   */
  readonly name?: string;
  /**
   * The subscription ID for which the linked integration runtime belong to.
   */
  readonly subscriptionId?: string;
  /**
   * The name of the data factory for which the linked integration runtime belong to.
   */
  readonly dataFactoryName?: string;
  /**
   * The location of the data factory for which the linked integration runtime belong to.
   */
  readonly dataFactoryLocation?: string;
  /**
   * The creating time of the linked integration runtime.
   */
  readonly createTime?: Date;
}

/**
 * Properties of Self-hosted integration runtime node.
 */
export interface SelfHostedIntegrationRuntimeNode {
  /**
   * Name of the integration runtime node.
   */
  readonly nodeName?: string;
  /**
   * Machine name of the integration runtime node.
   */
  readonly machineName?: string;
  /**
   * URI for the host machine of the integration runtime.
   */
  readonly hostServiceUri?: string;
  /**
   * Status of the integration runtime node. Possible values include: 'NeedRegistration', 'Online',
   * 'Limited', 'Offline', 'Upgrading', 'Initializing', 'InitializeFailed'
   */
  readonly status?: string;
  /**
   * The integration runtime capabilities dictionary
   */
  readonly capabilities?: { [propertyName: string]: string };
  /**
   * Status of the integration runtime node version.
   */
  readonly versionStatus?: string;
  /**
   * Version of the integration runtime node.
   */
  readonly version?: string;
  /**
   * The time at which the integration runtime node was registered in ISO8601 format.
   */
  readonly registerTime?: Date;
  /**
   * The most recent time at which the integration runtime was connected in ISO8601 format.
   */
  readonly lastConnectTime?: Date;
  /**
   * The time at which the integration runtime will expire in ISO8601 format.
   */
  readonly expiryTime?: Date;
  /**
   * The time the node last started up.
   */
  readonly lastStartTime?: Date;
  /**
   * The integration runtime node last stop time.
   */
  readonly lastStopTime?: Date;
  /**
   * The result of the last integration runtime node update. Possible values include: 'None',
   * 'Succeed', 'Fail'
   */
  readonly lastUpdateResult?: string;
  /**
   * The last time for the integration runtime node update start.
   */
  readonly lastStartUpdateTime?: Date;
  /**
   * The last time for the integration runtime node update end.
   */
  readonly lastEndUpdateTime?: Date;
  /**
   * Indicates whether this node is the active dispatcher for integration runtime requests.
   */
  readonly isActiveDispatcher?: boolean;
  /**
   * Maximum concurrent jobs on the integration runtime node.
   */
  readonly concurrentJobsLimit?: number;
  /**
   * The maximum concurrent jobs in this integration runtime.
   */
  readonly maxConcurrentJobs?: number;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Self-hosted integration runtime status.
 */
export interface SelfHostedIntegrationRuntimeStatus extends IntegrationRuntimeStatus {
  /**
   * The time at which the integration runtime was created, in ISO8601 format.
   */
  readonly createTime?: Date;
  /**
   * The task queue id of the integration runtime.
   */
  readonly taskQueueId?: string;
  /**
   * It is used to set the encryption mode for node-node communication channel (when more than 2
   * self-hosted integration runtime nodes exist). Possible values include: 'NotSet',
   * 'SslEncrypted', 'NotEncrypted'
   */
  readonly internalChannelEncryption?: string;
  /**
   * Version of the integration runtime.
   */
  readonly version?: string;
  /**
   * The list of nodes for this integration runtime.
   */
  nodes?: SelfHostedIntegrationRuntimeNode[];
  /**
   * The date at which the integration runtime will be scheduled to update, in ISO8601 format.
   */
  readonly scheduledUpdateDate?: Date;
  /**
   * The time in the date scheduled by service to update the integration runtime, e.g., PT03H is 3
   * hours
   */
  readonly updateDelayOffset?: string;
  /**
   * The local time zone offset in hours.
   */
  readonly localTimeZoneOffset?: string;
  /**
   * Object with additional information about integration runtime capabilities.
   */
  readonly capabilities?: { [propertyName: string]: string };
  /**
   * The URLs for the services used in integration runtime backend service.
   */
  readonly serviceUrls?: string[];
  /**
   * Whether Self-hosted integration runtime auto update has been turned on. Possible values
   * include: 'On', 'Off'
   */
  readonly autoUpdate?: string;
  /**
   * Status of the integration runtime version.
   */
  readonly versionStatus?: string;
  /**
   * The list of linked integration runtimes that are created to share with this integration
   * runtime.
   */
  links?: LinkedIntegrationRuntime[];
  /**
   * The version that the integration runtime is going to update to.
   */
  readonly pushedVersion?: string;
  /**
   * The latest version on download center.
   */
  readonly latestVersion?: string;
  /**
   * The estimated time when the self-hosted integration runtime will be updated.
   */
  readonly autoUpdateETA?: Date;
}

/**
 * Properties of managed integration runtime operation result.
 */
export interface ManagedIntegrationRuntimeOperationResult {
  /**
   * The operation type. Could be start or stop.
   */
  readonly type?: string;
  /**
   * The start time of the operation.
   */
  readonly startTime?: Date;
  /**
   * The operation result.
   */
  readonly result?: string;
  /**
   * The error code.
   */
  readonly errorCode?: string;
  /**
   * Managed integration runtime error parameters.
   */
  readonly parameters?: string[];
  /**
   * The activity id for the operation request.
   */
  readonly activityId?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Error definition for managed integration runtime.
 */
export interface ManagedIntegrationRuntimeError {
  /**
   * The time when the error occurred.
   */
  readonly time?: Date;
  /**
   * Error code.
   */
  readonly code?: string;
  /**
   * Managed integration runtime error parameters.
   */
  readonly parameters?: string[];
  /**
   * Error message.
   */
  readonly message?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Properties of integration runtime node.
 */
export interface ManagedIntegrationRuntimeNode {
  /**
   * The managed integration runtime node id.
   */
  readonly nodeId?: string;
  /**
   * The managed integration runtime node status. Possible values include: 'Starting', 'Available',
   * 'Recycling', 'Unavailable'
   */
  readonly status?: string;
  /**
   * The errors that occurred on this integration runtime node.
   */
  errors?: ManagedIntegrationRuntimeError[];
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
   */
  [additionalPropertyName: string]: any;
}

/**
 * Managed integration runtime status.
 */
export interface ManagedIntegrationRuntimeStatus extends IntegrationRuntimeStatus {
  /**
   * The time at which the integration runtime was created, in ISO8601 format.
   */
  readonly createTime?: Date;
  /**
   * The list of nodes for managed integration runtime.
   */
  readonly nodes?: ManagedIntegrationRuntimeNode[];
  /**
   * The errors that occurred on this integration runtime.
   */
  readonly otherErrors?: ManagedIntegrationRuntimeError[];
  /**
   * The last operation result that occurred on this integration runtime.
   */
  readonly lastOperation?: ManagedIntegrationRuntimeOperationResult;
}

/**
 * The base definition of a linked integration runtime.
 */
export interface LinkedIntegrationRuntimeType {
  /**
   * Polymorphic Discriminator
   */
  authorizationType: string;
}

/**
 * The role based access control (RBAC) authorization type integration runtime.
 */
export interface LinkedIntegrationRuntimeRbacAuthorization extends LinkedIntegrationRuntimeType {
  /**
   * The resource identifier of the integration runtime to be shared.
   */
  resourceId: string;
}

/**
 * The key authorization type integration runtime.
 */
export interface LinkedIntegrationRuntimeKeyAuthorization extends LinkedIntegrationRuntimeType {
  /**
   * The key used for authorization.
   */
  key: SecureString;
}

/**
 * Self-hosted integration runtime.
 */
export interface SelfHostedIntegrationRuntime extends IntegrationRuntime {
  linkedInfo?: LinkedIntegrationRuntimeType;
}

/**
 * Custom setup script properties for a managed dedicated integration runtime.
*/
export interface IntegrationRuntimeCustomSetupScriptProperties {
  /**
   * The URI of the Azure blob container that contains the custom setup script.
  */
  blobContainerUri?: string;
  /**
   * The SAS token of the Azure blob container.
  */
  sasToken?: SecureString;
}

/**
 * Catalog information for managed dedicated integration runtime.
*/
export interface IntegrationRuntimeSsisCatalogInfo {
  /**
   * The catalog database server URL.
  */
  catalogServerEndpoint?: string;
  /**
   * The administrator user name of catalog database.
  */
  catalogAdminUserName?: string;
  /**
   * The password of the administrator user account of the catalog database.
  */
  catalogAdminPassword?: SecureString;
  /**
   * The pricing tier for the catalog database. The valid values could be found in
   * https://azure.microsoft.com/en-us/pricing/details/sql-database/. Possible values include:
   * 'Basic', 'Standard', 'Premium', 'PremiumRS'
  */
  catalogPricingTier?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * SSIS properties for managed integration runtime.
*/
export interface IntegrationRuntimeSsisProperties {
  /**
   * Catalog information for managed dedicated integration runtime.
  */
  catalogInfo?: IntegrationRuntimeSsisCatalogInfo;
  /**
   * License type for bringing your own license scenario. Possible values include: 'BasePrice',
   * 'LicenseIncluded'
  */
  licenseType?: string;
  /**
   * Custom setup script properties for a managed dedicated integration runtime.
  */
  customSetupScriptProperties?: IntegrationRuntimeCustomSetupScriptProperties;
  /**
   * The edition for the SSIS Integration Runtime. Possible values include: 'Standard',
   * 'Enterprise'
  */
  edition?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * VNet properties for managed integration runtime.
*/
export interface IntegrationRuntimeVNetProperties {
  /**
   * The ID of the VNet that this integration runtime will join.
  */
  vNetId?: string;
  /**
   * The name of the subnet this integration runtime will join.
  */
  subnet?: string;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * The compute resource properties for managed integration runtime.
*/
export interface IntegrationRuntimeComputeProperties {
  /**
   * The location for managed integration runtime. The supported regions could be found on
   * https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-movement-activities
  */
  location?: string;
  /**
   * The node size requirement to managed integration runtime.
  */
  nodeSize?: string;
  /**
   * The required number of nodes for managed integration runtime.
  */
  numberOfNodes?: number;
  /**
   * Maximum parallel executions count per node for managed integration runtime.
  */
  maxParallelExecutionsPerNode?: number;
  /**
   * VNet properties for managed integration runtime.
  */
  vNetProperties?: IntegrationRuntimeVNetProperties;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * Managed integration runtime, including managed elastic and managed dedicated integration
 * runtimes.
*/
export interface ManagedIntegrationRuntime extends IntegrationRuntime {
  /**
   * Integration runtime state, only valid for managed dedicated integration runtime. Possible
   * values include: 'Initial', 'Stopped', 'Started', 'Starting', 'Stopping', 'NeedRegistration',
   * 'Online', 'Limited', 'Offline', 'AccessDenied'
  */
  readonly state?: string;
  /**
   * The compute resource for managed integration runtime.
  */
  computeProperties?: IntegrationRuntimeComputeProperties;
  /**
   * SSIS properties for managed integration runtime.
  */
  ssisProperties?: IntegrationRuntimeSsisProperties;
}

/**
 * The IP address of self-hosted integration runtime node.
*/
export interface IntegrationRuntimeNodeIpAddress {
  /**
   * The IP address of self-hosted integration runtime node.
  */
  readonly ipAddress?: string;
}

/**
 * SSIS object metadata.
*/
export interface SsisObjectMetadata {
  /**
   * Metadata id.
  */
  id?: number;
  /**
   * Metadata name.
  */
  name?: string;
  /**
   * Metadata description.
  */
  description?: string;
  /**
   * Polymorphic Discriminator
  */
  type: string;
}

/**
 * A list of SSIS object metadata.
*/
export interface SsisObjectMetadataListResponse {
  /**
   * List of SSIS object metadata.
  */
  value?: SsisObjectMetadata[];
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * Monitoring data for integration runtime node.
*/
export interface IntegrationRuntimeNodeMonitoringData {
  /**
   * Name of the integration runtime node.
  */
  readonly nodeName?: string;
  /**
   * Available memory (MB) on the integration runtime node.
  */
  readonly availableMemoryInMB?: number;
  /**
   * CPU percentage on the integration runtime node.
  */
  readonly cpuUtilization?: number;
  /**
   * Maximum concurrent jobs on the integration runtime node.
  */
  readonly concurrentJobsLimit?: number;
  /**
   * The number of jobs currently running on the integration runtime node.
  */
  readonly concurrentJobsRunning?: number;
  /**
   * The maximum concurrent jobs in this integration runtime.
  */
  readonly maxConcurrentJobs?: number;
  /**
   * Sent bytes on the integration runtime node.
  */
  readonly sentBytes?: number;
  /**
   * Received bytes on the integration runtime node.
  */
  readonly receivedBytes?: number;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * Get monitoring data response.
*/
export interface IntegrationRuntimeMonitoringData {
  /**
   * Integration runtime name.
  */
  name?: string;
  /**
   * Integration runtime node monitoring data.
  */
  nodes?: IntegrationRuntimeNodeMonitoringData[];
}

/**
 * The integration runtime authentication keys.
*/
export interface IntegrationRuntimeAuthKeys {
  /**
   * The primary integration runtime authentication key.
  */
  authKey1?: string;
  /**
   * The secondary integration runtime authentication key.
  */
  authKey2?: string;
}

/**
 * Parameters to regenerate the authentication key.
*/
export interface IntegrationRuntimeRegenerateKeyParameters {
  /**
   * The name of the authentication key to regenerate. Possible values include: 'authKey1',
   * 'authKey2'
  */
  keyName?: string;
}

/**
 * Connection information for encrypting the on-premises data source credentials.
*/
export interface IntegrationRuntimeConnectionInfo {
  /**
   * The token generated in service. Callers use this token to authenticate to integration runtime.
  */
  readonly serviceToken?: string;
  /**
   * The integration runtime SSL certificate thumbprint. Click-Once application uses it to do
   * server validation.
  */
  readonly identityCertThumbprint?: string;
  /**
   * The on-premises integration runtime host URL.
  */
  readonly hostServiceUri?: string;
  /**
   * The integration runtime version.
  */
  readonly version?: string;
  /**
   * The public key for encrypting a credential when transferring the credential to the integration
   * runtime.
  */
  readonly publicKey?: string;
  /**
   * Whether the identity certificate is expired.
  */
  readonly isIdentityCertExprired?: boolean;
  /**
   * Describes unknown properties. The value of an unknown property can be of "any" type.
  */
  [additionalPropertyName: string]: any;
}

/**
 * A list of operations that can be performed by the Data Factory service.
*/
export interface OperationListResponse extends Array<Operation> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of factory resources.
*/
export interface FactoryListResponse extends Array<Factory> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of integration runtime resources.
*/
export interface IntegrationRuntimeListResponse extends Array<IntegrationRuntimeResource> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of linked service resources.
*/
export interface LinkedServiceListResponse extends Array<LinkedServiceResource> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of dataset resources.
*/
export interface DatasetListResponse extends Array<DatasetResource> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of pipeline resources.
*/
export interface PipelineListResponse extends Array<PipelineResource> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of trigger resources.
*/
export interface TriggerListResponse extends Array<TriggerResource> {
  /**
   * The link to the next page of results, if any remaining results exist.
  */
  nextLink?: string;
}

/**
 * A list of rerun triggers.
*/
export interface RerunTriggerListResponse extends Array<RerunTriggerResource> {
  /**
   * The continuation token for getting the next page of results, if any remaining results exist,
   * null otherwise.
  */
  readonly nextLink?: string;
}
