/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

const models = require('./index');

/**
 * @summary A job schedule that allows recurring jobs by specifying when to run
 * jobs and a specification used to create each job.
  *
 */
class CloudJobSchedule {
  /**
   * Create a CloudJobSchedule.
   * @member {string} [id] A string that uniquely identifies the schedule
   * within the account.
   * @member {string} [displayName] The display name for the schedule.
   * @member {string} [url] The URL of the job schedule.
   * @member {string} [eTag] The ETag of the job schedule. This is an opaque
   * string. You can use it to detect whether the job schedule has changed
   * between requests. In particular, you can be pass the ETag with an Update
   * Job Schedule request to specify that your changes should take effect only
   * if nobody else has modified the schedule in the meantime.
   * @member {date} [lastModified] The last modified time of the job schedule.
   * This is the last time at which the schedule level data, such as the job
   * specification or recurrence information, changed. It does not factor in
   * job-level changes such as new jobs being created or jobs changing state.
   * @member {date} [creationTime] The creation time of the job schedule.
   * @member {string} [state] The current state of the job schedule. Possible
   * values include: 'active', 'completed', 'disabled', 'terminating',
   * 'deleting'
   * @member {date} [stateTransitionTime] The time at which the job schedule
   * entered the current state.
   * @member {string} [previousState] The previous state of the job schedule.
   * This property is not present if the job schedule is in its initial active
   * state. Possible values include: 'active', 'completed', 'disabled',
   * 'terminating', 'deleting'
   * @member {date} [previousStateTransitionTime] The time at which the job
   * schedule entered its previous state. This property is not present if the
   * job schedule is in its initial active state.
   * @member {object} [schedule] The schedule according to which jobs will be
   * created.
   * @member {date} [schedule.doNotRunUntil] If you do not specify a
   * doNotRunUntil time, the schedule becomes ready to create jobs immediately.
   * @member {date} [schedule.doNotRunAfter] If you do not specify a
   * doNotRunAfter time, and you are creating a recurring job schedule, the job
   * schedule will remain active until you explicitly terminate it.
   * @member {moment.duration} [schedule.startWindow] If a job is not created
   * within the startWindow interval, then the 'opportunity' is lost; no job
   * will be created until the next recurrence of the schedule. If the schedule
   * is recurring, and the startWindow is longer than the recurrence interval,
   * then this is equivalent to an infinite startWindow, because the job that
   * is 'due' in one recurrenceInterval is not carried forward into the next
   * recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @member {moment.duration} [schedule.recurrenceInterval] Because a job
   * schedule can have at most one active job under it at any given time, if it
   * is time to create a new job under a job schedule, but the previous job is
   * still running, the Batch service will not create the new job until the
   * previous job finishes. If the previous job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new job will be
   * scheduled for that interval. For recurring jobs, you should normally
   * specify a jobManagerTask in the jobSpecification. If you do not use
   * jobManagerTask, you will need an external process to monitor when jobs are
   * created, add tasks to the jobs and terminate the jobs ready for the next
   * recurrence. The default is that the schedule does not recur: one job is
   * created, within the startWindow after the doNotRunUntil time, and the
   * schedule is complete as soon as that job finishes. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @member {object} [jobSpecification] The details of the jobs to be created
   * on this schedule.
   * @member {number} [jobSpecification.priority] Priority values can range
   * from -1000 to 1000, with -1000 being the lowest priority and 1000 being
   * the highest priority. The default value is 0. This priority is used as the
   * default for all jobs under the job schedule. You can update a job's
   * priority after it has been created using by using the update job API.
   * @member {string} [jobSpecification.displayName] The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   * @member {boolean} [jobSpecification.usesTaskDependencies]
   * @member {string} [jobSpecification.onAllTasksComplete] Note that if a job
   * contains no tasks, then all tasks are considered complete. This option is
   * therefore most commonly used with a Job Manager task; if you want to use
   * automatic job termination without a Job Manager, you should initially set
   * onAllTasksComplete to noAction and update the job properties to set
   * onAllTasksComplete to terminateJob once you have finished adding tasks.
   * The default is noAction. Possible values include: 'noAction',
   * 'terminateJob'
   * @member {string} [jobSpecification.onTaskFailure] The default is noAction.
   * Possible values include: 'noAction', 'performExitOptionsJobAction'
   * @member {object} [jobSpecification.constraints]
   * @member {moment.duration} [jobSpecification.constraints.maxWallClockTime]
   * If the job does not complete within the time limit, the Batch service
   * terminates it and any tasks that are still running. In this case, the
   * termination reason will be MaxWallClockTimeExpiry. If this property is not
   * specified, there is no time limit on how long the job may run.
   * @member {number} [jobSpecification.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries. The Batch
   * service will try each task once, and may then retry up to this limit. For
   * example, if the maximum retry count is 3, Batch tries a task up to 4 times
   * (one initial try and 3 retries). If the maximum retry count is 0, the
   * Batch service does not retry tasks. If the maximum retry count is -1, the
   * Batch service retries tasks without limit. The default value is 0 (no
   * retries).
   * @member {object} [jobSpecification.jobManagerTask] If the job does not
   * specify a Job Manager task, the user must explicitly add tasks to the job
   * using the Task API. If the job does specify a Job Manager task, the Batch
   * service creates the Job Manager task when the job is created, and will try
   * to schedule the Job Manager task before scheduling other tasks in the job.
   * @member {string} [jobSpecification.jobManagerTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters.
   * @member {string} [jobSpecification.jobManagerTask.displayName] It need not
   * be unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   * @member {string} [jobSpecification.jobManagerTask.commandLine] The command
   * line does not run under a shell, and therefore cannot take advantage of
   * shell features such as environment variable expansion. If you want to take
   * advantage of such features, you should invoke the shell in the command
   * line, for example using "cmd /c MyCommand" in Windows or "/bin/sh -c
   * MyCommand" in Linux.
   * @member {object} [jobSpecification.jobManagerTask.containerSettings] If
   * the pool that will run this task has containerConfiguration set, this must
   * be set as well. If the pool that will run this task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all
   * task environment variables are mapped into the container, and the task
   * command line is executed in the container.
   * @member {string}
   * [jobSpecification.jobManagerTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @member {string}
   * [jobSpecification.jobManagerTask.containerSettings.imageName] This is the
   * full image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @member {object}
   * [jobSpecification.jobManagerTask.containerSettings.registry] This setting
   * can be omitted if was already provided at pool creation.
   * @member {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @member {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.userName]
   * @member {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.password]
   * @member {array} [jobSpecification.jobManagerTask.resourceFiles] Files
   * listed under this element are located in the task's working directory.
   * @member {array} [jobSpecification.jobManagerTask.outputFiles] For
   * multi-instance tasks, the files will only be uploaded from the compute
   * node on which the primary task is executed.
   * @member {array} [jobSpecification.jobManagerTask.environmentSettings]
   * @member {object} [jobSpecification.jobManagerTask.constraints]
   * @member {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.maxWallClockTime] If this is
   * not specified, there is no time limit on how long the task may run.
   * @member {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.retentionTime] The default is
   * infinite, i.e. the task directory will be retained until the compute node
   * is removed or reimaged.
   * @member {number}
   * [jobSpecification.jobManagerTask.constraints.maxTaskRetryCount] Note that
   * this value specifically controls the number of retries. The Batch service
   * will try the task once, and may then retry up to this limit. For example,
   * if the maximum retry count is 3, Batch tries the task up to 4 times (one
   * initial try and 3 retries). If the maximum retry count is 0, the Batch
   * service does not retry the task. If the maximum retry count is -1, the
   * Batch service retries the task without limit.
   * @member {boolean} [jobSpecification.jobManagerTask.killJobOnCompletion] If
   * true, when the Job Manager task completes, the Batch service marks the job
   * as complete. If any tasks are still running at this time (other than Job
   * Release), those tasks are terminated. If false, the completion of the Job
   * Manager task does not affect the job status. In this case, you should
   * either use the onAllTasksComplete attribute to terminate the job, or have
   * a client or user terminate the job explicitly. An example of this is if
   * the Job Manager creates a set of tasks but then takes no further role in
   * their execution. The default value is true. If you are using the
   * onAllTasksComplete and onTaskFailure attributes to control job lifetime,
   * and using the Job Manager task only to create the tasks for the job (not
   * to monitor progress), then it is important to set killJobOnCompletion to
   * false.
   * @member {object} [jobSpecification.jobManagerTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task.
   * @member {string} [jobSpecification.jobManagerTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {object} [jobSpecification.jobManagerTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.scope] Values are:
   *
   * pool - specifies that the task runs as the common auto user account which
   * is created on every node in a pool.
   * task - specifies that the service should create a new user for the task.
   * The default value is task. Possible values include: 'task', 'pool'
   * @member {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.elevationLevel]
   * nonAdmin - The auto user is a standard user without elevated access. admin
   * - The auto user is a user with elevated access and operates with full
   * Administrator permissions. The default value is nonAdmin. Possible values
   * include: 'nonAdmin', 'admin'
   * @member {boolean} [jobSpecification.jobManagerTask.runExclusive] If true,
   * no other tasks will run on the same compute node for as long as the Job
   * Manager is running. If false, other tasks can run simultaneously with the
   * Job Manager on a compute node. The Job Manager task counts normally
   * against the node's concurrent task limit, so this is only relevant if the
   * node allows multiple concurrent tasks. The default value is true.
   * @member {array}
   * [jobSpecification.jobManagerTask.applicationPackageReferences] Application
   * packages are downloaded and deployed to a shared directory, not the task
   * working directory. Therefore, if a referenced package is already on the
   * compute node, and is up to date, then it is not re-downloaded; the
   * existing copy on the compute node is used. If a referenced application
   * package cannot be installed, for example because the package has been
   * deleted or because download failed, the task fails.
   * @member {object}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings] If this
   * property is set, the Batch service provides the task with an
   * authentication token which can be used to authenticate Batch service
   * operations without requiring an account access key. The token is provided
   * via the AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations
   * that the task can carry out using the token depend on the settings. For
   * example, a task can request job permissions in order to add other tasks to
   * the job, or check the status of the job or of other tasks under the job.
   * @member {array}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings.access] The
   * authentication token grants access to a limited set of Batch service
   * operations. Currently the only supported value for the access property is
   * 'job', which grants access to all operations related to the job which
   * contains the task.
   * @member {boolean} [jobSpecification.jobManagerTask.allowLowPriorityNode]
   * The default value is false.
   * @member {object} [jobSpecification.jobPreparationTask] If a job has a Job
   * Preparation task, the Batch service will run the Job Preparation task on a
   * compute node before starting any tasks of that job on that compute node.
   * @member {string} [jobSpecification.jobPreparationTask.id] The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other task in the job can have the same ID as the Job
   * Preparation task. If you try to submit a task with the same id, the Batch
   * service rejects the request with error code
   * TaskIdSameAsJobPreparationTask; if you are calling the REST API directly,
   * the HTTP status code is 409 (Conflict).
   * @member {string} [jobSpecification.jobPreparationTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux.
   * @member {object} [jobSpecification.jobPreparationTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @member {string}
   * [jobSpecification.jobPreparationTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @member {string}
   * [jobSpecification.jobPreparationTask.containerSettings.imageName] This is
   * the full image reference, as would be specified to "docker pull". If no
   * tag is provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @member {object}
   * [jobSpecification.jobPreparationTask.containerSettings.registry] This
   * setting can be omitted if was already provided at pool creation.
   * @member {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @member {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.userName]
   * @member {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.password]
   * @member {array} [jobSpecification.jobPreparationTask.resourceFiles] Files
   * listed under this element are located in the task's working directory.
   * @member {array} [jobSpecification.jobPreparationTask.environmentSettings]
   * @member {object} [jobSpecification.jobPreparationTask.constraints]
   * @member {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.maxWallClockTime] If this
   * is not specified, there is no time limit on how long the task may run.
   * @member {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.retentionTime] The
   * default is infinite, i.e. the task directory will be retained until the
   * compute node is removed or reimaged.
   * @member {number}
   * [jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries. The Batch
   * service will try the task once, and may then retry up to this limit. For
   * example, if the maximum retry count is 3, Batch tries the task up to 4
   * times (one initial try and 3 retries). If the maximum retry count is 0,
   * the Batch service does not retry the task. If the maximum retry count is
   * -1, the Batch service retries the task without limit.
   * @member {boolean} [jobSpecification.jobPreparationTask.waitForSuccess] If
   * true and the Job Preparation task fails on a compute node, the Batch
   * service retries the Job Preparation task up to its maximum retry count (as
   * specified in the constraints element). If the task has still not completed
   * successfully after all retries, then the Batch service will not schedule
   * tasks of the job to the compute node. The compute node remains active and
   * eligible to run tasks of other jobs. If false, the Batch service will not
   * wait for the Job Preparation task to complete. In this case, other tasks
   * of the job can start executing on the compute node while the Job
   * Preparation task is still running; and even if the Job Preparation task
   * fails, new tasks will continue to be scheduled on the node. The default
   * value is true.
   * @member {object} [jobSpecification.jobPreparationTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task on
   * Windows nodes, or a a non-administrative user unique to the pool on Linux
   * nodes.
   * @member {string}
   * [jobSpecification.jobPreparationTask.userIdentity.userName] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @member {object}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @member {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.scope] Values
   * are:
   *
   * pool - specifies that the task runs as the common auto user account which
   * is created on every node in a pool.
   * task - specifies that the service should create a new user for the task.
   * The default value is task. Possible values include: 'task', 'pool'
   * @member {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.elevationLevel]
   * nonAdmin - The auto user is a standard user without elevated access. admin
   * - The auto user is a user with elevated access and operates with full
   * Administrator permissions. The default value is nonAdmin. Possible values
   * include: 'nonAdmin', 'admin'
   * @member {boolean}
   * [jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess] The
   * Job Preparation task is always rerun if a compute node is reimaged, or if
   * the Job Preparation task did not complete (e.g. because the reboot
   * occurred while the task was running). Therefore, you should always write a
   * Job Preparation task to be idempotent and to behave correctly if run
   * multiple times. The default value is true.
   * @member {object} [jobSpecification.jobReleaseTask] The primary purpose of
   * the Job Release task is to undo changes to compute nodes made by the Job
   * Preparation task. Example activities include deleting local files, or
   * shutting down services that were started as part of job preparation. A Job
   * Release task cannot be specified without also specifying a Job Preparation
   * task for the job. The Batch service runs the Job Release task on the
   * compute nodes that have run the Job Preparation task.
   * @member {string} [jobSpecification.jobReleaseTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other task in the job can have the same ID as the Job
   * Release task. If you try to submit a task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   * @member {string} [jobSpecification.jobReleaseTask.commandLine] The command
   * line does not run under a shell, and therefore cannot take advantage of
   * shell features such as environment variable expansion. If you want to take
   * advantage of such features, you should invoke the shell in the command
   * line, for example using "cmd /c MyCommand" in Windows or "/bin/sh -c
   * MyCommand" in Linux.
   * @member {object} [jobSpecification.jobReleaseTask.containerSettings] When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @member {string}
   * [jobSpecification.jobReleaseTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @member {string}
   * [jobSpecification.jobReleaseTask.containerSettings.imageName] This is the
   * full image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @member {object}
   * [jobSpecification.jobReleaseTask.containerSettings.registry] This setting
   * can be omitted if was already provided at pool creation.
   * @member {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @member {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.userName]
   * @member {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.password]
   * @member {array} [jobSpecification.jobReleaseTask.resourceFiles] Files
   * listed under this element are located in the task's working directory.
   * @member {array} [jobSpecification.jobReleaseTask.environmentSettings]
   * @member {moment.duration}
   * [jobSpecification.jobReleaseTask.maxWallClockTime]
   * @member {moment.duration} [jobSpecification.jobReleaseTask.retentionTime]
   * The default is infinite, i.e. the task directory will be retained until
   * the compute node is removed or reimaged.
   * @member {object} [jobSpecification.jobReleaseTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task.
   * @member {string} [jobSpecification.jobReleaseTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {object} [jobSpecification.jobReleaseTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.scope] Values are:
   *
   * pool - specifies that the task runs as the common auto user account which
   * is created on every node in a pool.
   * task - specifies that the service should create a new user for the task.
   * The default value is task. Possible values include: 'task', 'pool'
   * @member {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.elevationLevel]
   * nonAdmin - The auto user is a standard user without elevated access. admin
   * - The auto user is a user with elevated access and operates with full
   * Administrator permissions. The default value is nonAdmin. Possible values
   * include: 'nonAdmin', 'admin'
   * @member {array} [jobSpecification.commonEnvironmentSettings] Individual
   * tasks can override an environment setting specified here by specifying the
   * same setting name with a different value.
   * @member {object} [jobSpecification.poolInfo]
   * @member {string} [jobSpecification.poolInfo.poolId] You must ensure that
   * the pool referenced by this property exists. If the pool does not exist at
   * the time the Batch service tries to schedule a job, no tasks for the job
   * will run until you create a pool with that id. Note that the Batch service
   * will not reject the job request; it will simply not run tasks until the
   * pool exists. You must specify either the pool ID or the auto pool
   * specification, but not both.
   * @member {object} [jobSpecification.poolInfo.autoPoolSpecification] If auto
   * pool creation fails, the Batch service moves the job to a completed state,
   * and the pool creation error is set in the job's scheduling error property.
   * The Batch service manages the lifetime (both creation and, unless
   * keepAlive is specified, deletion) of the auto pool. Any user actions that
   * affect the lifetime of the auto pool while the job is active will result
   * in unexpected behavior. You must specify either the pool ID or the auto
   * pool specification, but not both.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix] The
   * Batch service assigns each auto pool a unique identifier on creation. To
   * distinguish between pools created for different purposes, you can specify
   * this element to add a prefix to the ID that is assigned. The prefix can be
   * up to 20 characters long.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption] When
   * the pool lifetime is jobSchedule the pool exists for the lifetime of the
   * job schedule. The Batch Service creates the pool when it creates the first
   * job on the schedule. You may apply this option only to job schedules, not
   * to jobs. When the pool lifetime is job the pool exists for the lifetime of
   * the job to which it is dedicated. The Batch service creates the pool when
   * it creates the job. If the 'job' option is applied to a job schedule, the
   * Batch service creates a new auto pool for every job created on the
   * schedule. Possible values include: 'jobSchedule', 'job'
   * @member {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.keepAlive] If false, the
   * Batch service deletes the pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the job or job schedule
   * completes. If true, the Batch service does not delete the pool
   * automatically. It is up to the user to delete auto pools created with this
   * option.
   * @member {object} [jobSpecification.poolInfo.autoPoolSpecification.pool]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.displayName] The
   * display name need not be unique and can contain any Unicode characters up
   * to a maximum length of 1024.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize] For
   * information about available sizes of virtual machines for Cloud Services
   * pools (pools created with cloudServiceConfiguration), see Sizes for Cloud
   * Services
   * (http://azure.microsoft.com/documentation/articles/cloud-services-sizes-specs/).
   * Batch supports all Cloud Services VM sizes except ExtraSmall, A1V2 and
   * A2V2. For information about available VM sizes for pools using images from
   * the Virtual Machines Marketplace (pools created with
   * virtualMachineConfiguration) see Sizes for Virtual Machines (Linux)
   * (https://azure.microsoft.com/documentation/articles/virtual-machines-linux-sizes/)
   * or Sizes for Virtual Machines (Windows)
   * (https://azure.microsoft.com/documentation/articles/virtual-machines-windows-sizes/).
   * Batch supports all Azure VM sizes except STANDARD_A0 and those with
   * premium storage (STANDARD_GS, STANDARD_DS, and STANDARD_DSV2 series).
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * This property must be specified if the pool needs to be created with Azure
   * PaaS VMs. This property and virtualMachineConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request). This
   * property cannot be specified if the Batch account was created with its
   * poolAllocationMode property set to 'UserSubscription'.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily]
   * Possible values are: 2 - OS Family 2, equivalent to Windows Server 2008 R2
   * SP1. 3 - OS Family 3, equivalent to Windows Server 2012. 4 - OS Family 4,
   * equivalent to Windows Server 2012 R2. 5 - OS Family 5, equivalent to
   * Windows Server 2016. For more information, see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.targetOSVersion]
   * The default value is * which specifies the latest operating system version
   * for the specified OS family.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.currentOSVersion]
   * This may differ from targetOSVersion if the pool state is Upgrading. In
   * this case some virtual machines may be on the targetOSVersion and some may
   * be on the currentOSVersion during the upgrade process. Once all virtual
   * machines have upgraded, currentOSVersion is updated to be the same as
   * targetOSVersion.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * This property must be specified if the pool needs to be created with Azure
   * IaaS VMs. This property and cloudServiceConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request).
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * For example, Canonical or MicrosoftWindowsServer.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * For example, UbuntuServer or WindowsServer.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * For example, 14.04.0-LTS or 2012-R2-Datacenter.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * A value of 'latest' can be specified to select the latest version of an
   * image. If omitted, the default is 'latest'.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * This property is mutually exclusive with other ImageReference properties.
   * The virtual machine image must be in the same region and subscription as
   * the Azure Batch account. For information about the firewall settings for
   * the Batch node agent to communicate with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.osDisk]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.osDisk.caching]
   * Values are:
   *
   * none - The caching mode for the disk is not enabled.
   * readOnly - The caching mode for the disk is read only.
   * readWrite - The caching mode for the disk is read and write.
   *
   * The default value for caching is none. For information about the caching
   * options see:
   * https://blogs.msdn.microsoft.com/windowsazurestorage/2012/06/27/exploring-windows-azure-drives-disks-and-images/.
   * Possible values include: 'none', 'readOnly', 'readWrite'
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId]
   * The Batch node agent is a program that runs on each node in the pool, and
   * provides the command-and-control interface between the node and the Batch
   * service. There are different implementations of the node agent, known as
   * SKUs, for different operating systems. You must specify a node agent SKU
   * which matches the selected image reference. To get the list of supported
   * node agent SKUs along with their list of verified image references, see
   * the 'List supported node agent SKUs' operation.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * This property must not be specified if the imageReference or osDisk
   * property specifies a Linux OS image.
   * @member {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * If omitted, the default value is true.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * This property must be specified if the compute nodes in the pool need to
   * have empty data disks attached to them. This cannot be updated.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * This only applies to images that contain the Windows operating system, and
   * should only be used when you hold valid on-premises licenses for the nodes
   * which will be deployed. If omitted, no on-premises licensing discount is
   * applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * If specified, setup is performed on each node in the pool to allow tasks
   * to run in containers. All regular tasks and job manager tasks run on this
   * pool must specify the containerSettings property, and all other tasks may
   * specify it.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * This is the full image reference, as would be specified to "docker pull".
   * An image will be sourced from the default Docker registry unless the image
   * is fully qualified with an alternative registry.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * If any images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   * @member {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.maxTasksPerNode] The
   * default value is 1. The maximum value of this setting depends on the size
   * of the compute nodes in the pool (the vmSize setting).
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType]
   * Possible values include: 'spread', 'pack'
   * @member {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout] This
   * timeout applies only to manual scaling; it has no effect when
   * enableAutoScale is set to true. The default value is 15 minutes. The
   * minimum value is 5 minutes. If you specify a value less than 5 minutes,
   * the Batch service rejects the request with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   * @member {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @member {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @member {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale] If
   * false, at least one of targetDedicateNodes and targetLowPriorityNodes must
   * be specified. If true, the autoScaleFormula element is required. The pool
   * automatically resizes according to the formula. The default value is
   * false.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * This property must not be specified if enableAutoScale is set to false. It
   * is required if enableAutoScale is set to true. The formula is checked for
   * validity before the pool is created. If the formula is not valid, the
   * Batch service rejects the request with detailed error information.
   * @member {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The default value is 15 minutes. The minimum and maximum value are 5
   * minutes and 168 hours respectively. If you specify a value less than 5
   * minutes or greater than 168 hours, the Batch service rejects the request
   * with an invalid property value error; if you are calling the REST API
   * directly, the HTTP status code is 400 (Bad Request).
   * @member {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Enabling inter-node communication limits the maximum size of the pool due
   * to deployment restrictions on the nodes of the pool. This may result in
   * the pool not reaching its desired size. The default value is false.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The virtual network must be in the same region and subscription as the
   * Azure Batch account. The specified subnet should have enough free IP
   * addresses to accommodate the number of nodes in the pool. If the subnet
   * doesn't have enough free IP addresses, the pool will partially allocate
   * compute nodes, and a resize error will occur. The 'MicrosoftAzureBatch'
   * service principal must have the 'Classic Virtual Machine Contributor'
   * Role-Based Access Control (RBAC) role for the specified VNet. The
   * specified subnet must allow communication from the Azure Batch service to
   * be able to schedule tasks on the compute nodes. This can be verified by
   * checking if the specified VNet has any associated Network Security Groups
   * (NSG). If communication to the compute nodes in the specified subnet is
   * denied by an NSG, then the Batch service will set the state of the compute
   * nodes to unusable. For pools created with virtualMachineConfiguration only
   * ARM virtual networks ('Microsoft.Network/virtualNetworks') are supported,
   * but for pools created with cloudServiceConfiguration both ARM and classic
   * virtual networks are supported. If the specified VNet has any associated
   * Network Security Groups (NSG), then a few reserved system ports must be
   * enabled for inbound communication. For pools created with a virtual
   * machine configuration, enable ports 29876 and 29877, as well as port 22
   * for Linux and port 3389 for Windows. For pools created with a cloud
   * service configuration, enable ports 10100, 20100, and 30100. Also enable
   * outbound connections to Azure Storage on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * Pool endpoint configuration is only supported on pools with the
   * virtualMachineConfiguration property.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools]
   * The maximum number of inbound NAT pools per Batch pool is 5. If the
   * maximum number of inbound NAT pools is exceeded the request fails with
   * HTTP status code 400.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine]
   * The command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName]
   * This is the full image reference, as would be specified to "docker pull".
   * If no tag is provided as part of the image name, the tag ":latest" is used
   * as a default.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * This setting can be omitted if was already provided at pool creation.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName]
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password]
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * Files listed under this element are located in the task's working
   * directory.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * If omitted, the task runs as a non-administrative user unique to the task.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * Values are:
   *
   * pool - specifies that the task runs as the common auto user account which
   * is created on every node in a pool.
   * task - specifies that the service should create a new user for the task.
   * The default value is task. Possible values include: 'task', 'pool'
   * @member {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * nonAdmin - The auto user is a standard user without elevated access. admin
   * - The auto user is a user with elevated access and operates with full
   * Administrator permissions. The default value is nonAdmin. Possible values
   * include: 'nonAdmin', 'admin'
   * @member {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The Batch service retries a task if its exit code is nonzero. Note that
   * this value specifically controls the number of retries. The Batch service
   * will try the task once, and may then retry up to this limit. For example,
   * if the maximum retry count is 3, Batch tries the task up to 4 times (one
   * initial try and 3 retries). If the maximum retry count is 0, the Batch
   * service does not retry the task. If the maximum retry count is -1, the
   * Batch service retries the task without limit.
   * @member {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * If true and the start task fails on a compute node, the Batch service
   * retries the start task up to its maximum retry count (maxTaskRetryCount).
   * If the task has still not completed successfully after all retries, then
   * the Batch service marks the compute node unusable, and will not schedule
   * tasks to it. This condition can be detected via the node state and failure
   * info details. If false, the Batch service will not wait for the start task
   * to complete. In this case, other tasks can start executing on the compute
   * node while the start task is still running; and even if the start task
   * fails, new tasks will continue to be scheduled on the node. The default is
   * false.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * For Windows compute nodes, the Batch service installs the certificates to
   * the specified certificate store and location. For Linux compute nodes, the
   * certificates are stored in a directory inside the task working directory
   * and an environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the
   * task to query for this location. For certificates with visibility of
   * 'remoteUser', a 'certs' directory is created in the user's home directory
   * (e.g., /home/{user-name}/certs) and certificates are placed in that
   * directory.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses must be a subset of available Batch
   * service application licenses. If a license is requested which is not
   * supported, pool creation will fail.
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * @member {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.metadata] The Batch
   * service does not assign any meaning to metadata; it is solely for the use
   * of user code.
   * @member {array} [jobSpecification.metadata] The Batch service does not
   * assign any meaning to metadata; it is solely for the use of user code.
   * @member {object} [executionInfo] Information about jobs that have been and
   * will be run under this schedule.
   * @member {date} [executionInfo.nextRunTime] This property is meaningful
   * only if the schedule is in the active state when the time comes around.
   * For example, if the schedule is disabled, no job will be created at
   * nextRunTime unless the job is enabled before then.
   * @member {object} [executionInfo.recentJob] This property is present only
   * if the at least one job has run under the schedule.
   * @member {string} [executionInfo.recentJob.id]
   * @member {string} [executionInfo.recentJob.url]
   * @member {date} [executionInfo.endTime] This property is set only if the
   * job schedule is in the completed state.
   * @member {array} [metadata] A list of name-value pairs associated with the
   * schedule as metadata. The Batch service does not assign any meaning to
   * metadata; it is solely for the use of user code.
   * @member {object} [stats] The lifetime resource usage statistics for the
   * job schedule.
   * @member {string} [stats.url]
   * @member {date} [stats.startTime]
   * @member {date} [stats.lastUpdateTime]
   * @member {moment.duration} [stats.userCPUTime]
   * @member {moment.duration} [stats.kernelCPUTime]
   * @member {moment.duration} [stats.wallClockTime] The wall clock time is the
   * elapsed time from when the task started running on a compute node to when
   * it finished (or to the last time the statistics were updated, if the task
   * had not finished by then). If a task was retried, this includes the wall
   * clock time of all the task retries.
   * @member {number} [stats.readIOps]
   * @member {number} [stats.writeIOps]
   * @member {number} [stats.readIOGiB]
   * @member {number} [stats.writeIOGiB]
   * @member {number} [stats.numSucceededTasks]
   * @member {number} [stats.numFailedTasks]
   * @member {number} [stats.numTaskRetries]
   * @member {moment.duration} [stats.waitTime] This value is only reported in
   * the account lifetime statistics; it is not included in the job statistics.
   */
  constructor() {
  }

  /**
   * Defines the metadata of CloudJobSchedule
   *
   * @returns {object} metadata of CloudJobSchedule
   *
   */
  mapper() {
    return {
      required: false,
      serializedName: 'CloudJobSchedule',
      type: {
        name: 'Composite',
        className: 'CloudJobSchedule',
        modelProperties: {
          id: {
            required: false,
            serializedName: 'id',
            type: {
              name: 'String'
            }
          },
          displayName: {
            required: false,
            serializedName: 'displayName',
            type: {
              name: 'String'
            }
          },
          url: {
            required: false,
            serializedName: 'url',
            type: {
              name: 'String'
            }
          },
          eTag: {
            required: false,
            serializedName: 'eTag',
            type: {
              name: 'String'
            }
          },
          lastModified: {
            required: false,
            serializedName: 'lastModified',
            type: {
              name: 'DateTime'
            }
          },
          creationTime: {
            required: false,
            serializedName: 'creationTime',
            type: {
              name: 'DateTime'
            }
          },
          state: {
            required: false,
            serializedName: 'state',
            type: {
              name: 'Enum',
              allowedValues: [ 'active', 'completed', 'disabled', 'terminating', 'deleting' ]
            }
          },
          stateTransitionTime: {
            required: false,
            serializedName: 'stateTransitionTime',
            type: {
              name: 'DateTime'
            }
          },
          previousState: {
            required: false,
            serializedName: 'previousState',
            type: {
              name: 'Enum',
              allowedValues: [ 'active', 'completed', 'disabled', 'terminating', 'deleting' ]
            }
          },
          previousStateTransitionTime: {
            required: false,
            serializedName: 'previousStateTransitionTime',
            type: {
              name: 'DateTime'
            }
          },
          schedule: {
            required: false,
            serializedName: 'schedule',
            type: {
              name: 'Composite',
              className: 'Schedule'
            }
          },
          jobSpecification: {
            required: false,
            serializedName: 'jobSpecification',
            type: {
              name: 'Composite',
              className: 'JobSpecification'
            }
          },
          executionInfo: {
            required: false,
            serializedName: 'executionInfo',
            type: {
              name: 'Composite',
              className: 'JobScheduleExecutionInformation'
            }
          },
          metadata: {
            required: false,
            serializedName: 'metadata',
            type: {
              name: 'Sequence',
              element: {
                  required: false,
                  serializedName: 'MetadataItemElementType',
                  type: {
                    name: 'Composite',
                    className: 'MetadataItem'
                  }
              }
            }
          },
          stats: {
            required: false,
            serializedName: 'stats',
            type: {
              name: 'Composite',
              className: 'JobScheduleStatistics'
            }
          }
        }
      }
    };
  }
}

module.exports = CloudJobSchedule;
