/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

/**
 * @summary A job schedule that allows recurring jobs by specifying when to run
 * jobs and a specification used to create each job.
  *
 */
class JobScheduleAddParameter {
  /**
   * Create a JobScheduleAddParameter.
   * @property {string} id A string that uniquely identifies the schedule
   * within the account. The ID can contain any combination of alphanumeric
   * characters including hyphens and underscores, and cannot contain more than
   * 64 characters. The ID is case-preserving and case-insensitive (that is,
   * you may not have two IDs within an account that differ only by case).
   * @property {string} [displayName] The display name for the schedule. The
   * display name need not be unique and can contain any Unicode characters up
   * to a maximum length of 1024.
   * @property {object} schedule The schedule according to which jobs will be
   * created.
   * @property {date} [schedule.doNotRunUntil] If you do not specify a
   * doNotRunUntil time, the schedule becomes ready to create jobs immediately.
   * @property {date} [schedule.doNotRunAfter] If you do not specify a
   * doNotRunAfter time, and you are creating a recurring job schedule, the job
   * schedule will remain active until you explicitly terminate it.
   * @property {moment.duration} [schedule.startWindow] If a job is not created
   * within the startWindow interval, then the 'opportunity' is lost; no job
   * will be created until the next recurrence of the schedule. If the schedule
   * is recurring, and the startWindow is longer than the recurrence interval,
   * then this is equivalent to an infinite startWindow, because the job that
   * is 'due' in one recurrenceInterval is not carried forward into the next
   * recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @property {moment.duration} [schedule.recurrenceInterval] Because a job
   * schedule can have at most one active job under it at any given time, if it
   * is time to create a new job under a job schedule, but the previous job is
   * still running, the Batch service will not create the new job until the
   * previous job finishes. If the previous job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new job will be
   * scheduled for that interval. For recurring jobs, you should normally
   * specify a jobManagerTask in the jobSpecification. If you do not use
   * jobManagerTask, you will need an external process to monitor when jobs are
   * created, add tasks to the jobs and terminate the jobs ready for the next
   * recurrence. The default is that the schedule does not recur: one job is
   * created, within the startWindow after the doNotRunUntil time, and the
   * schedule is complete as soon as that job finishes. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @property {object} jobSpecification The details of the jobs to be created
   * on this schedule.
   * @property {number} [jobSpecification.priority] Priority values can range
   * from -1000 to 1000, with -1000 being the lowest priority and 1000 being
   * the highest priority. The default value is 0. This priority is used as the
   * default for all jobs under the job schedule. You can update a job's
   * priority after it has been created using by using the update job API.
   * @property {string} [jobSpecification.displayName] The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   * @property {boolean} [jobSpecification.usesTaskDependencies]
   * @property {string} [jobSpecification.onAllTasksComplete] Note that if a
   * job contains no tasks, then all tasks are considered complete. This option
   * is therefore most commonly used with a Job Manager task; if you want to
   * use automatic job termination without a Job Manager, you should initially
   * set onAllTasksComplete to noaction and update the job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding tasks.
   * The default is noaction. Possible values include: 'noAction',
   * 'terminateJob'
   * @property {string} [jobSpecification.onTaskFailure] The default is
   * noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   * @property {object} [jobSpecification.constraints]
   * @property {moment.duration}
   * [jobSpecification.constraints.maxWallClockTime] If the job does not
   * complete within the time limit, the Batch service terminates it and any
   * tasks that are still running. In this case, the termination reason will be
   * MaxWallClockTimeExpiry. If this property is not specified, there is no
   * time limit on how long the job may run.
   * @property {number} [jobSpecification.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries. The Batch
   * service will try each task once, and may then retry up to this limit. For
   * example, if the maximum retry count is 3, Batch tries a task up to 4 times
   * (one initial try and 3 retries). If the maximum retry count is 0, the
   * Batch service does not retry tasks. If the maximum retry count is -1, the
   * Batch service retries tasks without limit. The default value is 0 (no
   * retries).
   * @property {object} [jobSpecification.jobManagerTask] If the job does not
   * specify a Job Manager task, the user must explicitly add tasks to the job
   * using the Task API. If the job does specify a Job Manager task, the Batch
   * service creates the Job Manager task when the job is created, and will try
   * to schedule the Job Manager task before scheduling other tasks in the job.
   * @property {string} [jobSpecification.jobManagerTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters.
   * @property {string} [jobSpecification.jobManagerTask.displayName] It need
   * not be unique and can contain any Unicode characters up to a maximum
   * length of 1024.
   * @property {string} [jobSpecification.jobManagerTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobManagerTask.containerSettings] If
   * the pool that will run this task has containerConfiguration set, this must
   * be set as well. If the pool that will run this task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all
   * task environment variables are mapped into the container, and the task
   * command line is executed in the container.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.imageName] This is the
   * full image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobManagerTask.containerSettings.registry] This setting
   * can be omitted if was already provided at pool creation.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.password]
   * @property {array} [jobSpecification.jobManagerTask.resourceFiles] Files
   * listed under this element are located in the task's working directory.
   * There is a maximum size for the list of resource files.  When the max size
   * is exceeded, the request will fail and the response error code will be
   * RequestEntityTooLarge. If this occurs, the collection of ResourceFiles
   * must be reduced in size. This can be achieved using .zip files,
   * Application Packages, or Docker Containers.
   * @property {array} [jobSpecification.jobManagerTask.outputFiles] For
   * multi-instance tasks, the files will only be uploaded from the compute
   * node on which the primary task is executed.
   * @property {array} [jobSpecification.jobManagerTask.environmentSettings]
   * @property {object} [jobSpecification.jobManagerTask.constraints]
   * @property {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.maxWallClockTime] If this is
   * not specified, there is no time limit on how long the task may run.
   * @property {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.retentionTime] The default is
   * infinite, i.e. the task directory will be retained until the compute node
   * is removed or reimaged.
   * @property {number}
   * [jobSpecification.jobManagerTask.constraints.maxTaskRetryCount] Note that
   * this value specifically controls the number of retries for the task
   * executable due to a nonzero exit code. The Batch service will try the task
   * once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the task up to 4 times (one initial try and
   * 3 retries). If the maximum retry count is 0, the Batch service does not
   * retry the task after the first attempt. If the maximum retry count is -1,
   * the Batch service retries the task without limit. Resource files and
   * application packages are only downloaded again if the task is retried on a
   * new compute node.
   * @property {boolean} [jobSpecification.jobManagerTask.killJobOnCompletion]
   * If true, when the Job Manager task completes, the Batch service marks the
   * job as complete. If any tasks are still running at this time (other than
   * Job Release), those tasks are terminated. If false, the completion of the
   * Job Manager task does not affect the job status. In this case, you should
   * either use the onAllTasksComplete attribute to terminate the job, or have
   * a client or user terminate the job explicitly. An example of this is if
   * the Job Manager creates a set of tasks but then takes no further role in
   * their execution. The default value is true. If you are using the
   * onAllTasksComplete and onTaskFailure attributes to control job lifetime,
   * and using the Job Manager task only to create the tasks for the job (not
   * to monitor progress), then it is important to set killJobOnCompletion to
   * false.
   * @property {object} [jobSpecification.jobManagerTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task.
   * @property {string} [jobSpecification.jobManagerTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object} [jobSpecification.jobManagerTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.scope] The default
   * value is task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.elevationLevel] The
   * default value is nonAdmin. Possible values include: 'nonAdmin', 'admin'
   * @property {boolean} [jobSpecification.jobManagerTask.runExclusive] If
   * true, no other tasks will run on the same compute node for as long as the
   * Job Manager is running. If false, other tasks can run simultaneously with
   * the Job Manager on a compute node. The Job Manager task counts normally
   * against the node's concurrent task limit, so this is only relevant if the
   * node allows multiple concurrent tasks. The default value is true.
   * @property {array}
   * [jobSpecification.jobManagerTask.applicationPackageReferences] Application
   * packages are downloaded and deployed to a shared directory, not the task
   * working directory. Therefore, if a referenced package is already on the
   * compute node, and is up to date, then it is not re-downloaded; the
   * existing copy on the compute node is used. If a referenced application
   * package cannot be installed, for example because the package has been
   * deleted or because download failed, the task fails.
   * @property {object}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings] If this
   * property is set, the Batch service provides the task with an
   * authentication token which can be used to authenticate Batch service
   * operations without requiring an account access key. The token is provided
   * via the AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations
   * that the task can carry out using the token depend on the settings. For
   * example, a task can request job permissions in order to add other tasks to
   * the job, or check the status of the job or of other tasks under the job.
   * @property {array}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings.access] The
   * authentication token grants access to a limited set of Batch service
   * operations. Currently the only supported value for the access property is
   * 'job', which grants access to all operations related to the job which
   * contains the task.
   * @property {boolean} [jobSpecification.jobManagerTask.allowLowPriorityNode]
   * The default value is true.
   * @property {object} [jobSpecification.jobPreparationTask] If a job has a
   * Job Preparation task, the Batch service will run the Job Preparation task
   * on a compute node before starting any tasks of that job on that compute
   * node.
   * @property {string} [jobSpecification.jobPreparationTask.id] The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other task in the job can have the same ID as the Job
   * Preparation task. If you try to submit a task with the same id, the Batch
   * service rejects the request with error code
   * TaskIdSameAsJobPreparationTask; if you are calling the REST API directly,
   * the HTTP status code is 409 (Conflict).
   * @property {string} [jobSpecification.jobPreparationTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobPreparationTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.imageName] This is
   * the full image reference, as would be specified to "docker pull". If no
   * tag is provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobPreparationTask.containerSettings.registry] This
   * setting can be omitted if was already provided at pool creation.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.password]
   * @property {array} [jobSpecification.jobPreparationTask.resourceFiles]
   * Files listed under this element are located in the task's working
   * directory.  There is a maximum size for the list of resource files.  When
   * the max size is exceeded, the request will fail and the response error
   * code will be RequestEntityTooLarge. If this occurs, the collection of
   * ResourceFiles must be reduced in size. This can be achieved using .zip
   * files, Application Packages, or Docker Containers.
   * @property {array}
   * [jobSpecification.jobPreparationTask.environmentSettings]
   * @property {object} [jobSpecification.jobPreparationTask.constraints]
   * @property {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.maxWallClockTime] If this
   * is not specified, there is no time limit on how long the task may run.
   * @property {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.retentionTime] The
   * default is infinite, i.e. the task directory will be retained until the
   * compute node is removed or reimaged.
   * @property {number}
   * [jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries for the task
   * executable due to a nonzero exit code. The Batch service will try the task
   * once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the task up to 4 times (one initial try and
   * 3 retries). If the maximum retry count is 0, the Batch service does not
   * retry the task after the first attempt. If the maximum retry count is -1,
   * the Batch service retries the task without limit. Resource files and
   * application packages are only downloaded again if the task is retried on a
   * new compute node.
   * @property {boolean} [jobSpecification.jobPreparationTask.waitForSuccess]
   * If true and the Job Preparation task fails on a compute node, the Batch
   * service retries the Job Preparation task up to its maximum retry count (as
   * specified in the constraints element). If the task has still not completed
   * successfully after all retries, then the Batch service will not schedule
   * tasks of the job to the compute node. The compute node remains active and
   * eligible to run tasks of other jobs. If false, the Batch service will not
   * wait for the Job Preparation task to complete. In this case, other tasks
   * of the job can start executing on the compute node while the Job
   * Preparation task is still running; and even if the Job Preparation task
   * fails, new tasks will continue to be scheduled on the node. The default
   * value is true.
   * @property {object} [jobSpecification.jobPreparationTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task on
   * Windows nodes, or a non-administrative user unique to the pool on Linux
   * nodes.
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.userName] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @property {object}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.scope] The
   * default value is task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.elevationLevel]
   * The default value is nonAdmin. Possible values include: 'nonAdmin',
   * 'admin'
   * @property {boolean}
   * [jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess] The
   * Job Preparation task is always rerun if a compute node is reimaged, or if
   * the Job Preparation task did not complete (e.g. because the reboot
   * occurred while the task was running). Therefore, you should always write a
   * Job Preparation task to be idempotent and to behave correctly if run
   * multiple times. The default value is true.
   * @property {object} [jobSpecification.jobReleaseTask] The primary purpose
   * of the Job Release task is to undo changes to compute nodes made by the
   * Job Preparation task. Example activities include deleting local files, or
   * shutting down services that were started as part of job preparation. A Job
   * Release task cannot be specified without also specifying a Job Preparation
   * task for the job. The Batch service runs the Job Release task on the
   * compute nodes that have run the Job Preparation task.
   * @property {string} [jobSpecification.jobReleaseTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other task in the job can have the same ID as the Job
   * Release task. If you try to submit a task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   * @property {string} [jobSpecification.jobReleaseTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobReleaseTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.imageName] This is the
   * full image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobReleaseTask.containerSettings.registry] This setting
   * can be omitted if was already provided at pool creation.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.password]
   * @property {array} [jobSpecification.jobReleaseTask.resourceFiles] Files
   * listed under this element are located in the task's working directory.
   * @property {array} [jobSpecification.jobReleaseTask.environmentSettings]
   * @property {moment.duration}
   * [jobSpecification.jobReleaseTask.maxWallClockTime]
   * @property {moment.duration}
   * [jobSpecification.jobReleaseTask.retentionTime] The default is infinite,
   * i.e. the task directory will be retained until the compute node is removed
   * or reimaged.
   * @property {object} [jobSpecification.jobReleaseTask.userIdentity] If
   * omitted, the task runs as a non-administrative user unique to the task.
   * @property {string} [jobSpecification.jobReleaseTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object} [jobSpecification.jobReleaseTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.scope] The default
   * value is task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.elevationLevel] The
   * default value is nonAdmin. Possible values include: 'nonAdmin', 'admin'
   * @property {array} [jobSpecification.commonEnvironmentSettings] Individual
   * tasks can override an environment setting specified here by specifying the
   * same setting name with a different value.
   * @property {object} [jobSpecification.poolInfo]
   * @property {string} [jobSpecification.poolInfo.poolId] You must ensure that
   * the pool referenced by this property exists. If the pool does not exist at
   * the time the Batch service tries to schedule a job, no tasks for the job
   * will run until you create a pool with that id. Note that the Batch service
   * will not reject the job request; it will simply not run tasks until the
   * pool exists. You must specify either the pool ID or the auto pool
   * specification, but not both.
   * @property {object} [jobSpecification.poolInfo.autoPoolSpecification] If
   * auto pool creation fails, the Batch service moves the job to a completed
   * state, and the pool creation error is set in the job's scheduling error
   * property. The Batch service manages the lifetime (both creation and,
   * unless keepAlive is specified, deletion) of the auto pool. Any user
   * actions that affect the lifetime of the auto pool while the job is active
   * will result in unexpected behavior. You must specify either the pool ID or
   * the auto pool specification, but not both.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix] The
   * Batch service assigns each auto pool a unique identifier on creation. To
   * distinguish between pools created for different purposes, you can specify
   * this element to add a prefix to the ID that is assigned. The prefix can be
   * up to 20 characters long.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption]
   * Possible values include: 'jobSchedule', 'job'
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.keepAlive] If false, the
   * Batch service deletes the pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the job or job schedule
   * completes. If true, the Batch service does not delete the pool
   * automatically. It is up to the user to delete auto pools created with this
   * option.
   * @property {object} [jobSpecification.poolInfo.autoPoolSpecification.pool]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.displayName] The
   * display name need not be unique and can contain any Unicode characters up
   * to a maximum length of 1024.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize] For
   * information about available sizes of virtual machines in pools, see Choose
   * a VM size for compute nodes in an Azure Batch pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * This property must be specified if the pool needs to be created with Azure
   * PaaS VMs. This property and virtualMachineConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request). This
   * property cannot be specified if the Batch account was created with its
   * poolAllocationMode property set to 'UserSubscription'.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily]
   * Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.targetOSVersion]
   * The default value is * which specifies the latest operating system version
   * for the specified OS family.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.currentOSVersion]
   * This may differ from targetOSVersion if the pool state is Upgrading. In
   * this case some virtual machines may be on the targetOSVersion and some may
   * be on the currentOSVersion during the upgrade process. Once all virtual
   * machines have upgraded, currentOSVersion is updated to be the same as
   * targetOSVersion.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * This property must be specified if the pool needs to be created with Azure
   * IaaS VMs. This property and cloudServiceConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * For example, Canonical or MicrosoftWindowsServer.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * For example, UbuntuServer or WindowsServer.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * For example, 14.04.0-LTS or 2012-R2-Datacenter.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * A value of 'latest' can be specified to select the latest version of an
   * image. If omitted, the default is 'latest'.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * This property is mutually exclusive with other ImageReference properties.
   * The virtual machine image must be in the same region and subscription as
   * the Azure Batch account. For information about the firewall settings for
   * the Batch node agent to communicate with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.osDisk]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.osDisk.caching]
   * The default value for caching is readwrite. For information about the
   * caching options see:
   * https://blogs.msdn.microsoft.com/windowsazurestorage/2012/06/27/exploring-windows-azure-drives-disks-and-images/.
   * Possible values include: 'none', 'readOnly', 'readWrite'
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId]
   * The Batch node agent is a program that runs on each node in the pool, and
   * provides the command-and-control interface between the node and the Batch
   * service. There are different implementations of the node agent, known as
   * SKUs, for different operating systems. You must specify a node agent SKU
   * which matches the selected image reference. To get the list of supported
   * node agent SKUs along with their list of verified image references, see
   * the 'List supported node agent SKUs' operation.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * This property must not be specified if the imageReference or osDisk
   * property specifies a Linux OS image.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * If omitted, the default value is true.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * This property must be specified if the compute nodes in the pool need to
   * have empty data disks attached to them. This cannot be updated. Each node
   * gets its own disk (the disk is not a file share). Existing disks cannot be
   * attached, each attached disk is empty. When the node is removed from the
   * pool, the disk and all data associated with it is also deleted. The disk
   * is not formatted after being attached, it must be formatted before use -
   * for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * This only applies to images that contain the Windows operating system, and
   * should only be used when you hold valid on-premises licenses for the nodes
   * which will be deployed. If omitted, no on-premises licensing discount is
   * applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * If specified, setup is performed on each node in the pool to allow tasks
   * to run in containers. All regular tasks and job manager tasks run on this
   * pool must specify the containerSettings property, and all other tasks may
   * specify it.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * This is the full image reference, as would be specified to "docker pull".
   * An image will be sourced from the default Docker registry unless the image
   * is fully qualified with an alternative registry.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * If any images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.maxTasksPerNode] The
   * default value is 1. The maximum value of this setting depends on the size
   * of the compute nodes in the pool (the vmSize setting).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType]
   * Possible values include: 'spread', 'pack'
   * @property {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout] This
   * timeout applies only to manual scaling; it has no effect when
   * enableAutoScale is set to true. The default value is 15 minutes. The
   * minimum value is 5 minutes. If you specify a value less than 5 minutes,
   * the Batch service rejects the request with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale] If
   * false, at least one of targetDedicateNodes and targetLowPriorityNodes must
   * be specified. If true, the autoScaleFormula element is required. The pool
   * automatically resizes according to the formula. The default value is
   * false.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * This property must not be specified if enableAutoScale is set to false. It
   * is required if enableAutoScale is set to true. The formula is checked for
   * validity before the pool is created. If the formula is not valid, the
   * Batch service rejects the request with detailed error information.
   * @property {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The default value is 15 minutes. The minimum and maximum value are 5
   * minutes and 168 hours respectively. If you specify a value less than 5
   * minutes or greater than 168 hours, the Batch service rejects the request
   * with an invalid property value error; if you are calling the REST API
   * directly, the HTTP status code is 400 (Bad Request).
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Enabling inter-node communication limits the maximum size of the pool due
   * to deployment restrictions on the nodes of the pool. This may result in
   * the pool not reaching its desired size. The default value is false.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The virtual network must be in the same region and subscription as the
   * Azure Batch account. The specified subnet should have enough free IP
   * addresses to accommodate the number of nodes in the pool. If the subnet
   * doesn't have enough free IP addresses, the pool will partially allocate
   * compute nodes, and a resize error will occur. The 'MicrosoftAzureBatch'
   * service principal must have the 'Classic Virtual Machine Contributor'
   * Role-Based Access Control (RBAC) role for the specified VNet. The
   * specified subnet must allow communication from the Azure Batch service to
   * be able to schedule tasks on the compute nodes. This can be verified by
   * checking if the specified VNet has any associated Network Security Groups
   * (NSG). If communication to the compute nodes in the specified subnet is
   * denied by an NSG, then the Batch service will set the state of the compute
   * nodes to unusable. For pools created with virtualMachineConfiguration only
   * ARM virtual networks ('Microsoft.Network/virtualNetworks') are supported,
   * but for pools created with cloudServiceConfiguration both ARM and classic
   * virtual networks are supported. If the specified VNet has any associated
   * Network Security Groups (NSG), then a few reserved system ports must be
   * enabled for inbound communication. For pools created with a virtual
   * machine configuration, enable ports 29876 and 29877, as well as port 22
   * for Linux and port 3389 for Windows. For pools created with a cloud
   * service configuration, enable ports 10100, 20100, and 30100. Also enable
   * outbound connections to Azure Storage on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * Pool endpoint configuration is only supported on pools with the
   * virtualMachineConfiguration property.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools]
   * The maximum number of inbound NAT pools per Batch pool is 5. If the
   * maximum number of inbound NAT pools is exceeded the request fails with
   * HTTP status code 400.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine]
   * The command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all task environment variables are mapped
   * into the container, and the task command line is executed in the
   * container.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName]
   * This is the full image reference, as would be specified to "docker pull".
   * If no tag is provided as part of the image name, the tag ":latest" is used
   * as a default.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * This setting can be omitted if was already provided at pool creation.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password]
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * Files listed under this element are located in the task's working
   * directory.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * If omitted, the task runs as a non-administrative user unique to the task.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The default value is task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The default value is nonAdmin. Possible values include: 'nonAdmin',
   * 'admin'
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The Batch service retries a task if its exit code is nonzero. Note that
   * this value specifically controls the number of retries. The Batch service
   * will try the task once, and may then retry up to this limit. For example,
   * if the maximum retry count is 3, Batch tries the task up to 4 times (one
   * initial try and 3 retries). If the maximum retry count is 0, the Batch
   * service does not retry the task. If the maximum retry count is -1, the
   * Batch service retries the task without limit.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * If true and the start task fails on a compute node, the Batch service
   * retries the start task up to its maximum retry count (maxTaskRetryCount).
   * If the task has still not completed successfully after all retries, then
   * the Batch service marks the compute node unusable, and will not schedule
   * tasks to it. This condition can be detected via the node state and failure
   * info details. If false, the Batch service will not wait for the start task
   * to complete. In this case, other tasks can start executing on the compute
   * node while the start task is still running; and even if the start task
   * fails, new tasks will continue to be scheduled on the node. The default is
   * false.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * For Windows compute nodes, the Batch service installs the certificates to
   * the specified certificate store and location. For Linux compute nodes, the
   * certificates are stored in a directory inside the task working directory
   * and an environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the
   * task to query for this location. For certificates with visibility of
   * 'remoteUser', a 'certs' directory is created in the user's home directory
   * (e.g., /home/{user-name}/certs) and certificates are placed in that
   * directory.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses must be a subset of available Batch
   * service application licenses. If a license is requested which is not
   * supported, pool creation will fail. The permitted licenses available on
   * the pool are 'maya', 'vray', '3dsmax', 'arnold'. An additional charge
   * applies for each application license added to the pool.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.metadata] The Batch
   * service does not assign any meaning to metadata; it is solely for the use
   * of user code.
   * @property {array} [jobSpecification.metadata] The Batch service does not
   * assign any meaning to metadata; it is solely for the use of user code.
   * @property {array} [metadata] A list of name-value pairs associated with
   * the schedule as metadata. The Batch service does not assign any meaning to
   * metadata; it is solely for the use of user code.
   */
  constructor() {
  }

  /**
   * Defines the metadata of JobScheduleAddParameter
   *
   * @returns {object} metadata of JobScheduleAddParameter
   *
   */
  mapper() {
    return {
      required: false,
      serializedName: 'JobScheduleAddParameter',
      type: {
        name: 'Composite',
        className: 'JobScheduleAddParameter',
        modelProperties: {
          id: {
            required: true,
            serializedName: 'id',
            type: {
              name: 'String'
            }
          },
          displayName: {
            required: false,
            serializedName: 'displayName',
            type: {
              name: 'String'
            }
          },
          schedule: {
            required: true,
            serializedName: 'schedule',
            type: {
              name: 'Composite',
              className: 'Schedule'
            }
          },
          jobSpecification: {
            required: true,
            serializedName: 'jobSpecification',
            defaultValue: {},
            type: {
              name: 'Composite',
              className: 'JobSpecification'
            }
          },
          metadata: {
            required: false,
            serializedName: 'metadata',
            type: {
              name: 'Sequence',
              element: {
                  required: false,
                  serializedName: 'MetadataItemElementType',
                  type: {
                    name: 'Composite',
                    className: 'MetadataItem'
                  }
              }
            }
          }
        }
      }
    };
  }
}

module.exports = JobScheduleAddParameter;
