/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

/**
 * @summary The set of changes to be made to a Job Schedule.
  *
 */
class JobSchedulePatchParameter {
  /**
   * Create a JobSchedulePatchParameter.
   * @property {object} [schedule] The schedule according to which Jobs will be
   * created. If you do not specify this element, the existing schedule is left
   * unchanged.
   * @property {date} [schedule.doNotRunUntil] If you do not specify a
   * doNotRunUntil time, the schedule becomes ready to create Jobs immediately.
   * @property {date} [schedule.doNotRunAfter] If you do not specify a
   * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
   * Schedule will remain active until you explicitly terminate it.
   * @property {moment.duration} [schedule.startWindow] If a Job is not created
   * within the startWindow interval, then the 'opportunity' is lost; no Job
   * will be created until the next recurrence of the schedule. If the schedule
   * is recurring, and the startWindow is longer than the recurrence interval,
   * then this is equivalent to an infinite startWindow, because the Job that
   * is 'due' in one recurrenceInterval is not carried forward into the next
   * recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @property {moment.duration} [schedule.recurrenceInterval] Because a Job
   * Schedule can have at most one active Job under it at any given time, if it
   * is time to create a new Job under a Job Schedule, but the previous Job is
   * still running, the Batch service will not create the new Job until the
   * previous Job finishes. If the previous Job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new Job will be
   * scheduled for that interval. For recurring Jobs, you should normally
   * specify a jobManagerTask in the jobSpecification. If you do not use
   * jobManagerTask, you will need an external process to monitor when Jobs are
   * created, add Tasks to the Jobs and terminate the Jobs ready for the next
   * recurrence. The default is that the schedule does not recur: one Job is
   * created, within the startWindow after the doNotRunUntil time, and the
   * schedule is complete as soon as that Job finishes. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the
   * schedule with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   * @property {object} [jobSpecification] The details of the Jobs to be
   * created on this schedule. Updates affect only Jobs that are started after
   * the update has taken place. Any currently active Job continues with the
   * older specification.
   * @property {number} [jobSpecification.priority] Priority values can range
   * from -1000 to 1000, with -1000 being the lowest priority and 1000 being
   * the highest priority. The default value is 0. This priority is used as the
   * default for all Jobs under the Job Schedule. You can update a Job's
   * priority after it has been created using by using the update Job API.
   * @property {string} [jobSpecification.displayName] The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   * @property {boolean} [jobSpecification.usesTaskDependencies]
   * @property {string} [jobSpecification.onAllTasksComplete] Note that if a
   * Job contains no Tasks, then all Tasks are considered complete. This option
   * is therefore most commonly used with a Job Manager task; if you want to
   * use automatic Job termination without a Job Manager, you should initially
   * set onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks.
   * The default is noaction. Possible values include: 'noAction',
   * 'terminateJob'
   * @property {string} [jobSpecification.onTaskFailure] The default is
   * noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   * @property {object} [jobSpecification.networkConfiguration]
   * @property {string} [jobSpecification.networkConfiguration.subnetId] The
   * virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses
   * to accommodate the number of Compute Nodes which will run Tasks from the
   * Job. This can be up to the number of Compute Nodes in the Pool. The
   * 'MicrosoftAzureBatch' service principal must have the 'Classic Virtual
   * Machine Contributor' Role-Based Access Control (RBAC) role for the
   * specified VNet so that Azure Batch service can schedule Tasks on the
   * Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG),
   * then a few reserved system ports must be enabled for inbound communication
   * from the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for
   * outbound connections for communications to Azure Storage. For more details
   * see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   * @property {object} [jobSpecification.constraints]
   * @property {moment.duration}
   * [jobSpecification.constraints.maxWallClockTime] If the Job does not
   * complete within the time limit, the Batch service terminates it and any
   * Tasks that are still running. In this case, the termination reason will be
   * MaxWallClockTimeExpiry. If this property is not specified, there is no
   * time limit on how long the Job may run.
   * @property {number} [jobSpecification.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries. The Batch
   * service will try each Task once, and may then retry up to this limit. For
   * example, if the maximum retry count is 3, Batch tries a Task up to 4 times
   * (one initial try and 3 retries). If the maximum retry count is 0, the
   * Batch service does not retry Tasks. If the maximum retry count is -1, the
   * Batch service retries Tasks without limit. The default value is 0 (no
   * retries).
   * @property {object} [jobSpecification.jobManagerTask] If the Job does not
   * specify a Job Manager Task, the user must explicitly add Tasks to the Job
   * using the Task API. If the Job does specify a Job Manager Task, the Batch
   * service creates the Job Manager Task when the Job is created, and will try
   * to schedule the Job Manager Task before scheduling other Tasks in the Job.
   * @property {string} [jobSpecification.jobManagerTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters.
   * @property {string} [jobSpecification.jobManagerTask.displayName] It need
   * not be unique and can contain any Unicode characters up to a maximum
   * length of 1024.
   * @property {string} [jobSpecification.jobManagerTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the Task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobManagerTask.containerSettings] If
   * the Pool that will run this Task has containerConfiguration set, this must
   * be set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all
   * Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.imageName] This is the
   * full Image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the Image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobManagerTask.containerSettings.registry] This setting
   * can be omitted if was already provided at Pool creation.
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.registry.password]
   * @property {string}
   * [jobSpecification.jobManagerTask.containerSettings.workingDirectory] The
   * default is 'taskWorkingDirectory'. Possible values include:
   * 'taskWorkingDirectory', 'containerImageDefault'
   * @property {array} [jobSpecification.jobManagerTask.resourceFiles] Files
   * listed under this element are located in the Task's working directory.
   * There is a maximum size for the list of resource files.  When the max size
   * is exceeded, the request will fail and the response error code will be
   * RequestEntityTooLarge. If this occurs, the collection of ResourceFiles
   * must be reduced in size. This can be achieved using .zip files,
   * Application Packages, or Docker Containers.
   * @property {array} [jobSpecification.jobManagerTask.outputFiles] For
   * multi-instance Tasks, the files will only be uploaded from the Compute
   * Node on which the primary Task is executed.
   * @property {array} [jobSpecification.jobManagerTask.environmentSettings]
   * @property {object} [jobSpecification.jobManagerTask.constraints]
   * @property {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.maxWallClockTime] If this is
   * not specified, there is no time limit on how long the Task may run.
   * @property {moment.duration}
   * [jobSpecification.jobManagerTask.constraints.retentionTime] The default is
   * 7 days, i.e. the Task directory will be retained for 7 days unless the
   * Compute Node is removed or the Job is deleted.
   * @property {number}
   * [jobSpecification.jobManagerTask.constraints.maxTaskRetryCount] Note that
   * this value specifically controls the number of retries for the Task
   * executable due to a nonzero exit code. The Batch service will try the Task
   * once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and
   * 3 retries). If the maximum retry count is 0, the Batch service does not
   * retry the Task after the first attempt. If the maximum retry count is -1,
   * the Batch service retries the Task without limit.
   * @property {boolean} [jobSpecification.jobManagerTask.killJobOnCompletion]
   * If true, when the Job Manager Task completes, the Batch service marks the
   * Job as complete. If any Tasks are still running at this time (other than
   * Job Release), those Tasks are terminated. If false, the completion of the
   * Job Manager Task does not affect the Job status. In this case, you should
   * either use the onAllTasksComplete attribute to terminate the Job, or have
   * a client or user terminate the Job explicitly. An example of this is if
   * the Job Manager creates a set of Tasks but then takes no further role in
   * their execution. The default value is true. If you are using the
   * onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not
   * to monitor progress), then it is important to set killJobOnCompletion to
   * false.
   * @property {object} [jobSpecification.jobManagerTask.userIdentity] If
   * omitted, the Task runs as a non-administrative user unique to the Task.
   * @property {string} [jobSpecification.jobManagerTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object} [jobSpecification.jobManagerTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.scope] The default
   * value is Task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobManagerTask.userIdentity.autoUser.elevationLevel] The
   * default value is nonAdmin. Possible values include: 'nonAdmin', 'admin'
   * @property {boolean} [jobSpecification.jobManagerTask.runExclusive] If
   * true, no other Tasks will run on the same Node for as long as the Job
   * Manager is running. If false, other Tasks can run simultaneously with the
   * Job Manager on a Compute Node. The Job Manager Task counts normally
   * against the Compute Node's concurrent Task limit, so this is only relevant
   * if the Compute Node allows multiple concurrent Tasks. The default value is
   * true.
   * @property {array}
   * [jobSpecification.jobManagerTask.applicationPackageReferences] Application
   * Packages are downloaded and deployed to a shared directory, not the Task
   * working directory. Therefore, if a referenced Application Package is
   * already on the Compute Node, and is up to date, then it is not
   * re-downloaded; the existing copy on the Compute Compute Node is used. If a
   * referenced Application Package cannot be installed, for example because
   * the package has been deleted or because download failed, the Task fails.
   * @property {object}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings] If this
   * property is set, the Batch service provides the Task with an
   * authentication token which can be used to authenticate Batch service
   * operations without requiring an Account access key. The token is provided
   * via the AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations
   * that the Task can carry out using the token depend on the settings. For
   * example, a Task can request Job permissions in order to add other Tasks to
   * the Job, or check the status of the Job or of other Tasks under the Job.
   * @property {array}
   * [jobSpecification.jobManagerTask.authenticationTokenSettings.access] The
   * authentication token grants access to a limited set of Batch service
   * operations. Currently the only supported value for the access property is
   * 'job', which grants access to all operations related to the Job which
   * contains the Task.
   * @property {boolean} [jobSpecification.jobManagerTask.allowLowPriorityNode]
   * The default value is true.
   * @property {object} [jobSpecification.jobPreparationTask] If a Job has a
   * Job Preparation Task, the Batch service will run the Job Preparation Task
   * on a Node before starting any Tasks of that Job on that Compute Node.
   * @property {string} [jobSpecification.jobPreparationTask.id] The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code
   * TaskIdSameAsJobPreparationTask; if you are calling the REST API directly,
   * the HTTP status code is 409 (Conflict).
   * @property {string} [jobSpecification.jobPreparationTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the Task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobPreparationTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all Task environment variables are mapped
   * into the container, and the Task command line is executed in the
   * container. Files produced in the container outside of
   * AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.imageName] This is
   * the full Image reference, as would be specified to "docker pull". If no
   * tag is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobPreparationTask.containerSettings.registry] This
   * setting can be omitted if was already provided at Pool creation.
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.registry.password]
   * @property {string}
   * [jobSpecification.jobPreparationTask.containerSettings.workingDirectory]
   * The default is 'taskWorkingDirectory'. Possible values include:
   * 'taskWorkingDirectory', 'containerImageDefault'
   * @property {array} [jobSpecification.jobPreparationTask.resourceFiles]
   * Files listed under this element are located in the Task's working
   * directory.  There is a maximum size for the list of resource files.  When
   * the max size is exceeded, the request will fail and the response error
   * code will be RequestEntityTooLarge. If this occurs, the collection of
   * ResourceFiles must be reduced in size. This can be achieved using .zip
   * files, Application Packages, or Docker Containers.
   * @property {array}
   * [jobSpecification.jobPreparationTask.environmentSettings]
   * @property {object} [jobSpecification.jobPreparationTask.constraints]
   * @property {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.maxWallClockTime] If this
   * is not specified, there is no time limit on how long the Task may run.
   * @property {moment.duration}
   * [jobSpecification.jobPreparationTask.constraints.retentionTime] The
   * default is 7 days, i.e. the Task directory will be retained for 7 days
   * unless the Compute Node is removed or the Job is deleted.
   * @property {number}
   * [jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount] Note
   * that this value specifically controls the number of retries for the Task
   * executable due to a nonzero exit code. The Batch service will try the Task
   * once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and
   * 3 retries). If the maximum retry count is 0, the Batch service does not
   * retry the Task after the first attempt. If the maximum retry count is -1,
   * the Batch service retries the Task without limit.
   * @property {boolean} [jobSpecification.jobPreparationTask.waitForSuccess]
   * If true and the Job Preparation Task fails on a Node, the Batch service
   * retries the Job Preparation Task up to its maximum retry count (as
   * specified in the constraints element). If the Task has still not completed
   * successfully after all retries, then the Batch service will not schedule
   * Tasks of the Job to the Node. The Node remains active and eligible to run
   * Tasks of other Jobs. If false, the Batch service will not wait for the Job
   * Preparation Task to complete. In this case, other Tasks of the Job can
   * start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   * @property {object} [jobSpecification.jobPreparationTask.userIdentity] If
   * omitted, the Task runs as a non-administrative user unique to the Task on
   * Windows Compute Nodes, or a non-administrative user unique to the Pool on
   * Linux Compute Nodes.
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.userName] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @property {object}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser] The userName
   * and autoUser properties are mutually exclusive; you must specify one but
   * not both.
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.scope] The
   * default value is Task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobPreparationTask.userIdentity.autoUser.elevationLevel]
   * The default value is nonAdmin. Possible values include: 'nonAdmin',
   * 'admin'
   * @property {boolean}
   * [jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess] The
   * Job Preparation Task is always rerun if a Compute Node is reimaged, or if
   * the Job Preparation Task did not complete (e.g. because the reboot
   * occurred while the Task was running). Therefore, you should always write a
   * Job Preparation Task to be idempotent and to behave correctly if run
   * multiple times. The default value is true.
   * @property {object} [jobSpecification.jobReleaseTask] The primary purpose
   * of the Job Release Task is to undo changes to Nodes made by the Job
   * Preparation Task. Example activities include deleting local files, or
   * shutting down services that were started as part of Job preparation. A Job
   * Release Task cannot be specified without also specifying a Job Preparation
   * Task for the Job. The Batch service runs the Job Release Task on the
   * Compute Nodes that have run the Job Preparation Task.
   * @property {string} [jobSpecification.jobReleaseTask.id] The ID can contain
   * any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other Task in the Job can have the same ID as the Job
   * Release Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   * @property {string} [jobSpecification.jobReleaseTask.commandLine] The
   * command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the Task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object} [jobSpecification.jobReleaseTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all Task environment variables are mapped
   * into the container, and the Task command line is executed in the
   * container. Files produced in the container outside of
   * AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.imageName] This is the
   * full Image reference, as would be specified to "docker pull". If no tag is
   * provided as part of the Image name, the tag ":latest" is used as a
   * default.
   * @property {object}
   * [jobSpecification.jobReleaseTask.containerSettings.registry] This setting
   * can be omitted if was already provided at Pool creation.
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.registry.password]
   * @property {string}
   * [jobSpecification.jobReleaseTask.containerSettings.workingDirectory] The
   * default is 'taskWorkingDirectory'. Possible values include:
   * 'taskWorkingDirectory', 'containerImageDefault'
   * @property {array} [jobSpecification.jobReleaseTask.resourceFiles] Files
   * listed under this element are located in the Task's working directory.
   * @property {array} [jobSpecification.jobReleaseTask.environmentSettings]
   * @property {moment.duration}
   * [jobSpecification.jobReleaseTask.maxWallClockTime]
   * @property {moment.duration}
   * [jobSpecification.jobReleaseTask.retentionTime] The default is 7 days,
   * i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   * @property {object} [jobSpecification.jobReleaseTask.userIdentity] If
   * omitted, the Task runs as a non-administrative user unique to the Task.
   * @property {string} [jobSpecification.jobReleaseTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object} [jobSpecification.jobReleaseTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.scope] The default
   * value is Task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.jobReleaseTask.userIdentity.autoUser.elevationLevel] The
   * default value is nonAdmin. Possible values include: 'nonAdmin', 'admin'
   * @property {array} [jobSpecification.commonEnvironmentSettings] Individual
   * Tasks can override an environment setting specified here by specifying the
   * same setting name with a different value.
   * @property {object} [jobSpecification.poolInfo]
   * @property {string} [jobSpecification.poolInfo.poolId] You must ensure that
   * the Pool referenced by this property exists. If the Pool does not exist at
   * the time the Batch service tries to schedule a Job, no Tasks for the Job
   * will run until you create a Pool with that id. Note that the Batch service
   * will not reject the Job request; it will simply not run Tasks until the
   * Pool exists. You must specify either the Pool ID or the auto Pool
   * specification, but not both.
   * @property {object} [jobSpecification.poolInfo.autoPoolSpecification] If
   * auto Pool creation fails, the Batch service moves the Job to a completed
   * state, and the Pool creation error is set in the Job's scheduling error
   * property. The Batch service manages the lifetime (both creation and,
   * unless keepAlive is specified, deletion) of the auto Pool. Any user
   * actions that affect the lifetime of the auto Pool while the Job is active
   * will result in unexpected behavior. You must specify either the Pool ID or
   * the auto Pool specification, but not both.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix] The
   * Batch service assigns each auto Pool a unique identifier on creation. To
   * distinguish between Pools created for different purposes, you can specify
   * this element to add a prefix to the ID that is assigned. The prefix can be
   * up to 20 characters long.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption]
   * Possible values include: 'jobSchedule', 'job'
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.keepAlive] If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   * @property {object} [jobSpecification.poolInfo.autoPoolSpecification.pool]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.displayName] The
   * display name need not be unique and can contain any Unicode characters up
   * to a maximum length of 1024.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize] For
   * information about available sizes of virtual machines in Pools, see Choose
   * a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * This property must be specified if the Pool needs to be created with Azure
   * PaaS VMs. This property and virtualMachineConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request). This
   * property cannot be specified if the Batch Account was created with its
   * poolAllocationMode property set to 'UserSubscription'.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily]
   * Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The default value is * which specifies the latest operating system version
   * for the specified OS family.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * This property must be specified if the Pool needs to be created with Azure
   * IaaS VMs. This property and cloudServiceConfiguration are mutually
   * exclusive and one of the properties must be specified. If neither is
   * specified then the Batch service returns an error; if you are calling the
   * REST API directly, the HTTP status code is 400 (Bad Request).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * For example, Canonical or MicrosoftWindowsServer.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * For example, UbuntuServer or WindowsServer.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * For example, 14.04.0-LTS or 2012-R2-Datacenter.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * A value of 'latest' can be specified to select the latest version of an
   * Image. If omitted, the default is 'latest'.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * This property is mutually exclusive with other ImageReference properties.
   * The Virtual Machine Image must be in the same region and subscription as
   * the Azure Batch Account. For information about the firewall settings for
   * the Batch Compute Node agent to communicate with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId]
   * The Batch Compute Node agent is a program that runs on each Compute Node
   * in the Pool, and provides the command-and-control interface between the
   * Compute Node and the Batch service. There are different implementations of
   * the Compute Node agent, known as SKUs, for different operating systems.
   * You must specify a Compute Node agent SKU which matches the selected Image
   * reference. To get the list of supported Compute Node agent SKUs along with
   * their list of verified Image references, see the 'List supported Compute
   * Node agent SKUs' operation.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * This property must not be specified if the imageReference property
   * specifies a Linux OS Image.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * If omitted, the default value is true.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each
   * Compute Node gets its own disk (the disk is not a file share). Existing
   * disks cannot be attached, each attached disk is empty. When the Compute
   * Node is removed from the Pool, the disk and all data associated with it is
   * also deleted. The disk is not formatted after being attached, it must be
   * formatted before use - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * This only applies to Images that contain the Windows operating system, and
   * should only be used when you hold valid on-premises licenses for the
   * Compute Nodes which will be deployed. If omitted, no on-premises licensing
   * discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * If specified, setup is performed on each Compute Node in the Pool to allow
   * Tasks to run in containers. All regular Tasks and Job manager Tasks run on
   * this Pool must specify the containerSettings property, and all other Tasks
   * may specify it.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * This is the full Image reference, as would be specified to "docker pull".
   * An Image will be sourced from the default Docker registry unless the Image
   * is fully qualified with an alternative registry.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * If any Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.maxTasksPerNode] The
   * default value is 1. The maximum value is the smaller of 4 times the number
   * of cores of the vmSize of the Pool or 256.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * If not specified, the default is spread.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType]
   * If not specified, the default is spread. Possible values include:
   * 'spread', 'pack'
   * @property {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout] This
   * timeout applies only to manual scaling; it has no effect when
   * enableAutoScale is set to true. The default value is 15 minutes. The
   * minimum value is 5 minutes. If you specify a value less than 5 minutes,
   * the Batch service rejects the request with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * This property must not be specified if enableAutoScale is set to true. If
   * enableAutoScale is set to false, then you must set either
   * targetDedicatedNodes, targetLowPriorityNodes, or both.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale] If
   * false, at least one of targetDedicateNodes and targetLowPriorityNodes must
   * be specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is
   * false.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * This property must not be specified if enableAutoScale is set to false. It
   * is required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the
   * Batch service rejects the request with detailed error information.
   * @property {moment.duration}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The default value is 15 minutes. The minimum and maximum value are 5
   * minutes and 168 hours respectively. If you specify a value less than 5
   * minutes or greater than 168 hours, the Batch service rejects the request
   * with an invalid property value error; if you are calling the REST API
   * directly, the HTTP status code is 400 (Bad Request).
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Enabling inter-node communication limits the maximum size of the Pool due
   * to deployment restrictions on the Compute Nodes of the Pool. This may
   * result in the Pool not reaching its desired size. The default value is
   * false.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The virtual network must be in the same region and subscription as the
   * Azure Batch Account. The specified subnet should have enough free IP
   * addresses to accommodate the number of Compute Nodes in the Pool. If the
   * subnet doesn't have enough free IP addresses, the Pool will partially
   * allocate Nodes, and a resize error will occur. The 'MicrosoftAzureBatch'
   * service principal must have the 'Classic Virtual Machine Contributor'
   * Role-Based Access Control (RBAC) role for the specified VNet. The
   * specified subnet must allow communication from the Azure Batch service to
   * be able to schedule Tasks on the Nodes. This can be verified by checking
   * if the specified VNet has any associated Network Security Groups (NSG). If
   * communication to the Nodes in the specified subnet is denied by an NSG,
   * then the Batch service will set the state of the Compute Nodes to
   * unusable. For Pools created with virtualMachineConfiguration only ARM
   * virtual networks ('Microsoft.Network/virtualNetworks') are supported, but
   * for Pools created with cloudServiceConfiguration both ARM and classic
   * virtual networks are supported. If the specified VNet has any associated
   * Network Security Groups (NSG), then a few reserved system ports must be
   * enabled for inbound communication. For Pools created with a virtual
   * machine configuration, enable ports 29876 and 29877, as well as port 22
   * for Linux and port 3389 for Windows. For Pools created with a cloud
   * service configuration, enable ports 10100, 20100, and 30100. Also enable
   * outbound connections to Azure Storage on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * Possible values include: 'none', 'job'
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * Pool endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools]
   * The maximum number of inbound NAT Pools per Batch Pool is 5. If the
   * maximum number of inbound NAT Pools is exceeded the request fails with
   * HTTP status code 400.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine]
   * The command line does not run under a shell, and therefore cannot take
   * advantage of shell features such as environment variable expansion. If you
   * want to take advantage of such features, you should invoke the shell in
   * the command line, for example using "cmd /c MyCommand" in Windows or
   * "/bin/sh -c MyCommand" in Linux. If the command line refers to file paths,
   * it should use a relative path (relative to the Task working directory), or
   * use the Batch provided environment variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)
   * are mapped into the container, all Task environment variables are mapped
   * into the container, and the Task command line is executed in the
   * container. Files produced in the container outside of
   * AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * These additional options are supplied as arguments to the "docker create"
   * command, in addition to those controlled by the Batch Service.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName]
   * This is the full Image reference, as would be specified to "docker pull".
   * If no tag is provided as part of the Image name, the tag ":latest" is used
   * as a default.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * This setting can be omitted if was already provided at Pool creation.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * If omitted, the default is "docker.io".
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password]
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The default is 'taskWorkingDirectory'. Possible values include:
   * 'taskWorkingDirectory', 'containerImageDefault'
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * Files listed under this element are located in the Task's working
   * directory.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * If omitted, the Task runs as a non-administrative user unique to the Task.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {object}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The userName and autoUser properties are mutually exclusive; you must
   * specify one but not both.
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The default value is Task. Possible values include: 'task', 'pool'
   * @property {string}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The default value is nonAdmin. Possible values include: 'nonAdmin',
   * 'admin'
   * @property {number}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The Batch service retries a Task if its exit code is nonzero. Note that
   * this value specifically controls the number of retries. The Batch service
   * will try the Task once, and may then retry up to this limit. For example,
   * if the maximum retry count is 3, Batch tries the Task up to 4 times (one
   * initial try and 3 retries). If the maximum retry count is 0, the Batch
   * service does not retry the Task. If the maximum retry count is -1, the
   * Batch service retries the Task without limit.
   * @property {boolean}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * If true and the start Task fails on a Node, the Batch service retries the
   * start Task up to its maximum retry count (maxTaskRetryCount). If the Task
   * has still not completed successfully after all retries, then the Batch
   * service marks the Node unusable, and will not schedule Tasks to it. This
   * condition can be detected via the Compute Node state and failure info
   * details. If false, the Batch service will not wait for the start Task to
   * complete. In this case, other Tasks can start executing on the Compute
   * Node while the start Task is still running; and even if the start Task
   * fails, new Tasks will continue to be scheduled on the Compute Node. The
   * default is false.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * For Windows Nodes, the Batch service installs the Certificates to the
   * specified Certificate store and location. For Linux Compute Nodes, the
   * Certificates are stored in a directory inside the Task working directory
   * and an environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the
   * Task to query for this location. For Certificates with visibility of
   * 'remoteUser', a 'certs' directory is created in the user's home directory
   * (e.g., /home/{user-name}/certs) and Certificates are placed in that
   * directory.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * Changes to Package references affect all new Nodes joining the Pool, but
   * do not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses must be a subset of available Batch
   * service application licenses. If a license is requested which is not
   * supported, Pool creation will fail. The permitted licenses available on
   * the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An additional charge
   * applies for each application license added to the Pool.
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * @property {array}
   * [jobSpecification.poolInfo.autoPoolSpecification.pool.metadata] The Batch
   * service does not assign any meaning to metadata; it is solely for the use
   * of user code.
   * @property {array} [jobSpecification.metadata] The Batch service does not
   * assign any meaning to metadata; it is solely for the use of user code.
   * @property {array} [metadata] A list of name-value pairs associated with
   * the Job Schedule as metadata. If you do not specify this element, existing
   * metadata is left unchanged.
   */
  constructor() {
  }

  /**
   * Defines the metadata of JobSchedulePatchParameter
   *
   * @returns {object} metadata of JobSchedulePatchParameter
   *
   */
  mapper() {
    return {
      required: false,
      serializedName: 'JobSchedulePatchParameter',
      type: {
        name: 'Composite',
        className: 'JobSchedulePatchParameter',
        modelProperties: {
          schedule: {
            required: false,
            serializedName: 'schedule',
            type: {
              name: 'Composite',
              className: 'Schedule'
            }
          },
          jobSpecification: {
            required: false,
            serializedName: 'jobSpecification',
            type: {
              name: 'Composite',
              className: 'JobSpecification'
            }
          },
          metadata: {
            required: false,
            serializedName: 'metadata',
            type: {
              name: 'Sequence',
              element: {
                  required: false,
                  serializedName: 'MetadataItemElementType',
                  type: {
                    name: 'Composite',
                    className: 'MetadataItem'
                  }
              }
            }
          }
        }
      }
    };
  }
}

module.exports = JobSchedulePatchParameter;
