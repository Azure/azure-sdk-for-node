/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

const msRest = require('ms-rest');
const msRestAzure = require('ms-rest-azure');
const WebResource = msRest.WebResource;

/**
 * @summary Checks the specified Job Schedule exists.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule which you want to
 * check.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleExistsOptions] Additional parameters for
 * the operation
 *
 * @param {number} [options.jobScheduleExistsOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleExistsOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleExistsOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleExistsOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleExistsOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleExistsOptions.ifNoneMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleExistsOptions.ifModifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has been
 * modified since the specified time.
 *
 * @param {date} [options.jobScheduleExistsOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {boolean} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _exists(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleExistsOptions = (options && options.jobScheduleExistsOptions !== undefined) ? options.jobScheduleExistsOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      timeout = jobScheduleExistsOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      clientRequestId = jobScheduleExistsOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      returnClientRequestId = jobScheduleExistsOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      ocpDate = jobScheduleExistsOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      ifMatch = jobScheduleExistsOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      ifNoneMatch = jobScheduleExistsOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      ifModifiedSince = jobScheduleExistsOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleExistsOptions !== null && jobScheduleExistsOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleExistsOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'HEAD';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200 && statusCode !== 404) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;
    result = (statusCode === 200);

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Deletes a Job Schedule from the specified Account.
 *
 * When you delete a Job Schedule, this also deletes all Jobs and Tasks under
 * that schedule. When Tasks are deleted, all the files in their working
 * directories on the Compute Nodes are also deleted (the retention period is
 * ignored). The Job Schedule statistics are no longer accessible once the Job
 * Schedule is deleted, though they are still counted towards Account lifetime
 * statistics.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to delete.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleDeleteMethodOptions] Additional
 * parameters for the operation
 *
 * @param {number} [options.jobScheduleDeleteMethodOptions.timeout] The maximum
 * time that the server can spend processing the request, in seconds. The
 * default is 30 seconds.
 *
 * @param {uuid} [options.jobScheduleDeleteMethodOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean}
 * [options.jobScheduleDeleteMethodOptions.returnClientRequestId] Whether the
 * server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleDeleteMethodOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleDeleteMethodOptions.ifMatch] An ETag
 * value associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleDeleteMethodOptions.ifNoneMatch] An ETag
 * value associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleDeleteMethodOptions.ifModifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has been modified since the specified time.
 *
 * @param {date} [options.jobScheduleDeleteMethodOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _deleteMethod(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleDeleteMethodOptions = (options && options.jobScheduleDeleteMethodOptions !== undefined) ? options.jobScheduleDeleteMethodOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      timeout = jobScheduleDeleteMethodOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      clientRequestId = jobScheduleDeleteMethodOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      returnClientRequestId = jobScheduleDeleteMethodOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      ocpDate = jobScheduleDeleteMethodOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      ifMatch = jobScheduleDeleteMethodOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      ifNoneMatch = jobScheduleDeleteMethodOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      ifModifiedSince = jobScheduleDeleteMethodOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleDeleteMethodOptions !== null && jobScheduleDeleteMethodOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleDeleteMethodOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'DELETE';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 202) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * Gets information about the specified Job Schedule.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to get.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleGetOptions] Additional parameters for
 * the operation
 *
 * @param {string} [options.jobScheduleGetOptions.select] An OData $select
 * clause.
 *
 * @param {string} [options.jobScheduleGetOptions.expand] An OData $expand
 * clause.
 *
 * @param {number} [options.jobScheduleGetOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleGetOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleGetOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleGetOptions.ocpDate] The time the request
 * was issued. Client libraries typically set this to the current system clock
 * time; set it explicitly if you are calling the REST API directly.
 *
 * @param {string} [options.jobScheduleGetOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleGetOptions.ifNoneMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleGetOptions.ifModifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has been
 * modified since the specified time.
 *
 * @param {date} [options.jobScheduleGetOptions.ifUnmodifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has not been
 * modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {object} [result]   - The deserialized result object if an error did not occur.
 *                      See {@link CloudJobSchedule} for more information.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _get(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleGetOptions = (options && options.jobScheduleGetOptions !== undefined) ? options.jobScheduleGetOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let select;
  let expand;
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      select = jobScheduleGetOptions.select;
      if (select !== null && select !== undefined && typeof select.valueOf() !== 'string') {
        throw new Error('select must be of type string.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      expand = jobScheduleGetOptions.expand;
      if (expand !== null && expand !== undefined && typeof expand.valueOf() !== 'string') {
        throw new Error('expand must be of type string.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      timeout = jobScheduleGetOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      clientRequestId = jobScheduleGetOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      returnClientRequestId = jobScheduleGetOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      ocpDate = jobScheduleGetOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      ifMatch = jobScheduleGetOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      ifNoneMatch = jobScheduleGetOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      ifModifiedSince = jobScheduleGetOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleGetOptions !== null && jobScheduleGetOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleGetOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (select !== null && select !== undefined) {
    queryParameters.push('$select=' + encodeURIComponent(select));
  }
  if (expand !== null && expand !== undefined) {
    queryParameters.push('$expand=' + encodeURIComponent(expand));
  }
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'GET';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;
    // Deserialize Response
    if (statusCode === 200) {
      let parsedResponse = null;
      try {
        parsedResponse = JSON.parse(responseBody);
        result = JSON.parse(responseBody);
        if (parsedResponse !== null && parsedResponse !== undefined) {
          let resultMapper = new client.models['CloudJobSchedule']().mapper();
          result = client.deserialize(resultMapper, parsedResponse, 'result');
        }
      } catch (error) {
        let deserializationError = new Error(`Error ${error} occurred in deserializing the responseBody - ${responseBody}`);
        deserializationError.request = msRest.stripRequest(httpRequest);
        deserializationError.response = msRest.stripResponse(response);
        return callback(deserializationError);
      }
    }

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Updates the properties of the specified Job Schedule.
 *
 * This replaces only the Job Schedule properties specified in the request. For
 * example, if the schedule property is not specified with this request, then
 * the Batch service will keep the existing schedule. Changes to a Job Schedule
 * only impact Jobs created by the schedule after the update has taken place;
 * currently running Jobs are unaffected.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to update.
 *
 * @param {object} jobSchedulePatchParameter The parameters for the request.
 *
 * @param {object} [jobSchedulePatchParameter.schedule] The schedule according
 * to which Jobs will be created. If you do not specify this element, the
 * existing schedule is left unchanged.
 *
 * @param {date} [jobSchedulePatchParameter.schedule.doNotRunUntil] The
 * earliest time at which any Job may be created under this Job Schedule. If
 * you do not specify a doNotRunUntil time, the schedule becomes ready to
 * create Jobs immediately.
 *
 * @param {date} [jobSchedulePatchParameter.schedule.doNotRunAfter] A time
 * after which no Job will be created under this Job Schedule. The schedule
 * will move to the completed state as soon as this deadline is past and there
 * is no active Job under this Job Schedule. If you do not specify a
 * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
 * Schedule will remain active until you explicitly terminate it.
 *
 * @param {moment.duration} [jobSchedulePatchParameter.schedule.startWindow]
 * The time interval, starting from the time at which the schedule indicates a
 * Job should be created, within which a Job must be created. If a Job is not
 * created within the startWindow interval, then the 'opportunity' is lost; no
 * Job will be created until the next recurrence of the schedule. If the
 * schedule is recurring, and the startWindow is longer than the recurrence
 * interval, then this is equivalent to an infinite startWindow, because the
 * Job that is 'due' in one recurrenceInterval is not carried forward into the
 * next recurrence interval. The default is infinite. The minimum value is 1
 * minute. If you specify a lower value, the Batch service rejects the schedule
 * with an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.schedule.recurrenceInterval] The time interval
 * between the start times of two successive Jobs under the Job Schedule. A Job
 * Schedule can have at most one active Job under it at any given time. Because
 * a Job Schedule can have at most one active Job under it at any given time,
 * if it is time to create a new Job under a Job Schedule, but the previous Job
 * is still running, the Batch service will not create the new Job until the
 * previous Job finishes. If the previous Job does not finish within the
 * startWindow period of the new recurrenceInterval, then no new Job will be
 * scheduled for that interval. For recurring Jobs, you should normally specify
 * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
 * you will need an external process to monitor when Jobs are created, add
 * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
 * default is that the schedule does not recur: one Job is created, within the
 * startWindow after the doNotRunUntil time, and the schedule is complete as
 * soon as that Job finishes. The minimum value is 1 minute. If you specify a
 * lower value, the Batch service rejects the schedule with an error; if you
 * are calling the REST API directly, the HTTP status code is 400 (Bad
 * Request).
 *
 * @param {object} [jobSchedulePatchParameter.jobSpecification] The details of
 * the Jobs to be created on this schedule. Updates affect only Jobs that are
 * started after the update has taken place. Any currently active Job continues
 * with the older specification.
 *
 * @param {number} [jobSchedulePatchParameter.jobSpecification.priority] The
 * priority of Jobs created under this schedule. Priority values can range from
 * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
 * highest priority. The default value is 0. This priority is used as the
 * default for all Jobs under the Job Schedule. You can update a Job's priority
 * after it has been created using by using the update Job API.
 *
 * @param {string} [jobSchedulePatchParameter.jobSpecification.displayName] The
 * display name for Jobs created under this schedule. The name need not be
 * unique and can contain any Unicode characters up to a maximum length of
 * 1024.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.usesTaskDependencies] Whether
 * Tasks in the Job can define dependencies on each other. The default is
 * false.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.onAllTasksComplete] The action
 * the Batch service should take when all Tasks in a Job created under this
 * schedule are in the completed state. Note that if a Job contains no Tasks,
 * then all Tasks are considered complete. This option is therefore most
 * commonly used with a Job Manager task; if you want to use automatic Job
 * termination without a Job Manager, you should initially set
 * onAllTasksComplete to noaction and update the Job properties to set
 * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
 * default is noaction. Possible values include: 'noAction', 'terminateJob'
 *
 * @param {string} [jobSchedulePatchParameter.jobSpecification.onTaskFailure]
 * The action the Batch service should take when any Task fails in a Job
 * created under this schedule. A Task is considered to have failed if it have
 * failed if has a failureInfo. A failureInfo is set if the Task completes with
 * a non-zero exit code after exhausting its retry count, or if there was an
 * error starting the Task, for example due to a resource file download error.
 * The default is noaction. Possible values include: 'noAction',
 * 'performExitOptionsJobAction'
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.networkConfiguration] The
 * network configuration for the Job.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.networkConfiguration.subnetId The
 * ARM resource identifier of the virtual network subnet which Compute Nodes
 * running Tasks from the Job will join for the duration of the Task. This will
 * only work with a VirtualMachineConfiguration Pool. The virtual network must
 * be in the same region and subscription as the Azure Batch Account. The
 * specified subnet should have enough free IP addresses to accommodate the
 * number of Compute Nodes which will run Tasks from the Job. This can be up to
 * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
 * principal must have the 'Classic Virtual Machine Contributor' Role-Based
 * Access Control (RBAC) role for the specified VNet so that Azure Batch
 * service can schedule Tasks on the Nodes. This can be verified by checking if
 * the specified VNet has any associated Network Security Groups (NSG). If
 * communication to the Nodes in the specified subnet is denied by an NSG, then
 * the Batch service will set the state of the Compute Nodes to unusable. This
 * is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * If the specified VNet has any associated Network Security Groups (NSG), then
 * a few reserved system ports must be enabled for inbound communication from
 * the Azure Batch service. For Pools created with a Virtual Machine
 * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
 * and port 3389 for Windows. Port 443 is also required to be open for outbound
 * connections for communications to Azure Storage. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {object} [jobSchedulePatchParameter.jobSpecification.constraints] The
 * execution constraints for Jobs created under this schedule.
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.constraints.maxWallClockTime]
 * The maximum elapsed time that the Job may run, measured from the time the
 * Job is created. If the Job does not complete within the time limit, the
 * Batch service terminates it and any Tasks that are still running. In this
 * case, the termination reason will be MaxWallClockTimeExpiry. If this
 * property is not specified, there is no time limit on how long the Job may
 * run.
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.constraints.maxTaskRetryCount]
 * The maximum number of times each Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries. The Batch service will try each
 * Task once, and may then retry up to this limit. For example, if the maximum
 * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
 * retries). If the maximum retry count is 0, the Batch service does not retry
 * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
 * without limit. The default value is 0 (no retries).
 *
 * @param {object} [jobSchedulePatchParameter.jobSpecification.jobManagerTask]
 * The details of a Job Manager Task to be launched when a Job is started under
 * this schedule. If the Job does not specify a Job Manager Task, the user must
 * explicitly add Tasks to the Job using the Task API. If the Job does specify
 * a Job Manager Task, the Batch service creates the Job Manager Task when the
 * Job is created, and will try to schedule the Job Manager Task before
 * scheduling other Tasks in the Job.
 *
 * @param {string} jobSchedulePatchParameter.jobSpecification.jobManagerTask.id
 * A string that uniquely identifies the Job Manager Task within the Job. The
 * ID can contain any combination of alphanumeric characters including hyphens
 * and underscores and cannot contain more than 64 characters.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.displayName] The
 * display name of the Job Manager Task. It need not be unique and can contain
 * any Unicode characters up to a maximum length of 1024.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.jobManagerTask.commandLine The
 * command line of the Job Manager Task. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.containerSettings]
 * The settings for the container under which the Job Manager Task runs. If the
 * Pool that will run this Task has containerConfiguration set, this must be
 * set as well. If the Pool that will run this Task doesn't have
 * containerConfiguration set, this must not be set. When this is specified,
 * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
 * Azure Batch directories on the node) are mapped into the container, all Task
 * environment variables are mapped into the container, and the Task command
 * line is executed in the container. Files produced in the container outside
 * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
 * that Batch file APIs will not be able to access those files.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.resourceFiles] A
 * list of files that the Batch service will download to the Compute Node
 * before running the command line. Files listed under this element are located
 * in the Task's working directory. There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.outputFiles] A
 * list of files that the Batch service will upload from the Compute Node after
 * running the command line. For multi-instance Tasks, the files will only be
 * uploaded from the Compute Node on which the primary Task is executed.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.environmentSettings]
 * A list of environment variable settings for the Job Manager Task.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.constraints]
 * Constraints that apply to the Job Manager Task.
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.requiredSlots]
 * The number of scheduling slots that the Task requires to run. The default is
 * 1. A Task can only be scheduled to run on a compute node if the node has
 * enough free scheduling slots available. For multi-instance Tasks, this must
 * be 1.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
 * Whether completion of the Job Manager Task signifies completion of the
 * entire Job. If true, when the Job Manager Task completes, the Batch service
 * marks the Job as complete. If any Tasks are still running at this time
 * (other than Job Release), those Tasks are terminated. If false, the
 * completion of the Job Manager Task does not affect the Job status. In this
 * case, you should either use the onAllTasksComplete attribute to terminate
 * the Job, or have a client or user terminate the Job explicitly. An example
 * of this is if the Job Manager creates a set of Tasks but then takes no
 * further role in their execution. The default value is true. If you are using
 * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
 * and using the Job Manager Task only to create the Tasks for the Job (not to
 * monitor progress), then it is important to set killJobOnCompletion to false.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.userIdentity] The
 * user identity under which the Job Manager Task runs. If omitted, the Task
 * runs as a non-administrative user unique to the Task.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.runExclusive]
 * Whether the Job Manager Task requires exclusive use of the Compute Node
 * where it runs. If true, no other Tasks will run on the same Node for as long
 * as the Job Manager is running. If false, other Tasks can run simultaneously
 * with the Job Manager on a Compute Node. The Job Manager Task counts normally
 * against the Compute Node's concurrent Task limit, so this is only relevant
 * if the Compute Node allows multiple concurrent Tasks. The default value is
 * true.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
 * A list of Application Packages that the Batch service will deploy to the
 * Compute Node before running the command line. Application Packages are
 * downloaded and deployed to a shared directory, not the Task working
 * directory. Therefore, if a referenced Application Package is already on the
 * Compute Node, and is up to date, then it is not re-downloaded; the existing
 * copy on the Compute Node is used. If a referenced Application Package cannot
 * be installed, for example because the package has been deleted or because
 * download failed, the Task fails.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
 * The settings for an authentication token that the Task can use to perform
 * Batch service operations. If this property is set, the Batch service
 * provides the Task with an authentication token which can be used to
 * authenticate Batch service operations without requiring an Account access
 * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
 * variable. The operations that the Task can carry out using the token depend
 * on the settings. For example, a Task can request Job permissions in order to
 * add other Tasks to the Job, or check the status of the Job or of other Tasks
 * under the Job.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
 * The Batch resources to which the token grants access. The authentication
 * token grants access to a limited set of Batch service operations. Currently
 * the only supported value for the access property is 'job', which grants
 * access to all operations related to the Job which contains the Task.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
 * Whether the Job Manager Task may run on a low-priority Compute Node. The
 * default value is true.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask] The Job
 * Preparation Task for Jobs created under this schedule. If a Job has a Job
 * Preparation Task, the Batch service will run the Job Preparation Task on a
 * Node before starting any Tasks of that Job on that Compute Node.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.id] A string
 * that uniquely identifies the Job Preparation Task within the Job. The ID can
 * contain any combination of alphanumeric characters including hyphens and
 * underscores and cannot contain more than 64 characters. If you do not
 * specify this property, the Batch service assigns a default value of
 * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
 * Preparation Task. If you try to submit a Task with the same id, the Batch
 * service rejects the request with error code TaskIdSameAsJobPreparationTask;
 * if you are calling the REST API directly, the HTTP status code is 409
 * (Conflict).
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.jobPreparationTask.commandLine
 * The command line of the Job Preparation Task. The command line does not run
 * under a shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.containerSettings]
 * The settings for the container under which the Job Preparation Task runs.
 * When this is specified, all directories recursively below the
 * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
 * mapped into the container, all Task environment variables are mapped into
 * the container, and the Task command line is executed in the container. Files
 * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
 * reflected to the host disk, meaning that Batch file APIs will not be able to
 * access those files.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.resourceFiles]
 * A list of files that the Batch service will download to the Compute Node
 * before running the command line. Files listed under this element are located
 * in the Task's working directory.  There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.environmentSettings]
 * A list of environment variable settings for the Job Preparation Task.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints]
 * Constraints that apply to the Job Preparation Task.
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
 * The maximum elapsed time that the Task may run, measured from the time the
 * Task starts. If the Task does not complete within the time limit, the Batch
 * service terminates it. If this is not specified, there is no time limit on
 * how long the Task may run.
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
 * The minimum time to retain the Task directory on the Compute Node where it
 * ran, from the time it completes execution. After this time, the Batch
 * service may delete the Task directory and all its contents. The default is 7
 * days, i.e. the Task directory will be retained for 7 days unless the Compute
 * Node is removed or the Job is deleted.
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries for the Task executable due to a
 * nonzero exit code. The Batch service will try the Task once, and may then
 * retry up to this limit. For example, if the maximum retry count is 3, Batch
 * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
 * retry count is 0, the Batch service does not retry the Task after the first
 * attempt. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.waitForSuccess]
 * Whether the Batch service should wait for the Job Preparation Task to
 * complete successfully before scheduling any other Tasks of the Job on the
 * Compute Node. A Job Preparation Task has completed successfully if it exits
 * with exit code 0. If true and the Job Preparation Task fails on a Node, the
 * Batch service retries the Job Preparation Task up to its maximum retry count
 * (as specified in the constraints element). If the Task has still not
 * completed successfully after all retries, then the Batch service will not
 * schedule Tasks of the Job to the Node. The Node remains active and eligible
 * to run Tasks of other Jobs. If false, the Batch service will not wait for
 * the Job Preparation Task to complete. In this case, other Tasks of the Job
 * can start executing on the Compute Node while the Job Preparation Task is
 * still running; and even if the Job Preparation Task fails, new Tasks will
 * continue to be scheduled on the Compute Node. The default value is true.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.userIdentity]
 * The user identity under which the Job Preparation Task runs. If omitted, the
 * Task runs as a non-administrative user unique to the Task on Windows Compute
 * Nodes, or a non-administrative user unique to the Pool on Linux Compute
 * Nodes.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
 * Whether the Batch service should rerun the Job Preparation Task after a
 * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
 * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
 * because the reboot occurred while the Task was running). Therefore, you
 * should always write a Job Preparation Task to be idempotent and to behave
 * correctly if run multiple times. The default value is true.
 *
 * @param {object} [jobSchedulePatchParameter.jobSpecification.jobReleaseTask]
 * The Job Release Task for Jobs created under this schedule. The primary
 * purpose of the Job Release Task is to undo changes to Nodes made by the Job
 * Preparation Task. Example activities include deleting local files, or
 * shutting down services that were started as part of Job preparation. A Job
 * Release Task cannot be specified without also specifying a Job Preparation
 * Task for the Job. The Batch service runs the Job Release Task on the Compute
 * Nodes that have run the Job Preparation Task.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.id] A string that
 * uniquely identifies the Job Release Task within the Job. The ID can contain
 * any combination of alphanumeric characters including hyphens and underscores
 * and cannot contain more than 64 characters. If you do not specify this
 * property, the Batch service assigns a default value of 'jobrelease'. No
 * other Task in the Job can have the same ID as the Job Release Task. If you
 * try to submit a Task with the same id, the Batch service rejects the request
 * with error code TaskIdSameAsJobReleaseTask; if you are calling the REST API
 * directly, the HTTP status code is 409 (Conflict).
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.jobReleaseTask.commandLine The
 * command line of the Job Release Task. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.containerSettings]
 * The settings for the container under which the Job Release Task runs. When
 * this is specified, all directories recursively below the
 * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
 * mapped into the container, all Task environment variables are mapped into
 * the container, and the Task command line is executed in the container. Files
 * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
 * reflected to the host disk, meaning that Batch file APIs will not be able to
 * access those files.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.resourceFiles] A
 * list of files that the Batch service will download to the Compute Node
 * before running the command line.  There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.environmentSettings]
 * A list of environment variable settings for the Job Release Task.
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
 * The maximum elapsed time that the Job Release Task may run on a given
 * Compute Node, measured from the time the Task starts. If the Task does not
 * complete within the time limit, the Batch service terminates it. The default
 * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
 * If you do, the Batch service rejects it with an error; if you are calling
 * the REST API directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.retentionTime]
 * The minimum time to retain the Task directory for the Job Release Task on
 * the Compute Node. After this time, the Batch service may delete the Task
 * directory and all its contents. The default is 7 days, i.e. the Task
 * directory will be retained for 7 days unless the Compute Node is removed or
 * the Job is deleted.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.userIdentity] The
 * user identity under which the Job Release Task runs. If omitted, the Task
 * runs as a non-administrative user unique to the Task.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.commonEnvironmentSettings] A
 * list of common environment variable settings. These environment variables
 * are set for all Tasks in Jobs created under this schedule (including the Job
 * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
 * override an environment setting specified here by specifying the same
 * setting name with a different value.
 *
 * @param {object} jobSchedulePatchParameter.jobSpecification.poolInfo The Pool
 * on which the Batch service runs the Tasks of Jobs created under this
 * schedule.
 *
 * @param {string} [jobSchedulePatchParameter.jobSpecification.poolInfo.poolId]
 * The ID of an existing Pool. All the Tasks of the Job will run on the
 * specified Pool. You must ensure that the Pool referenced by this property
 * exists. If the Pool does not exist at the time the Batch service tries to
 * schedule a Job, no Tasks for the Job will run until you create a Pool with
 * that id. Note that the Batch service will not reject the Job request; it
 * will simply not run Tasks until the Pool exists. You must specify either the
 * Pool ID or the auto Pool specification, but not both.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification]
 * Characteristics for a temporary 'auto pool'. The Batch service will create
 * this auto Pool when the Job is submitted. If auto Pool creation fails, the
 * Batch service moves the Job to a completed state, and the Pool creation
 * error is set in the Job's scheduling error property. The Batch service
 * manages the lifetime (both creation and, unless keepAlive is specified,
 * deletion) of the auto Pool. Any user actions that affect the lifetime of the
 * auto Pool while the Job is active will result in unexpected behavior. You
 * must specify either the Pool ID or the auto Pool specification, but not
 * both.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
 * A prefix to be added to the unique identifier when a Pool is automatically
 * created. The Batch service assigns each auto Pool a unique identifier on
 * creation. To distinguish between Pools created for different purposes, you
 * can specify this element to add a prefix to the ID that is assigned. The
 * prefix can be up to 20 characters long.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
 * The minimum lifetime of created auto Pools, and how multiple Jobs on a
 * schedule are assigned to Pools. Possible values include: 'jobSchedule',
 * 'job'
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
 * Whether to keep an auto Pool alive after its lifetime expires. If false, the
 * Batch service deletes the Pool once its lifetime (as determined by the
 * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
 * completes. If true, the Batch service does not delete the Pool
 * automatically. It is up to the user to delete auto Pools created with this
 * option.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
 * The Pool specification for the auto Pool.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
 * The display name for the Pool. The display name need not be unique and can
 * contain any Unicode characters up to a maximum length of 1024.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
 * The size of the virtual machines in the Pool. All virtual machines in a Pool
 * are the same size. For information about available sizes of virtual machines
 * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
 * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
 * The cloud service configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure PaaS VMs. This property
 * and virtualMachineConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request). This property cannot be specified if the Batch
 * Account was created with its poolAllocationMode property set to
 * 'UserSubscription'.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
 * The Azure Guest OS family to be installed on the virtual machines in the
 * Pool. Possible values are:
 * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
 * 3 - OS Family 3, equivalent to Windows Server 2012.
 * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
 * 5 - OS Family 5, equivalent to Windows Server 2016.
 * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
 * see Azure Guest OS Releases
 * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
 * The Azure Guest OS version to be installed on the virtual machines in the
 * Pool. The default value is * which specifies the latest operating system
 * version for the specified OS family.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
 * The virtual machine configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure IaaS VMs. This property
 * and cloudServiceConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {object}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
 * A reference to the Azure Virtual Machines Marketplace Image or the custom
 * Virtual Machine Image to use.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
 * The publisher of the Azure Virtual Machines Marketplace Image. For example,
 * Canonical or MicrosoftWindowsServer.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
 * The offer type of the Azure Virtual Machines Marketplace Image. For example,
 * UbuntuServer or WindowsServer.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
 * The SKU of the Azure Virtual Machines Marketplace Image. For example,
 * 18.04-LTS or 2019-Datacenter.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
 * The version of the Azure Virtual Machines Marketplace Image. A value of
 * 'latest' can be specified to select the latest version of an Image. If
 * omitted, the default is 'latest'.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
 * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
 * in the Pool will be created using this Image Id. This is of the form
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
 * or
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
 * for always defaulting to the latest image version. This property is mutually
 * exclusive with other ImageReference properties. The Shared Image Gallery
 * Image must have replicas in the same region and must be in the same
 * subscription as the Azure Batch account. If the image version is not
 * specified in the imageId, the latest version will be used. For information
 * about the firewall settings for the Batch Compute Node agent to communicate
 * with the Batch service see
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
 * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
 * in the Pool. The Batch Compute Node agent is a program that runs on each
 * Compute Node in the Pool, and provides the command-and-control interface
 * between the Compute Node and the Batch service. There are different
 * implementations of the Compute Node agent, known as SKUs, for different
 * operating systems. You must specify a Compute Node agent SKU which matches
 * the selected Image reference. To get the list of supported Compute Node
 * agent SKUs along with their list of verified Image references, see the 'List
 * supported Compute Node agent SKUs' operation.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
 * Windows operating system settings on the virtual machine. This property must
 * not be specified if the imageReference property specifies a Linux OS Image.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
 * Whether automatic updates are enabled on the virtual machine. If omitted,
 * the default value is true.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
 * The configuration for data disks attached to the Compute Nodes in the Pool.
 * This property must be specified if the Compute Nodes in the Pool need to
 * have empty data disks attached to them. This cannot be updated. Each Compute
 * Node gets its own disk (the disk is not a file share). Existing disks cannot
 * be attached, each attached disk is empty. When the Compute Node is removed
 * from the Pool, the disk and all data associated with it is also deleted. The
 * disk is not formatted after being attached, it must be formatted before use
 * - for more information see
 * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
 * and
 * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
 * The type of on-premises license to be used when deploying the operating
 * system. This only applies to Images that contain the Windows operating
 * system, and should only be used when you hold valid on-premises licenses for
 * the Compute Nodes which will be deployed. If omitted, no on-premises
 * licensing discount is applied. Values are:
 *
 * Windows_Server - The on-premises license is for Windows Server.
 * Windows_Client - The on-premises license is for Windows Client.
 *
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
 * The container configuration for the Pool. If specified, setup is performed
 * on each Compute Node in the Pool to allow Tasks to run in containers. All
 * regular Tasks and Job manager Tasks run on this Pool must specify the
 * containerSettings property, and all other Tasks may specify it.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
 * The collection of container Image names. This is the full Image reference,
 * as would be specified to "docker pull". An Image will be sourced from the
 * default Docker registry unless the Image is fully qualified with an
 * alternative registry.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
 * Additional private registries from which containers can be pulled. If any
 * Images must be downloaded from a private registry which requires
 * credentials, then those credentials must be provided here.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
 * The disk encryption configuration for the pool. If specified, encryption is
 * performed on each node in the pool during node provisioning.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
 * The list of disk targets Batch Service will encrypt on the compute node. If
 * omitted, no disks on the compute nodes in the pool will be encrypted. On
 * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
 * "TemporaryDisk" must be specified.
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
 * The number of task slots that can be used to run concurrent tasks on a
 * single compute node in the pool. The default value is 1. The maximum value
 * is the smaller of 4 times the number of cores of the vmSize of the pool or
 * 256.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread. Possible values include: 'spread', 'pack'
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
 * The timeout for allocation of Compute Nodes to the Pool. This timeout
 * applies only to manual scaling; it has no effect when enableAutoScale is set
 * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
 * you specify a value less than 5 minutes, the Batch service rejects the
 * request with an error; if you are calling the REST API directly, the HTTP
 * status code is 400 (Bad Request).
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
 * The desired number of dedicated Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
 * The desired number of low-priority Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
 * Whether the Pool size should automatically adjust over time. If false, at
 * least one of targetDedicateNodes and targetLowPriorityNodes must be
 * specified. If true, the autoScaleFormula element is required. The Pool
 * automatically resizes according to the formula. The default value is false.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
 * The formula for the desired number of Compute Nodes in the Pool. This
 * property must not be specified if enableAutoScale is set to false. It is
 * required if enableAutoScale is set to true. The formula is checked for
 * validity before the Pool is created. If the formula is not valid, the Batch
 * service rejects the request with detailed error information.
 *
 * @param {moment.duration}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
 * The time interval at which to automatically adjust the Pool size according
 * to the autoscale formula. The default value is 15 minutes. The minimum and
 * maximum value are 5 minutes and 168 hours respectively. If you specify a
 * value less than 5 minutes or greater than 168 hours, the Batch service
 * rejects the request with an invalid property value error; if you are calling
 * the REST API directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
 * Whether the Pool permits direct communication between Compute Nodes.
 * Enabling inter-node communication limits the maximum size of the Pool due to
 * deployment restrictions on the Compute Nodes of the Pool. This may result in
 * the Pool not reaching its desired size. The default value is false.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
 * The network configuration for the Pool.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
 * The ARM resource identifier of the virtual network subnet which the Compute
 * Nodes of the Pool will join. This is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * The virtual network must be in the same region and subscription as the Azure
 * Batch Account. The specified subnet should have enough free IP addresses to
 * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
 * have enough free IP addresses, the Pool will partially allocate Nodes and a
 * resize error will occur. The 'MicrosoftAzureBatch' service principal must
 * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
 * (RBAC) role for the specified VNet. The specified subnet must allow
 * communication from the Azure Batch service to be able to schedule Tasks on
 * the Nodes. This can be verified by checking if the specified VNet has any
 * associated Network Security Groups (NSG). If communication to the Nodes in
 * the specified subnet is denied by an NSG, then the Batch service will set
 * the state of the Compute Nodes to unusable. For Pools created with
 * virtualMachineConfiguration only ARM virtual networks
 * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
 * with cloudServiceConfiguration both ARM and classic virtual networks are
 * supported. If the specified VNet has any associated Network Security Groups
 * (NSG), then a few reserved system ports must be enabled for inbound
 * communication. For Pools created with a virtual machine configuration,
 * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
 * Windows. For Pools created with a cloud service configuration, enable ports
 * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
 * on port 443. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
 * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
 * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
 * endpoint configuration is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {array}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
 * A list of inbound NAT Pools that can be used to address specific ports on an
 * individual Compute Node externally. The maximum number of inbound NAT Pools
 * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
 * the request fails with HTTP status code 400. This cannot be specified if the
 * IPAddressProvisioningType is NoPublicIPAddresses.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
 * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
 * Public IP configuration property is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
 * The provisioning type for Public IP Addresses for the Pool. The default
 * value is BatchManaged. Possible values include: 'batchManaged',
 * 'userManaged', 'noPublicIPAddresses'
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
 * The list of public IPs which the Batch service will use when provisioning
 * Compute Nodes. The number of IPs specified here limits the maximum size of
 * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
 * for each public IP. For example, a pool needing 250 dedicated VMs would need
 * at least 3 public IPs specified. Each element of this collection is of the
 * form:
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
 * A Task to run on each Compute Node as it joins the Pool. The Task runs when
 * the Compute Node is added to the Pool or when the Compute Node is restarted.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
 * The command line of the StartTask. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
 * The settings for the container under which the StartTask runs. When this is
 * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
 * root of Azure Batch directories on the node) are mapped into the container,
 * all Task environment variables are mapped into the container, and the Task
 * command line is executed in the container. Files produced in the container
 * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
 * meaning that Batch file APIs will not be able to access those files.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
 * Additional options to the container create command. These additional options
 * are supplied as arguments to the "docker create" command, in addition to
 * those controlled by the Batch Service.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
 * The Image to use to create the container in which the Task will run. This is
 * the full Image reference, as would be specified to "docker pull". If no tag
 * is provided as part of the Image name, the tag ":latest" is used as a
 * default.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
 * The private registry which contains the container Image. This setting can be
 * omitted if was already provided at Pool creation.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
 * The registry URL. If omitted, the default is "docker.io".
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
 * The user name to log into the registry server.
 *
 * @param {string}
 * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
 * The password to log into the registry server.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
 * The location of the container Task working directory. The default is
 * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
 * 'containerImageDefault'
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
 * A list of files that the Batch service will download to the Compute Node
 * before running the command line.  There is a maximum size for the list of
 * resource files. When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
 * A list of environment variable settings for the StartTask.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
 * The user identity under which the StartTask runs. If omitted, the Task runs
 * as a non-administrative user unique to the Task.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
 * The name of the user identity under which the Task is run. The userName and
 * autoUser properties are mutually exclusive; you must specify one but not
 * both.
 *
 * @param {object}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
 * The auto user under which the Task is run. The userName and autoUser
 * properties are mutually exclusive; you must specify one but not both.
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
 * The scope for the auto user The default value is pool. If the pool is
 * running Windows a value of Task should be specified if stricter isolation
 * between tasks is required. For example, if the task mutates the registry in
 * a way which could impact other tasks, or if certificates have been specified
 * on the pool which should not be accessible by normal tasks but should be
 * accessible by StartTasks. Possible values include: 'task', 'pool'
 *
 * @param {string}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
 * The elevation level of the auto user. The default value is nonAdmin.
 * Possible values include: 'nonAdmin', 'admin'
 *
 * @param {number}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries. The Batch service will try the
 * Task once, and may then retry up to this limit. For example, if the maximum
 * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
 * retries). If the maximum retry count is 0, the Batch service does not retry
 * the Task. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
 * Whether the Batch service should wait for the StartTask to complete
 * successfully (that is, to exit with exit code 0) before scheduling any Tasks
 * on the Compute Node. If true and the StartTask fails on a Node, the Batch
 * service retries the StartTask up to its maximum retry count
 * (maxTaskRetryCount). If the Task has still not completed successfully after
 * all retries, then the Batch service marks the Node unusable, and will not
 * schedule Tasks to it. This condition can be detected via the Compute Node
 * state and failure info details. If false, the Batch service will not wait
 * for the StartTask to complete. In this case, other Tasks can start executing
 * on the Compute Node while the StartTask is still running; and even if the
 * StartTask fails, new Tasks will continue to be scheduled on the Compute
 * Node. The default is true.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
 * A list of Certificates to be installed on each Compute Node in the Pool. For
 * Windows Nodes, the Batch service installs the Certificates to the specified
 * Certificate store and location. For Linux Compute Nodes, the Certificates
 * are stored in a directory inside the Task working directory and an
 * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
 * query for this location. For Certificates with visibility of 'remoteUser', a
 * 'certs' directory is created in the user's home directory (e.g.,
 * /home/{user-name}/certs) and Certificates are placed in that directory.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
 * The list of Packages to be installed on each Compute Node in the Pool.
 * Changes to Package references affect all new Nodes joining the Pool, but do
 * not affect Compute Nodes that are already in the Pool until they are
 * rebooted or reimaged. There is a maximum of 10 Package references on any
 * given Pool.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
 * The list of application licenses the Batch service will make available on
 * each Compute Node in the Pool. The list of application licenses must be a
 * subset of available Batch service application licenses. If a license is
 * requested which is not supported, Pool creation will fail. The permitted
 * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
 * additional charge applies for each application license added to the Pool.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
 * The list of user Accounts to be created on each Compute Node in the Pool.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
 * A list of name-value pairs associated with the Pool as metadata. The Batch
 * service does not assign any meaning to metadata; it is solely for the use of
 * user code.
 *
 * @param {array}
 * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
 * A list of file systems to mount on each node in the pool. This supports
 * Azure Files, NFS, CIFS/SMB, and Blobfuse.
 *
 * @param {array} [jobSchedulePatchParameter.jobSpecification.metadata] A list
 * of name-value pairs associated with each Job created under this schedule as
 * metadata. The Batch service does not assign any meaning to metadata; it is
 * solely for the use of user code.
 *
 * @param {array} [jobSchedulePatchParameter.metadata] A list of name-value
 * pairs associated with the Job Schedule as metadata. If you do not specify
 * this element, existing metadata is left unchanged.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobSchedulePatchOptions] Additional parameters for
 * the operation
 *
 * @param {number} [options.jobSchedulePatchOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobSchedulePatchOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobSchedulePatchOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobSchedulePatchOptions.ocpDate] The time the request
 * was issued. Client libraries typically set this to the current system clock
 * time; set it explicitly if you are calling the REST API directly.
 *
 * @param {string} [options.jobSchedulePatchOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobSchedulePatchOptions.ifNoneMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobSchedulePatchOptions.ifModifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has been
 * modified since the specified time.
 *
 * @param {date} [options.jobSchedulePatchOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _patch(jobScheduleId, jobSchedulePatchParameter, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobSchedulePatchOptions = (options && options.jobSchedulePatchOptions !== undefined) ? options.jobSchedulePatchOptions : undefined;
  if (jobSchedulePatchParameter === null || jobSchedulePatchParameter === undefined)
  {
    jobSchedulePatchParameter = {};
  }
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (jobSchedulePatchParameter === null || jobSchedulePatchParameter === undefined) {
      throw new Error('jobSchedulePatchParameter cannot be null or undefined.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      timeout = jobSchedulePatchOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      clientRequestId = jobSchedulePatchOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      returnClientRequestId = jobSchedulePatchOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      ocpDate = jobSchedulePatchOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      ifMatch = jobSchedulePatchOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      ifNoneMatch = jobSchedulePatchOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      ifModifiedSince = jobSchedulePatchOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobSchedulePatchOptions !== null && jobSchedulePatchOptions !== undefined) {
      ifUnmodifiedSince = jobSchedulePatchOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'PATCH';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  // Serialize Request
  let requestContent = null;
  let requestModel = null;
  try {
    if (jobSchedulePatchParameter !== null && jobSchedulePatchParameter !== undefined) {
      let requestModelMapper = new client.models['JobSchedulePatchParameter']().mapper();
      requestModel = client.serialize(requestModelMapper, jobSchedulePatchParameter, 'jobSchedulePatchParameter');
      requestContent = JSON.stringify(requestModel);
    }
  } catch (error) {
    let serializationError = new Error(`Error "${error.message}" occurred in serializing the ` +
        `payload - ${JSON.stringify(jobSchedulePatchParameter, null, 2)}.`);
    return callback(serializationError);
  }
  httpRequest.body = requestContent;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Updates the properties of the specified Job Schedule.
 *
 * This fully replaces all the updatable properties of the Job Schedule. For
 * example, if the schedule property is not specified with this request, then
 * the Batch service will remove the existing schedule. Changes to a Job
 * Schedule only impact Jobs created by the schedule after the update has taken
 * place; currently running Jobs are unaffected.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to update.
 *
 * @param {object} jobScheduleUpdateParameter The parameters for the request.
 *
 * @param {object} jobScheduleUpdateParameter.schedule The schedule according
 * to which Jobs will be created. If you do not specify this element, it is
 * equivalent to passing the default schedule: that is, a single Job scheduled
 * to run immediately.
 *
 * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunUntil] The
 * earliest time at which any Job may be created under this Job Schedule. If
 * you do not specify a doNotRunUntil time, the schedule becomes ready to
 * create Jobs immediately.
 *
 * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunAfter] A time
 * after which no Job will be created under this Job Schedule. The schedule
 * will move to the completed state as soon as this deadline is past and there
 * is no active Job under this Job Schedule. If you do not specify a
 * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
 * Schedule will remain active until you explicitly terminate it.
 *
 * @param {moment.duration} [jobScheduleUpdateParameter.schedule.startWindow]
 * The time interval, starting from the time at which the schedule indicates a
 * Job should be created, within which a Job must be created. If a Job is not
 * created within the startWindow interval, then the 'opportunity' is lost; no
 * Job will be created until the next recurrence of the schedule. If the
 * schedule is recurring, and the startWindow is longer than the recurrence
 * interval, then this is equivalent to an infinite startWindow, because the
 * Job that is 'due' in one recurrenceInterval is not carried forward into the
 * next recurrence interval. The default is infinite. The minimum value is 1
 * minute. If you specify a lower value, the Batch service rejects the schedule
 * with an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.schedule.recurrenceInterval] The time interval
 * between the start times of two successive Jobs under the Job Schedule. A Job
 * Schedule can have at most one active Job under it at any given time. Because
 * a Job Schedule can have at most one active Job under it at any given time,
 * if it is time to create a new Job under a Job Schedule, but the previous Job
 * is still running, the Batch service will not create the new Job until the
 * previous Job finishes. If the previous Job does not finish within the
 * startWindow period of the new recurrenceInterval, then no new Job will be
 * scheduled for that interval. For recurring Jobs, you should normally specify
 * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
 * you will need an external process to monitor when Jobs are created, add
 * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
 * default is that the schedule does not recur: one Job is created, within the
 * startWindow after the doNotRunUntil time, and the schedule is complete as
 * soon as that Job finishes. The minimum value is 1 minute. If you specify a
 * lower value, the Batch service rejects the schedule with an error; if you
 * are calling the REST API directly, the HTTP status code is 400 (Bad
 * Request).
 *
 * @param {object} jobScheduleUpdateParameter.jobSpecification Details of the
 * Jobs to be created on this schedule. Updates affect only Jobs that are
 * started after the update has taken place. Any currently active Job continues
 * with the older specification.
 *
 * @param {number} [jobScheduleUpdateParameter.jobSpecification.priority] The
 * priority of Jobs created under this schedule. Priority values can range from
 * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
 * highest priority. The default value is 0. This priority is used as the
 * default for all Jobs under the Job Schedule. You can update a Job's priority
 * after it has been created using by using the update Job API.
 *
 * @param {string} [jobScheduleUpdateParameter.jobSpecification.displayName]
 * The display name for Jobs created under this schedule. The name need not be
 * unique and can contain any Unicode characters up to a maximum length of
 * 1024.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.usesTaskDependencies] Whether
 * Tasks in the Job can define dependencies on each other. The default is
 * false.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.onAllTasksComplete] The action
 * the Batch service should take when all Tasks in a Job created under this
 * schedule are in the completed state. Note that if a Job contains no Tasks,
 * then all Tasks are considered complete. This option is therefore most
 * commonly used with a Job Manager task; if you want to use automatic Job
 * termination without a Job Manager, you should initially set
 * onAllTasksComplete to noaction and update the Job properties to set
 * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
 * default is noaction. Possible values include: 'noAction', 'terminateJob'
 *
 * @param {string} [jobScheduleUpdateParameter.jobSpecification.onTaskFailure]
 * The action the Batch service should take when any Task fails in a Job
 * created under this schedule. A Task is considered to have failed if it have
 * failed if has a failureInfo. A failureInfo is set if the Task completes with
 * a non-zero exit code after exhausting its retry count, or if there was an
 * error starting the Task, for example due to a resource file download error.
 * The default is noaction. Possible values include: 'noAction',
 * 'performExitOptionsJobAction'
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.networkConfiguration] The
 * network configuration for the Job.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.networkConfiguration.subnetId
 * The ARM resource identifier of the virtual network subnet which Compute
 * Nodes running Tasks from the Job will join for the duration of the Task.
 * This will only work with a VirtualMachineConfiguration Pool. The virtual
 * network must be in the same region and subscription as the Azure Batch
 * Account. The specified subnet should have enough free IP addresses to
 * accommodate the number of Compute Nodes which will run Tasks from the Job.
 * This can be up to the number of Compute Nodes in the Pool. The
 * 'MicrosoftAzureBatch' service principal must have the 'Classic Virtual
 * Machine Contributor' Role-Based Access Control (RBAC) role for the specified
 * VNet so that Azure Batch service can schedule Tasks on the Nodes. This can
 * be verified by checking if the specified VNet has any associated Network
 * Security Groups (NSG). If communication to the Nodes in the specified subnet
 * is denied by an NSG, then the Batch service will set the state of the
 * Compute Nodes to unusable. This is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * If the specified VNet has any associated Network Security Groups (NSG), then
 * a few reserved system ports must be enabled for inbound communication from
 * the Azure Batch service. For Pools created with a Virtual Machine
 * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
 * and port 3389 for Windows. Port 443 is also required to be open for outbound
 * connections for communications to Azure Storage. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {object} [jobScheduleUpdateParameter.jobSpecification.constraints]
 * The execution constraints for Jobs created under this schedule.
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.constraints.maxWallClockTime]
 * The maximum elapsed time that the Job may run, measured from the time the
 * Job is created. If the Job does not complete within the time limit, the
 * Batch service terminates it and any Tasks that are still running. In this
 * case, the termination reason will be MaxWallClockTimeExpiry. If this
 * property is not specified, there is no time limit on how long the Job may
 * run.
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.constraints.maxTaskRetryCount]
 * The maximum number of times each Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries. The Batch service will try each
 * Task once, and may then retry up to this limit. For example, if the maximum
 * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
 * retries). If the maximum retry count is 0, the Batch service does not retry
 * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
 * without limit. The default value is 0 (no retries).
 *
 * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobManagerTask]
 * The details of a Job Manager Task to be launched when a Job is started under
 * this schedule. If the Job does not specify a Job Manager Task, the user must
 * explicitly add Tasks to the Job using the Task API. If the Job does specify
 * a Job Manager Task, the Batch service creates the Job Manager Task when the
 * Job is created, and will try to schedule the Job Manager Task before
 * scheduling other Tasks in the Job.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.id A string that
 * uniquely identifies the Job Manager Task within the Job. The ID can contain
 * any combination of alphanumeric characters including hyphens and underscores
 * and cannot contain more than 64 characters.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.displayName] The
 * display name of the Job Manager Task. It need not be unique and can contain
 * any Unicode characters up to a maximum length of 1024.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.commandLine The
 * command line of the Job Manager Task. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.containerSettings]
 * The settings for the container under which the Job Manager Task runs. If the
 * Pool that will run this Task has containerConfiguration set, this must be
 * set as well. If the Pool that will run this Task doesn't have
 * containerConfiguration set, this must not be set. When this is specified,
 * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
 * Azure Batch directories on the node) are mapped into the container, all Task
 * environment variables are mapped into the container, and the Task command
 * line is executed in the container. Files produced in the container outside
 * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
 * that Batch file APIs will not be able to access those files.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.resourceFiles] A
 * list of files that the Batch service will download to the Compute Node
 * before running the command line. Files listed under this element are located
 * in the Task's working directory. There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.outputFiles] A
 * list of files that the Batch service will upload from the Compute Node after
 * running the command line. For multi-instance Tasks, the files will only be
 * uploaded from the Compute Node on which the primary Task is executed.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.environmentSettings]
 * A list of environment variable settings for the Job Manager Task.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.constraints]
 * Constraints that apply to the Job Manager Task.
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.requiredSlots]
 * The number of scheduling slots that the Task requires to run. The default is
 * 1. A Task can only be scheduled to run on a compute node if the node has
 * enough free scheduling slots available. For multi-instance Tasks, this must
 * be 1.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
 * Whether completion of the Job Manager Task signifies completion of the
 * entire Job. If true, when the Job Manager Task completes, the Batch service
 * marks the Job as complete. If any Tasks are still running at this time
 * (other than Job Release), those Tasks are terminated. If false, the
 * completion of the Job Manager Task does not affect the Job status. In this
 * case, you should either use the onAllTasksComplete attribute to terminate
 * the Job, or have a client or user terminate the Job explicitly. An example
 * of this is if the Job Manager creates a set of Tasks but then takes no
 * further role in their execution. The default value is true. If you are using
 * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
 * and using the Job Manager Task only to create the Tasks for the Job (not to
 * monitor progress), then it is important to set killJobOnCompletion to false.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.userIdentity]
 * The user identity under which the Job Manager Task runs. If omitted, the
 * Task runs as a non-administrative user unique to the Task.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.runExclusive]
 * Whether the Job Manager Task requires exclusive use of the Compute Node
 * where it runs. If true, no other Tasks will run on the same Node for as long
 * as the Job Manager is running. If false, other Tasks can run simultaneously
 * with the Job Manager on a Compute Node. The Job Manager Task counts normally
 * against the Compute Node's concurrent Task limit, so this is only relevant
 * if the Compute Node allows multiple concurrent Tasks. The default value is
 * true.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
 * A list of Application Packages that the Batch service will deploy to the
 * Compute Node before running the command line. Application Packages are
 * downloaded and deployed to a shared directory, not the Task working
 * directory. Therefore, if a referenced Application Package is already on the
 * Compute Node, and is up to date, then it is not re-downloaded; the existing
 * copy on the Compute Node is used. If a referenced Application Package cannot
 * be installed, for example because the package has been deleted or because
 * download failed, the Task fails.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
 * The settings for an authentication token that the Task can use to perform
 * Batch service operations. If this property is set, the Batch service
 * provides the Task with an authentication token which can be used to
 * authenticate Batch service operations without requiring an Account access
 * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
 * variable. The operations that the Task can carry out using the token depend
 * on the settings. For example, a Task can request Job permissions in order to
 * add other Tasks to the Job, or check the status of the Job or of other Tasks
 * under the Job.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
 * The Batch resources to which the token grants access. The authentication
 * token grants access to a limited set of Batch service operations. Currently
 * the only supported value for the access property is 'job', which grants
 * access to all operations related to the Job which contains the Task.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
 * Whether the Job Manager Task may run on a low-priority Compute Node. The
 * default value is true.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask] The Job
 * Preparation Task for Jobs created under this schedule. If a Job has a Job
 * Preparation Task, the Batch service will run the Job Preparation Task on a
 * Node before starting any Tasks of that Job on that Compute Node.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.id] A string
 * that uniquely identifies the Job Preparation Task within the Job. The ID can
 * contain any combination of alphanumeric characters including hyphens and
 * underscores and cannot contain more than 64 characters. If you do not
 * specify this property, the Batch service assigns a default value of
 * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
 * Preparation Task. If you try to submit a Task with the same id, the Batch
 * service rejects the request with error code TaskIdSameAsJobPreparationTask;
 * if you are calling the REST API directly, the HTTP status code is 409
 * (Conflict).
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.commandLine
 * The command line of the Job Preparation Task. The command line does not run
 * under a shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.containerSettings]
 * The settings for the container under which the Job Preparation Task runs.
 * When this is specified, all directories recursively below the
 * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
 * mapped into the container, all Task environment variables are mapped into
 * the container, and the Task command line is executed in the container. Files
 * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
 * reflected to the host disk, meaning that Batch file APIs will not be able to
 * access those files.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.resourceFiles]
 * A list of files that the Batch service will download to the Compute Node
 * before running the command line. Files listed under this element are located
 * in the Task's working directory.  There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.environmentSettings]
 * A list of environment variable settings for the Job Preparation Task.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints]
 * Constraints that apply to the Job Preparation Task.
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
 * The maximum elapsed time that the Task may run, measured from the time the
 * Task starts. If the Task does not complete within the time limit, the Batch
 * service terminates it. If this is not specified, there is no time limit on
 * how long the Task may run.
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
 * The minimum time to retain the Task directory on the Compute Node where it
 * ran, from the time it completes execution. After this time, the Batch
 * service may delete the Task directory and all its contents. The default is 7
 * days, i.e. the Task directory will be retained for 7 days unless the Compute
 * Node is removed or the Job is deleted.
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries for the Task executable due to a
 * nonzero exit code. The Batch service will try the Task once, and may then
 * retry up to this limit. For example, if the maximum retry count is 3, Batch
 * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
 * retry count is 0, the Batch service does not retry the Task after the first
 * attempt. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.waitForSuccess]
 * Whether the Batch service should wait for the Job Preparation Task to
 * complete successfully before scheduling any other Tasks of the Job on the
 * Compute Node. A Job Preparation Task has completed successfully if it exits
 * with exit code 0. If true and the Job Preparation Task fails on a Node, the
 * Batch service retries the Job Preparation Task up to its maximum retry count
 * (as specified in the constraints element). If the Task has still not
 * completed successfully after all retries, then the Batch service will not
 * schedule Tasks of the Job to the Node. The Node remains active and eligible
 * to run Tasks of other Jobs. If false, the Batch service will not wait for
 * the Job Preparation Task to complete. In this case, other Tasks of the Job
 * can start executing on the Compute Node while the Job Preparation Task is
 * still running; and even if the Job Preparation Task fails, new Tasks will
 * continue to be scheduled on the Compute Node. The default value is true.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.userIdentity]
 * The user identity under which the Job Preparation Task runs. If omitted, the
 * Task runs as a non-administrative user unique to the Task on Windows Compute
 * Nodes, or a non-administrative user unique to the Pool on Linux Compute
 * Nodes.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
 * Whether the Batch service should rerun the Job Preparation Task after a
 * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
 * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
 * because the reboot occurred while the Task was running). Therefore, you
 * should always write a Job Preparation Task to be idempotent and to behave
 * correctly if run multiple times. The default value is true.
 *
 * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask]
 * The Job Release Task for Jobs created under this schedule. The primary
 * purpose of the Job Release Task is to undo changes to Nodes made by the Job
 * Preparation Task. Example activities include deleting local files, or
 * shutting down services that were started as part of Job preparation. A Job
 * Release Task cannot be specified without also specifying a Job Preparation
 * Task for the Job. The Batch service runs the Job Release Task on the Compute
 * Nodes that have run the Job Preparation Task.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.id] A string
 * that uniquely identifies the Job Release Task within the Job. The ID can
 * contain any combination of alphanumeric characters including hyphens and
 * underscores and cannot contain more than 64 characters. If you do not
 * specify this property, the Batch service assigns a default value of
 * 'jobrelease'. No other Task in the Job can have the same ID as the Job
 * Release Task. If you try to submit a Task with the same id, the Batch
 * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
 * you are calling the REST API directly, the HTTP status code is 409
 * (Conflict).
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.commandLine The
 * command line of the Job Release Task. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.containerSettings]
 * The settings for the container under which the Job Release Task runs. When
 * this is specified, all directories recursively below the
 * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
 * mapped into the container, all Task environment variables are mapped into
 * the container, and the Task command line is executed in the container. Files
 * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
 * reflected to the host disk, meaning that Batch file APIs will not be able to
 * access those files.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.resourceFiles] A
 * list of files that the Batch service will download to the Compute Node
 * before running the command line.  There is a maximum size for the list of
 * resource files.  When the max size is exceeded, the request will fail and
 * the response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.environmentSettings]
 * A list of environment variable settings for the Job Release Task.
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
 * The maximum elapsed time that the Job Release Task may run on a given
 * Compute Node, measured from the time the Task starts. If the Task does not
 * complete within the time limit, the Batch service terminates it. The default
 * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
 * If you do, the Batch service rejects it with an error; if you are calling
 * the REST API directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.retentionTime]
 * The minimum time to retain the Task directory for the Job Release Task on
 * the Compute Node. After this time, the Batch service may delete the Task
 * directory and all its contents. The default is 7 days, i.e. the Task
 * directory will be retained for 7 days unless the Compute Node is removed or
 * the Job is deleted.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.userIdentity]
 * The user identity under which the Job Release Task runs. If omitted, the
 * Task runs as a non-administrative user unique to the Task.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.commonEnvironmentSettings] A
 * list of common environment variable settings. These environment variables
 * are set for all Tasks in Jobs created under this schedule (including the Job
 * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
 * override an environment setting specified here by specifying the same
 * setting name with a different value.
 *
 * @param {object} jobScheduleUpdateParameter.jobSpecification.poolInfo The
 * Pool on which the Batch service runs the Tasks of Jobs created under this
 * schedule.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.poolId] The ID of an
 * existing Pool. All the Tasks of the Job will run on the specified Pool. You
 * must ensure that the Pool referenced by this property exists. If the Pool
 * does not exist at the time the Batch service tries to schedule a Job, no
 * Tasks for the Job will run until you create a Pool with that id. Note that
 * the Batch service will not reject the Job request; it will simply not run
 * Tasks until the Pool exists. You must specify either the Pool ID or the auto
 * Pool specification, but not both.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification]
 * Characteristics for a temporary 'auto pool'. The Batch service will create
 * this auto Pool when the Job is submitted. If auto Pool creation fails, the
 * Batch service moves the Job to a completed state, and the Pool creation
 * error is set in the Job's scheduling error property. The Batch service
 * manages the lifetime (both creation and, unless keepAlive is specified,
 * deletion) of the auto Pool. Any user actions that affect the lifetime of the
 * auto Pool while the Job is active will result in unexpected behavior. You
 * must specify either the Pool ID or the auto Pool specification, but not
 * both.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
 * A prefix to be added to the unique identifier when a Pool is automatically
 * created. The Batch service assigns each auto Pool a unique identifier on
 * creation. To distinguish between Pools created for different purposes, you
 * can specify this element to add a prefix to the ID that is assigned. The
 * prefix can be up to 20 characters long.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
 * The minimum lifetime of created auto Pools, and how multiple Jobs on a
 * schedule are assigned to Pools. Possible values include: 'jobSchedule',
 * 'job'
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
 * Whether to keep an auto Pool alive after its lifetime expires. If false, the
 * Batch service deletes the Pool once its lifetime (as determined by the
 * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
 * completes. If true, the Batch service does not delete the Pool
 * automatically. It is up to the user to delete auto Pools created with this
 * option.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
 * The Pool specification for the auto Pool.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
 * The display name for the Pool. The display name need not be unique and can
 * contain any Unicode characters up to a maximum length of 1024.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
 * The size of the virtual machines in the Pool. All virtual machines in a Pool
 * are the same size. For information about available sizes of virtual machines
 * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
 * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
 * The cloud service configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure PaaS VMs. This property
 * and virtualMachineConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request). This property cannot be specified if the Batch
 * Account was created with its poolAllocationMode property set to
 * 'UserSubscription'.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
 * The Azure Guest OS family to be installed on the virtual machines in the
 * Pool. Possible values are:
 * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
 * 3 - OS Family 3, equivalent to Windows Server 2012.
 * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
 * 5 - OS Family 5, equivalent to Windows Server 2016.
 * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
 * see Azure Guest OS Releases
 * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
 * The Azure Guest OS version to be installed on the virtual machines in the
 * Pool. The default value is * which specifies the latest operating system
 * version for the specified OS family.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
 * The virtual machine configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure IaaS VMs. This property
 * and cloudServiceConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {object}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
 * A reference to the Azure Virtual Machines Marketplace Image or the custom
 * Virtual Machine Image to use.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
 * The publisher of the Azure Virtual Machines Marketplace Image. For example,
 * Canonical or MicrosoftWindowsServer.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
 * The offer type of the Azure Virtual Machines Marketplace Image. For example,
 * UbuntuServer or WindowsServer.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
 * The SKU of the Azure Virtual Machines Marketplace Image. For example,
 * 18.04-LTS or 2019-Datacenter.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
 * The version of the Azure Virtual Machines Marketplace Image. A value of
 * 'latest' can be specified to select the latest version of an Image. If
 * omitted, the default is 'latest'.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
 * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
 * in the Pool will be created using this Image Id. This is of the form
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
 * or
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
 * for always defaulting to the latest image version. This property is mutually
 * exclusive with other ImageReference properties. The Shared Image Gallery
 * Image must have replicas in the same region and must be in the same
 * subscription as the Azure Batch account. If the image version is not
 * specified in the imageId, the latest version will be used. For information
 * about the firewall settings for the Batch Compute Node agent to communicate
 * with the Batch service see
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
 * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
 * in the Pool. The Batch Compute Node agent is a program that runs on each
 * Compute Node in the Pool, and provides the command-and-control interface
 * between the Compute Node and the Batch service. There are different
 * implementations of the Compute Node agent, known as SKUs, for different
 * operating systems. You must specify a Compute Node agent SKU which matches
 * the selected Image reference. To get the list of supported Compute Node
 * agent SKUs along with their list of verified Image references, see the 'List
 * supported Compute Node agent SKUs' operation.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
 * Windows operating system settings on the virtual machine. This property must
 * not be specified if the imageReference property specifies a Linux OS Image.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
 * Whether automatic updates are enabled on the virtual machine. If omitted,
 * the default value is true.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
 * The configuration for data disks attached to the Compute Nodes in the Pool.
 * This property must be specified if the Compute Nodes in the Pool need to
 * have empty data disks attached to them. This cannot be updated. Each Compute
 * Node gets its own disk (the disk is not a file share). Existing disks cannot
 * be attached, each attached disk is empty. When the Compute Node is removed
 * from the Pool, the disk and all data associated with it is also deleted. The
 * disk is not formatted after being attached, it must be formatted before use
 * - for more information see
 * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
 * and
 * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
 * The type of on-premises license to be used when deploying the operating
 * system. This only applies to Images that contain the Windows operating
 * system, and should only be used when you hold valid on-premises licenses for
 * the Compute Nodes which will be deployed. If omitted, no on-premises
 * licensing discount is applied. Values are:
 *
 * Windows_Server - The on-premises license is for Windows Server.
 * Windows_Client - The on-premises license is for Windows Client.
 *
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
 * The container configuration for the Pool. If specified, setup is performed
 * on each Compute Node in the Pool to allow Tasks to run in containers. All
 * regular Tasks and Job manager Tasks run on this Pool must specify the
 * containerSettings property, and all other Tasks may specify it.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
 * The collection of container Image names. This is the full Image reference,
 * as would be specified to "docker pull". An Image will be sourced from the
 * default Docker registry unless the Image is fully qualified with an
 * alternative registry.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
 * Additional private registries from which containers can be pulled. If any
 * Images must be downloaded from a private registry which requires
 * credentials, then those credentials must be provided here.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
 * The disk encryption configuration for the pool. If specified, encryption is
 * performed on each node in the pool during node provisioning.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
 * The list of disk targets Batch Service will encrypt on the compute node. If
 * omitted, no disks on the compute nodes in the pool will be encrypted. On
 * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
 * "TemporaryDisk" must be specified.
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
 * The number of task slots that can be used to run concurrent tasks on a
 * single compute node in the pool. The default value is 1. The maximum value
 * is the smaller of 4 times the number of cores of the vmSize of the pool or
 * 256.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread. Possible values include: 'spread', 'pack'
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
 * The timeout for allocation of Compute Nodes to the Pool. This timeout
 * applies only to manual scaling; it has no effect when enableAutoScale is set
 * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
 * you specify a value less than 5 minutes, the Batch service rejects the
 * request with an error; if you are calling the REST API directly, the HTTP
 * status code is 400 (Bad Request).
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
 * The desired number of dedicated Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
 * The desired number of low-priority Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
 * Whether the Pool size should automatically adjust over time. If false, at
 * least one of targetDedicateNodes and targetLowPriorityNodes must be
 * specified. If true, the autoScaleFormula element is required. The Pool
 * automatically resizes according to the formula. The default value is false.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
 * The formula for the desired number of Compute Nodes in the Pool. This
 * property must not be specified if enableAutoScale is set to false. It is
 * required if enableAutoScale is set to true. The formula is checked for
 * validity before the Pool is created. If the formula is not valid, the Batch
 * service rejects the request with detailed error information.
 *
 * @param {moment.duration}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
 * The time interval at which to automatically adjust the Pool size according
 * to the autoscale formula. The default value is 15 minutes. The minimum and
 * maximum value are 5 minutes and 168 hours respectively. If you specify a
 * value less than 5 minutes or greater than 168 hours, the Batch service
 * rejects the request with an invalid property value error; if you are calling
 * the REST API directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
 * Whether the Pool permits direct communication between Compute Nodes.
 * Enabling inter-node communication limits the maximum size of the Pool due to
 * deployment restrictions on the Compute Nodes of the Pool. This may result in
 * the Pool not reaching its desired size. The default value is false.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
 * The network configuration for the Pool.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
 * The ARM resource identifier of the virtual network subnet which the Compute
 * Nodes of the Pool will join. This is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * The virtual network must be in the same region and subscription as the Azure
 * Batch Account. The specified subnet should have enough free IP addresses to
 * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
 * have enough free IP addresses, the Pool will partially allocate Nodes and a
 * resize error will occur. The 'MicrosoftAzureBatch' service principal must
 * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
 * (RBAC) role for the specified VNet. The specified subnet must allow
 * communication from the Azure Batch service to be able to schedule Tasks on
 * the Nodes. This can be verified by checking if the specified VNet has any
 * associated Network Security Groups (NSG). If communication to the Nodes in
 * the specified subnet is denied by an NSG, then the Batch service will set
 * the state of the Compute Nodes to unusable. For Pools created with
 * virtualMachineConfiguration only ARM virtual networks
 * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
 * with cloudServiceConfiguration both ARM and classic virtual networks are
 * supported. If the specified VNet has any associated Network Security Groups
 * (NSG), then a few reserved system ports must be enabled for inbound
 * communication. For Pools created with a virtual machine configuration,
 * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
 * Windows. For Pools created with a cloud service configuration, enable ports
 * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
 * on port 443. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
 * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
 * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
 * endpoint configuration is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {array}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
 * A list of inbound NAT Pools that can be used to address specific ports on an
 * individual Compute Node externally. The maximum number of inbound NAT Pools
 * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
 * the request fails with HTTP status code 400. This cannot be specified if the
 * IPAddressProvisioningType is NoPublicIPAddresses.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
 * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
 * Public IP configuration property is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
 * The provisioning type for Public IP Addresses for the Pool. The default
 * value is BatchManaged. Possible values include: 'batchManaged',
 * 'userManaged', 'noPublicIPAddresses'
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
 * The list of public IPs which the Batch service will use when provisioning
 * Compute Nodes. The number of IPs specified here limits the maximum size of
 * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
 * for each public IP. For example, a pool needing 250 dedicated VMs would need
 * at least 3 public IPs specified. Each element of this collection is of the
 * form:
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
 * A Task to run on each Compute Node as it joins the Pool. The Task runs when
 * the Compute Node is added to the Pool or when the Compute Node is restarted.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
 * The command line of the StartTask. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
 * The settings for the container under which the StartTask runs. When this is
 * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
 * root of Azure Batch directories on the node) are mapped into the container,
 * all Task environment variables are mapped into the container, and the Task
 * command line is executed in the container. Files produced in the container
 * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
 * meaning that Batch file APIs will not be able to access those files.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
 * Additional options to the container create command. These additional options
 * are supplied as arguments to the "docker create" command, in addition to
 * those controlled by the Batch Service.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
 * The Image to use to create the container in which the Task will run. This is
 * the full Image reference, as would be specified to "docker pull". If no tag
 * is provided as part of the Image name, the tag ":latest" is used as a
 * default.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
 * The private registry which contains the container Image. This setting can be
 * omitted if was already provided at Pool creation.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
 * The registry URL. If omitted, the default is "docker.io".
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
 * The user name to log into the registry server.
 *
 * @param {string}
 * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
 * The password to log into the registry server.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
 * The location of the container Task working directory. The default is
 * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
 * 'containerImageDefault'
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
 * A list of files that the Batch service will download to the Compute Node
 * before running the command line.  There is a maximum size for the list of
 * resource files. When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
 * A list of environment variable settings for the StartTask.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
 * The user identity under which the StartTask runs. If omitted, the Task runs
 * as a non-administrative user unique to the Task.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
 * The name of the user identity under which the Task is run. The userName and
 * autoUser properties are mutually exclusive; you must specify one but not
 * both.
 *
 * @param {object}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
 * The auto user under which the Task is run. The userName and autoUser
 * properties are mutually exclusive; you must specify one but not both.
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
 * The scope for the auto user The default value is pool. If the pool is
 * running Windows a value of Task should be specified if stricter isolation
 * between tasks is required. For example, if the task mutates the registry in
 * a way which could impact other tasks, or if certificates have been specified
 * on the pool which should not be accessible by normal tasks but should be
 * accessible by StartTasks. Possible values include: 'task', 'pool'
 *
 * @param {string}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
 * The elevation level of the auto user. The default value is nonAdmin.
 * Possible values include: 'nonAdmin', 'admin'
 *
 * @param {number}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries. The Batch service will try the
 * Task once, and may then retry up to this limit. For example, if the maximum
 * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
 * retries). If the maximum retry count is 0, the Batch service does not retry
 * the Task. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
 * Whether the Batch service should wait for the StartTask to complete
 * successfully (that is, to exit with exit code 0) before scheduling any Tasks
 * on the Compute Node. If true and the StartTask fails on a Node, the Batch
 * service retries the StartTask up to its maximum retry count
 * (maxTaskRetryCount). If the Task has still not completed successfully after
 * all retries, then the Batch service marks the Node unusable, and will not
 * schedule Tasks to it. This condition can be detected via the Compute Node
 * state and failure info details. If false, the Batch service will not wait
 * for the StartTask to complete. In this case, other Tasks can start executing
 * on the Compute Node while the StartTask is still running; and even if the
 * StartTask fails, new Tasks will continue to be scheduled on the Compute
 * Node. The default is true.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
 * A list of Certificates to be installed on each Compute Node in the Pool. For
 * Windows Nodes, the Batch service installs the Certificates to the specified
 * Certificate store and location. For Linux Compute Nodes, the Certificates
 * are stored in a directory inside the Task working directory and an
 * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
 * query for this location. For Certificates with visibility of 'remoteUser', a
 * 'certs' directory is created in the user's home directory (e.g.,
 * /home/{user-name}/certs) and Certificates are placed in that directory.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
 * The list of Packages to be installed on each Compute Node in the Pool.
 * Changes to Package references affect all new Nodes joining the Pool, but do
 * not affect Compute Nodes that are already in the Pool until they are
 * rebooted or reimaged. There is a maximum of 10 Package references on any
 * given Pool.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
 * The list of application licenses the Batch service will make available on
 * each Compute Node in the Pool. The list of application licenses must be a
 * subset of available Batch service application licenses. If a license is
 * requested which is not supported, Pool creation will fail. The permitted
 * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
 * additional charge applies for each application license added to the Pool.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
 * The list of user Accounts to be created on each Compute Node in the Pool.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
 * A list of name-value pairs associated with the Pool as metadata. The Batch
 * service does not assign any meaning to metadata; it is solely for the use of
 * user code.
 *
 * @param {array}
 * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
 * A list of file systems to mount on each node in the pool. This supports
 * Azure Files, NFS, CIFS/SMB, and Blobfuse.
 *
 * @param {array} [jobScheduleUpdateParameter.jobSpecification.metadata] A list
 * of name-value pairs associated with each Job created under this schedule as
 * metadata. The Batch service does not assign any meaning to metadata; it is
 * solely for the use of user code.
 *
 * @param {array} [jobScheduleUpdateParameter.metadata] A list of name-value
 * pairs associated with the Job Schedule as metadata. If you do not specify
 * this element, it takes the default value of an empty list; in effect, any
 * existing metadata is deleted.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleUpdateOptions] Additional parameters for
 * the operation
 *
 * @param {number} [options.jobScheduleUpdateOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleUpdateOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleUpdateOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleUpdateOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleUpdateOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleUpdateOptions.ifNoneMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleUpdateOptions.ifModifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has been
 * modified since the specified time.
 *
 * @param {date} [options.jobScheduleUpdateOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _update(jobScheduleId, jobScheduleUpdateParameter, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleUpdateOptions = (options && options.jobScheduleUpdateOptions !== undefined) ? options.jobScheduleUpdateOptions : undefined;
  if (jobScheduleUpdateParameter === null || jobScheduleUpdateParameter === undefined)
  {
    jobScheduleUpdateParameter = {};
  }
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleUpdateParameter === null || jobScheduleUpdateParameter === undefined) {
      throw new Error('jobScheduleUpdateParameter cannot be null or undefined.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      timeout = jobScheduleUpdateOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      clientRequestId = jobScheduleUpdateOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      returnClientRequestId = jobScheduleUpdateOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      ocpDate = jobScheduleUpdateOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      ifMatch = jobScheduleUpdateOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      ifNoneMatch = jobScheduleUpdateOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      ifModifiedSince = jobScheduleUpdateOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleUpdateOptions !== null && jobScheduleUpdateOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleUpdateOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'PUT';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  // Serialize Request
  let requestContent = null;
  let requestModel = null;
  try {
    if (jobScheduleUpdateParameter !== null && jobScheduleUpdateParameter !== undefined) {
      let requestModelMapper = new client.models['JobScheduleUpdateParameter']().mapper();
      requestModel = client.serialize(requestModelMapper, jobScheduleUpdateParameter, 'jobScheduleUpdateParameter');
      requestContent = JSON.stringify(requestModel);
    }
  } catch (error) {
    let serializationError = new Error(`Error "${error.message}" occurred in serializing the ` +
        `payload - ${JSON.stringify(jobScheduleUpdateParameter, null, 2)}.`);
    return callback(serializationError);
  }
  httpRequest.body = requestContent;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Disables a Job Schedule.
 *
 * No new Jobs will be created until the Job Schedule is enabled again.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to disable.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleDisableOptions] Additional parameters
 * for the operation
 *
 * @param {number} [options.jobScheduleDisableOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleDisableOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleDisableOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleDisableOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleDisableOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleDisableOptions.ifNoneMatch] An ETag
 * value associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleDisableOptions.ifModifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has been modified since the specified time.
 *
 * @param {date} [options.jobScheduleDisableOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _disable(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleDisableOptions = (options && options.jobScheduleDisableOptions !== undefined) ? options.jobScheduleDisableOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      timeout = jobScheduleDisableOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      clientRequestId = jobScheduleDisableOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      returnClientRequestId = jobScheduleDisableOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      ocpDate = jobScheduleDisableOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      ifMatch = jobScheduleDisableOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      ifNoneMatch = jobScheduleDisableOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      ifModifiedSince = jobScheduleDisableOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleDisableOptions !== null && jobScheduleDisableOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleDisableOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}/disable';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'POST';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 204) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Enables a Job Schedule.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to enable.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleEnableOptions] Additional parameters for
 * the operation
 *
 * @param {number} [options.jobScheduleEnableOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleEnableOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleEnableOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleEnableOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleEnableOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleEnableOptions.ifNoneMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleEnableOptions.ifModifiedSince] A timestamp
 * indicating the last modified time of the resource known to the client. The
 * operation will be performed only if the resource on the service has been
 * modified since the specified time.
 *
 * @param {date} [options.jobScheduleEnableOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _enable(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleEnableOptions = (options && options.jobScheduleEnableOptions !== undefined) ? options.jobScheduleEnableOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      timeout = jobScheduleEnableOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      clientRequestId = jobScheduleEnableOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      returnClientRequestId = jobScheduleEnableOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      ocpDate = jobScheduleEnableOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      ifMatch = jobScheduleEnableOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      ifNoneMatch = jobScheduleEnableOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      ifModifiedSince = jobScheduleEnableOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleEnableOptions !== null && jobScheduleEnableOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleEnableOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}/enable';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'POST';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 204) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Terminates a Job Schedule.
 *
 * @param {string} jobScheduleId The ID of the Job Schedule to terminates.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleTerminateOptions] Additional parameters
 * for the operation
 *
 * @param {number} [options.jobScheduleTerminateOptions.timeout] The maximum
 * time that the server can spend processing the request, in seconds. The
 * default is 30 seconds.
 *
 * @param {uuid} [options.jobScheduleTerminateOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleTerminateOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleTerminateOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {string} [options.jobScheduleTerminateOptions.ifMatch] An ETag value
 * associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service exactly matches the value specified by the client.
 *
 * @param {string} [options.jobScheduleTerminateOptions.ifNoneMatch] An ETag
 * value associated with the version of the resource known to the client. The
 * operation will be performed only if the resource's current ETag on the
 * service does not match the value specified by the client.
 *
 * @param {date} [options.jobScheduleTerminateOptions.ifModifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has been modified since the specified time.
 *
 * @param {date} [options.jobScheduleTerminateOptions.ifUnmodifiedSince] A
 * timestamp indicating the last modified time of the resource known to the
 * client. The operation will be performed only if the resource on the service
 * has not been modified since the specified time.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _terminate(jobScheduleId, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleTerminateOptions = (options && options.jobScheduleTerminateOptions !== undefined) ? options.jobScheduleTerminateOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (jobScheduleId === null || jobScheduleId === undefined || typeof jobScheduleId.valueOf() !== 'string') {
      throw new Error('jobScheduleId cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  let ifMatch;
  let ifNoneMatch;
  let ifModifiedSince;
  let ifUnmodifiedSince;
  try {
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      timeout = jobScheduleTerminateOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      clientRequestId = jobScheduleTerminateOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      returnClientRequestId = jobScheduleTerminateOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      ocpDate = jobScheduleTerminateOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      ifMatch = jobScheduleTerminateOptions.ifMatch;
      if (ifMatch !== null && ifMatch !== undefined && typeof ifMatch.valueOf() !== 'string') {
        throw new Error('ifMatch must be of type string.');
      }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      ifNoneMatch = jobScheduleTerminateOptions.ifNoneMatch;
      if (ifNoneMatch !== null && ifNoneMatch !== undefined && typeof ifNoneMatch.valueOf() !== 'string') {
        throw new Error('ifNoneMatch must be of type string.');
      }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      ifModifiedSince = jobScheduleTerminateOptions.ifModifiedSince;
      if (ifModifiedSince && !(ifModifiedSince instanceof Date ||
          (typeof ifModifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifModifiedSince))))) {
            throw new Error('ifModifiedSince must be of type date.');
          }
    }
    if (jobScheduleTerminateOptions !== null && jobScheduleTerminateOptions !== undefined) {
      ifUnmodifiedSince = jobScheduleTerminateOptions.ifUnmodifiedSince;
      if (ifUnmodifiedSince && !(ifUnmodifiedSince instanceof Date ||
          (typeof ifUnmodifiedSince.valueOf() === 'string' && !isNaN(Date.parse(ifUnmodifiedSince))))) {
            throw new Error('ifUnmodifiedSince must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules/{jobScheduleId}/terminate';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  requestUrl = requestUrl.replace('{jobScheduleId}', encodeURIComponent(jobScheduleId));
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'POST';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if (ifMatch !== undefined && ifMatch !== null) {
    httpRequest.headers['If-Match'] = ifMatch;
  }
  if (ifNoneMatch !== undefined && ifNoneMatch !== null) {
    httpRequest.headers['If-None-Match'] = ifNoneMatch;
  }
  if (ifModifiedSince !== undefined && ifModifiedSince !== null) {
    httpRequest.headers['If-Modified-Since'] = ifModifiedSince.toUTCString();
  }
  if (ifUnmodifiedSince !== undefined && ifUnmodifiedSince !== null) {
    httpRequest.headers['If-Unmodified-Since'] = ifUnmodifiedSince.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 202) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Adds a Job Schedule to the specified Account.
 *
 * @param {object} cloudJobSchedule The Job Schedule to be added.
 *
 * @param {string} cloudJobSchedule.id A string that uniquely identifies the
 * schedule within the Account. The ID can contain any combination of
 * alphanumeric characters including hyphens and underscores, and cannot
 * contain more than 64 characters. The ID is case-preserving and
 * case-insensitive (that is, you may not have two IDs within an Account that
 * differ only by case).
 *
 * @param {string} [cloudJobSchedule.displayName] The display name for the
 * schedule. The display name need not be unique and can contain any Unicode
 * characters up to a maximum length of 1024.
 *
 * @param {object} cloudJobSchedule.schedule The schedule according to which
 * Jobs will be created.
 *
 * @param {date} [cloudJobSchedule.schedule.doNotRunUntil] The earliest time at
 * which any Job may be created under this Job Schedule. If you do not specify
 * a doNotRunUntil time, the schedule becomes ready to create Jobs immediately.
 *
 * @param {date} [cloudJobSchedule.schedule.doNotRunAfter] A time after which
 * no Job will be created under this Job Schedule. The schedule will move to
 * the completed state as soon as this deadline is past and there is no active
 * Job under this Job Schedule. If you do not specify a doNotRunAfter time, and
 * you are creating a recurring Job Schedule, the Job Schedule will remain
 * active until you explicitly terminate it.
 *
 * @param {moment.duration} [cloudJobSchedule.schedule.startWindow] The time
 * interval, starting from the time at which the schedule indicates a Job
 * should be created, within which a Job must be created. If a Job is not
 * created within the startWindow interval, then the 'opportunity' is lost; no
 * Job will be created until the next recurrence of the schedule. If the
 * schedule is recurring, and the startWindow is longer than the recurrence
 * interval, then this is equivalent to an infinite startWindow, because the
 * Job that is 'due' in one recurrenceInterval is not carried forward into the
 * next recurrence interval. The default is infinite. The minimum value is 1
 * minute. If you specify a lower value, the Batch service rejects the schedule
 * with an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {moment.duration} [cloudJobSchedule.schedule.recurrenceInterval] The
 * time interval between the start times of two successive Jobs under the Job
 * Schedule. A Job Schedule can have at most one active Job under it at any
 * given time. Because a Job Schedule can have at most one active Job under it
 * at any given time, if it is time to create a new Job under a Job Schedule,
 * but the previous Job is still running, the Batch service will not create the
 * new Job until the previous Job finishes. If the previous Job does not finish
 * within the startWindow period of the new recurrenceInterval, then no new Job
 * will be scheduled for that interval. For recurring Jobs, you should normally
 * specify a jobManagerTask in the jobSpecification. If you do not use
 * jobManagerTask, you will need an external process to monitor when Jobs are
 * created, add Tasks to the Jobs and terminate the Jobs ready for the next
 * recurrence. The default is that the schedule does not recur: one Job is
 * created, within the startWindow after the doNotRunUntil time, and the
 * schedule is complete as soon as that Job finishes. The minimum value is 1
 * minute. If you specify a lower value, the Batch service rejects the schedule
 * with an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {object} cloudJobSchedule.jobSpecification The details of the Jobs to
 * be created on this schedule.
 *
 * @param {number} [cloudJobSchedule.jobSpecification.priority] The priority of
 * Jobs created under this schedule. Priority values can range from -1000 to
 * 1000, with -1000 being the lowest priority and 1000 being the highest
 * priority. The default value is 0. This priority is used as the default for
 * all Jobs under the Job Schedule. You can update a Job's priority after it
 * has been created using by using the update Job API.
 *
 * @param {string} [cloudJobSchedule.jobSpecification.displayName] The display
 * name for Jobs created under this schedule. The name need not be unique and
 * can contain any Unicode characters up to a maximum length of 1024.
 *
 * @param {boolean} [cloudJobSchedule.jobSpecification.usesTaskDependencies]
 * Whether Tasks in the Job can define dependencies on each other. The default
 * is false.
 *
 * @param {string} [cloudJobSchedule.jobSpecification.onAllTasksComplete] The
 * action the Batch service should take when all Tasks in a Job created under
 * this schedule are in the completed state. Note that if a Job contains no
 * Tasks, then all Tasks are considered complete. This option is therefore most
 * commonly used with a Job Manager task; if you want to use automatic Job
 * termination without a Job Manager, you should initially set
 * onAllTasksComplete to noaction and update the Job properties to set
 * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
 * default is noaction. Possible values include: 'noAction', 'terminateJob'
 *
 * @param {string} [cloudJobSchedule.jobSpecification.onTaskFailure] The action
 * the Batch service should take when any Task fails in a Job created under
 * this schedule. A Task is considered to have failed if it have failed if has
 * a failureInfo. A failureInfo is set if the Task completes with a non-zero
 * exit code after exhausting its retry count, or if there was an error
 * starting the Task, for example due to a resource file download error. The
 * default is noaction. Possible values include: 'noAction',
 * 'performExitOptionsJobAction'
 *
 * @param {object} [cloudJobSchedule.jobSpecification.networkConfiguration] The
 * network configuration for the Job.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.networkConfiguration.subnetId The ARM
 * resource identifier of the virtual network subnet which Compute Nodes
 * running Tasks from the Job will join for the duration of the Task. This will
 * only work with a VirtualMachineConfiguration Pool. The virtual network must
 * be in the same region and subscription as the Azure Batch Account. The
 * specified subnet should have enough free IP addresses to accommodate the
 * number of Compute Nodes which will run Tasks from the Job. This can be up to
 * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
 * principal must have the 'Classic Virtual Machine Contributor' Role-Based
 * Access Control (RBAC) role for the specified VNet so that Azure Batch
 * service can schedule Tasks on the Nodes. This can be verified by checking if
 * the specified VNet has any associated Network Security Groups (NSG). If
 * communication to the Nodes in the specified subnet is denied by an NSG, then
 * the Batch service will set the state of the Compute Nodes to unusable. This
 * is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * If the specified VNet has any associated Network Security Groups (NSG), then
 * a few reserved system ports must be enabled for inbound communication from
 * the Azure Batch service. For Pools created with a Virtual Machine
 * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
 * and port 3389 for Windows. Port 443 is also required to be open for outbound
 * connections for communications to Azure Storage. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {object} [cloudJobSchedule.jobSpecification.constraints] The
 * execution constraints for Jobs created under this schedule.
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.constraints.maxWallClockTime] The maximum
 * elapsed time that the Job may run, measured from the time the Job is
 * created. If the Job does not complete within the time limit, the Batch
 * service terminates it and any Tasks that are still running. In this case,
 * the termination reason will be MaxWallClockTimeExpiry. If this property is
 * not specified, there is no time limit on how long the Job may run.
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.constraints.maxTaskRetryCount] The
 * maximum number of times each Task may be retried. The Batch service retries
 * a Task if its exit code is nonzero. Note that this value specifically
 * controls the number of retries. The Batch service will try each Task once,
 * and may then retry up to this limit. For example, if the maximum retry count
 * is 3, Batch tries a Task up to 4 times (one initial try and 3 retries). If
 * the maximum retry count is 0, the Batch service does not retry Tasks. If the
 * maximum retry count is -1, the Batch service retries Tasks without limit.
 * The default value is 0 (no retries).
 *
 * @param {object} [cloudJobSchedule.jobSpecification.jobManagerTask] The
 * details of a Job Manager Task to be launched when a Job is started under
 * this schedule. If the Job does not specify a Job Manager Task, the user must
 * explicitly add Tasks to the Job using the Task API. If the Job does specify
 * a Job Manager Task, the Batch service creates the Job Manager Task when the
 * Job is created, and will try to schedule the Job Manager Task before
 * scheduling other Tasks in the Job.
 *
 * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.id A string
 * that uniquely identifies the Job Manager Task within the Job. The ID can
 * contain any combination of alphanumeric characters including hyphens and
 * underscores and cannot contain more than 64 characters.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.displayName] The display
 * name of the Job Manager Task. It need not be unique and can contain any
 * Unicode characters up to a maximum length of 1024.
 *
 * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.commandLine
 * The command line of the Job Manager Task. The command line does not run
 * under a shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.containerSettings] The
 * settings for the container under which the Job Manager Task runs. If the
 * Pool that will run this Task has containerConfiguration set, this must be
 * set as well. If the Pool that will run this Task doesn't have
 * containerConfiguration set, this must not be set. When this is specified,
 * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
 * Azure Batch directories on the node) are mapped into the container, all Task
 * environment variables are mapped into the container, and the Task command
 * line is executed in the container. Files produced in the container outside
 * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
 * that Batch file APIs will not be able to access those files.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.resourceFiles] A list of
 * files that the Batch service will download to the Compute Node before
 * running the command line. Files listed under this element are located in the
 * Task's working directory. There is a maximum size for the list of resource
 * files.  When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.outputFiles] A list of
 * files that the Batch service will upload from the Compute Node after running
 * the command line. For multi-instance Tasks, the files will only be uploaded
 * from the Compute Node on which the primary Task is executed.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.environmentSettings] A
 * list of environment variable settings for the Job Manager Task.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.constraints] Constraints
 * that apply to the Job Manager Task.
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.requiredSlots] The number
 * of scheduling slots that the Task requires to run. The default is 1. A Task
 * can only be scheduled to run on a compute node if the node has enough free
 * scheduling slots available. For multi-instance Tasks, this must be 1.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.killJobOnCompletion]
 * Whether completion of the Job Manager Task signifies completion of the
 * entire Job. If true, when the Job Manager Task completes, the Batch service
 * marks the Job as complete. If any Tasks are still running at this time
 * (other than Job Release), those Tasks are terminated. If false, the
 * completion of the Job Manager Task does not affect the Job status. In this
 * case, you should either use the onAllTasksComplete attribute to terminate
 * the Job, or have a client or user terminate the Job explicitly. An example
 * of this is if the Job Manager creates a set of Tasks but then takes no
 * further role in their execution. The default value is true. If you are using
 * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
 * and using the Job Manager Task only to create the Tasks for the Job (not to
 * monitor progress), then it is important to set killJobOnCompletion to false.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.userIdentity] The user
 * identity under which the Job Manager Task runs. If omitted, the Task runs as
 * a non-administrative user unique to the Task.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.runExclusive] Whether the
 * Job Manager Task requires exclusive use of the Compute Node where it runs.
 * If true, no other Tasks will run on the same Node for as long as the Job
 * Manager is running. If false, other Tasks can run simultaneously with the
 * Job Manager on a Compute Node. The Job Manager Task counts normally against
 * the Compute Node's concurrent Task limit, so this is only relevant if the
 * Compute Node allows multiple concurrent Tasks. The default value is true.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.applicationPackageReferences]
 * A list of Application Packages that the Batch service will deploy to the
 * Compute Node before running the command line. Application Packages are
 * downloaded and deployed to a shared directory, not the Task working
 * directory. Therefore, if a referenced Application Package is already on the
 * Compute Node, and is up to date, then it is not re-downloaded; the existing
 * copy on the Compute Node is used. If a referenced Application Package cannot
 * be installed, for example because the package has been deleted or because
 * download failed, the Task fails.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings]
 * The settings for an authentication token that the Task can use to perform
 * Batch service operations. If this property is set, the Batch service
 * provides the Task with an authentication token which can be used to
 * authenticate Batch service operations without requiring an Account access
 * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
 * variable. The operations that the Task can carry out using the token depend
 * on the settings. For example, a Task can request Job permissions in order to
 * add other Tasks to the Job, or check the status of the Job or of other Tasks
 * under the Job.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
 * The Batch resources to which the token grants access. The authentication
 * token grants access to a limited set of Batch service operations. Currently
 * the only supported value for the access property is 'job', which grants
 * access to all operations related to the Job which contains the Task.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.jobManagerTask.allowLowPriorityNode]
 * Whether the Job Manager Task may run on a low-priority Compute Node. The
 * default value is true.
 *
 * @param {object} [cloudJobSchedule.jobSpecification.jobPreparationTask] The
 * Job Preparation Task for Jobs created under this schedule. If a Job has a
 * Job Preparation Task, the Batch service will run the Job Preparation Task on
 * a Node before starting any Tasks of that Job on that Compute Node.
 *
 * @param {string} [cloudJobSchedule.jobSpecification.jobPreparationTask.id] A
 * string that uniquely identifies the Job Preparation Task within the Job. The
 * ID can contain any combination of alphanumeric characters including hyphens
 * and underscores and cannot contain more than 64 characters. If you do not
 * specify this property, the Batch service assigns a default value of
 * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
 * Preparation Task. If you try to submit a Task with the same id, the Batch
 * service rejects the request with error code TaskIdSameAsJobPreparationTask;
 * if you are calling the REST API directly, the HTTP status code is 409
 * (Conflict).
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.jobPreparationTask.commandLine The command
 * line of the Job Preparation Task. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.containerSettings] The
 * settings for the container under which the Job Preparation Task runs. When
 * this is specified, all directories recursively below the
 * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
 * mapped into the container, all Task environment variables are mapped into
 * the container, and the Task command line is executed in the container. Files
 * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
 * reflected to the host disk, meaning that Batch file APIs will not be able to
 * access those files.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.resourceFiles] A list
 * of files that the Batch service will download to the Compute Node before
 * running the command line. Files listed under this element are located in the
 * Task's working directory.  There is a maximum size for the list of resource
 * files.  When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.environmentSettings] A
 * list of environment variable settings for the Job Preparation Task.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints]
 * Constraints that apply to the Job Preparation Task.
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
 * The maximum elapsed time that the Task may run, measured from the time the
 * Task starts. If the Task does not complete within the time limit, the Batch
 * service terminates it. If this is not specified, there is no time limit on
 * how long the Task may run.
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.retentionTime]
 * The minimum time to retain the Task directory on the Compute Node where it
 * ran, from the time it completes execution. After this time, the Batch
 * service may delete the Task directory and all its contents. The default is 7
 * days, i.e. the Task directory will be retained for 7 days unless the Compute
 * Node is removed or the Job is deleted.
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries for the Task executable due to a
 * nonzero exit code. The Batch service will try the Task once, and may then
 * retry up to this limit. For example, if the maximum retry count is 3, Batch
 * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
 * retry count is 0, the Batch service does not retry the Task after the first
 * attempt. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.waitForSuccess]
 * Whether the Batch service should wait for the Job Preparation Task to
 * complete successfully before scheduling any other Tasks of the Job on the
 * Compute Node. A Job Preparation Task has completed successfully if it exits
 * with exit code 0. If true and the Job Preparation Task fails on a Node, the
 * Batch service retries the Job Preparation Task up to its maximum retry count
 * (as specified in the constraints element). If the Task has still not
 * completed successfully after all retries, then the Batch service will not
 * schedule Tasks of the Job to the Node. The Node remains active and eligible
 * to run Tasks of other Jobs. If false, the Batch service will not wait for
 * the Job Preparation Task to complete. In this case, other Tasks of the Job
 * can start executing on the Compute Node while the Job Preparation Task is
 * still running; and even if the Job Preparation Task fails, new Tasks will
 * continue to be scheduled on the Compute Node. The default value is true.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.userIdentity] The user
 * identity under which the Job Preparation Task runs. If omitted, the Task
 * runs as a non-administrative user unique to the Task on Windows Compute
 * Nodes, or a non-administrative user unique to the Pool on Linux Compute
 * Nodes.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
 * Whether the Batch service should rerun the Job Preparation Task after a
 * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
 * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
 * because the reboot occurred while the Task was running). Therefore, you
 * should always write a Job Preparation Task to be idempotent and to behave
 * correctly if run multiple times. The default value is true.
 *
 * @param {object} [cloudJobSchedule.jobSpecification.jobReleaseTask] The Job
 * Release Task for Jobs created under this schedule. The primary purpose of
 * the Job Release Task is to undo changes to Nodes made by the Job Preparation
 * Task. Example activities include deleting local files, or shutting down
 * services that were started as part of Job preparation. A Job Release Task
 * cannot be specified without also specifying a Job Preparation Task for the
 * Job. The Batch service runs the Job Release Task on the Compute Nodes that
 * have run the Job Preparation Task.
 *
 * @param {string} [cloudJobSchedule.jobSpecification.jobReleaseTask.id] A
 * string that uniquely identifies the Job Release Task within the Job. The ID
 * can contain any combination of alphanumeric characters including hyphens and
 * underscores and cannot contain more than 64 characters. If you do not
 * specify this property, the Batch service assigns a default value of
 * 'jobrelease'. No other Task in the Job can have the same ID as the Job
 * Release Task. If you try to submit a Task with the same id, the Batch
 * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
 * you are calling the REST API directly, the HTTP status code is 409
 * (Conflict).
 *
 * @param {string} cloudJobSchedule.jobSpecification.jobReleaseTask.commandLine
 * The command line of the Job Release Task. The command line does not run
 * under a shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.containerSettings] The
 * settings for the container under which the Job Release Task runs. When this
 * is specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR
 * (the root of Azure Batch directories on the node) are mapped into the
 * container, all Task environment variables are mapped into the container, and
 * the Task command line is executed in the container. Files produced in the
 * container outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the
 * host disk, meaning that Batch file APIs will not be able to access those
 * files.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.resourceFiles] A list of
 * files that the Batch service will download to the Compute Node before
 * running the command line.  There is a maximum size for the list of resource
 * files.  When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.environmentSettings] A
 * list of environment variable settings for the Job Release Task.
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.maxWallClockTime] The
 * maximum elapsed time that the Job Release Task may run on a given Compute
 * Node, measured from the time the Task starts. If the Task does not complete
 * within the time limit, the Batch service terminates it. The default value is
 * 15 minutes. You may not specify a timeout longer than 15 minutes. If you do,
 * the Batch service rejects it with an error; if you are calling the REST API
 * directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.retentionTime] The minimum
 * time to retain the Task directory for the Job Release Task on the Compute
 * Node. After this time, the Batch service may delete the Task directory and
 * all its contents. The default is 7 days, i.e. the Task directory will be
 * retained for 7 days unless the Compute Node is removed or the Job is
 * deleted.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.jobReleaseTask.userIdentity] The user
 * identity under which the Job Release Task runs. If omitted, the Task runs as
 * a non-administrative user unique to the Task.
 *
 * @param {array} [cloudJobSchedule.jobSpecification.commonEnvironmentSettings]
 * A list of common environment variable settings. These environment variables
 * are set for all Tasks in Jobs created under this schedule (including the Job
 * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
 * override an environment setting specified here by specifying the same
 * setting name with a different value.
 *
 * @param {object} cloudJobSchedule.jobSpecification.poolInfo The Pool on which
 * the Batch service runs the Tasks of Jobs created under this schedule.
 *
 * @param {string} [cloudJobSchedule.jobSpecification.poolInfo.poolId] The ID
 * of an existing Pool. All the Tasks of the Job will run on the specified
 * Pool. You must ensure that the Pool referenced by this property exists. If
 * the Pool does not exist at the time the Batch service tries to schedule a
 * Job, no Tasks for the Job will run until you create a Pool with that id.
 * Note that the Batch service will not reject the Job request; it will simply
 * not run Tasks until the Pool exists. You must specify either the Pool ID or
 * the auto Pool specification, but not both.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification]
 * Characteristics for a temporary 'auto pool'. The Batch service will create
 * this auto Pool when the Job is submitted. If auto Pool creation fails, the
 * Batch service moves the Job to a completed state, and the Pool creation
 * error is set in the Job's scheduling error property. The Batch service
 * manages the lifetime (both creation and, unless keepAlive is specified,
 * deletion) of the auto Pool. Any user actions that affect the lifetime of the
 * auto Pool while the Job is active will result in unexpected behavior. You
 * must specify either the Pool ID or the auto Pool specification, but not
 * both.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
 * A prefix to be added to the unique identifier when a Pool is automatically
 * created. The Batch service assigns each auto Pool a unique identifier on
 * creation. To distinguish between Pools created for different purposes, you
 * can specify this element to add a prefix to the ID that is assigned. The
 * prefix can be up to 20 characters long.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
 * The minimum lifetime of created auto Pools, and how multiple Jobs on a
 * schedule are assigned to Pools. Possible values include: 'jobSchedule',
 * 'job'
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
 * Whether to keep an auto Pool alive after its lifetime expires. If false, the
 * Batch service deletes the Pool once its lifetime (as determined by the
 * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
 * completes. If true, the Batch service does not delete the Pool
 * automatically. It is up to the user to delete auto Pools created with this
 * option.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool] The
 * Pool specification for the auto Pool.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
 * The display name for the Pool. The display name need not be unique and can
 * contain any Unicode characters up to a maximum length of 1024.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
 * The size of the virtual machines in the Pool. All virtual machines in a Pool
 * are the same size. For information about available sizes of virtual machines
 * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
 * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
 * The cloud service configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure PaaS VMs. This property
 * and virtualMachineConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request). This property cannot be specified if the Batch
 * Account was created with its poolAllocationMode property set to
 * 'UserSubscription'.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
 * The Azure Guest OS family to be installed on the virtual machines in the
 * Pool. Possible values are:
 * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
 * 3 - OS Family 3, equivalent to Windows Server 2012.
 * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
 * 5 - OS Family 5, equivalent to Windows Server 2016.
 * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
 * see Azure Guest OS Releases
 * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
 * The Azure Guest OS version to be installed on the virtual machines in the
 * Pool. The default value is * which specifies the latest operating system
 * version for the specified OS family.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
 * The virtual machine configuration for the Pool. This property must be
 * specified if the Pool needs to be created with Azure IaaS VMs. This property
 * and cloudServiceConfiguration are mutually exclusive and one of the
 * properties must be specified. If neither is specified then the Batch service
 * returns an error; if you are calling the REST API directly, the HTTP status
 * code is 400 (Bad Request).
 *
 * @param {object}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
 * A reference to the Azure Virtual Machines Marketplace Image or the custom
 * Virtual Machine Image to use.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
 * The publisher of the Azure Virtual Machines Marketplace Image. For example,
 * Canonical or MicrosoftWindowsServer.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
 * The offer type of the Azure Virtual Machines Marketplace Image. For example,
 * UbuntuServer or WindowsServer.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
 * The SKU of the Azure Virtual Machines Marketplace Image. For example,
 * 18.04-LTS or 2019-Datacenter.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
 * The version of the Azure Virtual Machines Marketplace Image. A value of
 * 'latest' can be specified to select the latest version of an Image. If
 * omitted, the default is 'latest'.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
 * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
 * in the Pool will be created using this Image Id. This is of the form
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
 * or
 * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
 * for always defaulting to the latest image version. This property is mutually
 * exclusive with other ImageReference properties. The Shared Image Gallery
 * Image must have replicas in the same region and must be in the same
 * subscription as the Azure Batch account. If the image version is not
 * specified in the imageId, the latest version will be used. For information
 * about the firewall settings for the Batch Compute Node agent to communicate
 * with the Batch service see
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
 * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
 * in the Pool. The Batch Compute Node agent is a program that runs on each
 * Compute Node in the Pool, and provides the command-and-control interface
 * between the Compute Node and the Batch service. There are different
 * implementations of the Compute Node agent, known as SKUs, for different
 * operating systems. You must specify a Compute Node agent SKU which matches
 * the selected Image reference. To get the list of supported Compute Node
 * agent SKUs along with their list of verified Image references, see the 'List
 * supported Compute Node agent SKUs' operation.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
 * Windows operating system settings on the virtual machine. This property must
 * not be specified if the imageReference property specifies a Linux OS Image.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
 * Whether automatic updates are enabled on the virtual machine. If omitted,
 * the default value is true.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
 * The configuration for data disks attached to the Compute Nodes in the Pool.
 * This property must be specified if the Compute Nodes in the Pool need to
 * have empty data disks attached to them. This cannot be updated. Each Compute
 * Node gets its own disk (the disk is not a file share). Existing disks cannot
 * be attached, each attached disk is empty. When the Compute Node is removed
 * from the Pool, the disk and all data associated with it is also deleted. The
 * disk is not formatted after being attached, it must be formatted before use
 * - for more information see
 * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
 * and
 * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
 * The type of on-premises license to be used when deploying the operating
 * system. This only applies to Images that contain the Windows operating
 * system, and should only be used when you hold valid on-premises licenses for
 * the Compute Nodes which will be deployed. If omitted, no on-premises
 * licensing discount is applied. Values are:
 *
 * Windows_Server - The on-premises license is for Windows Server.
 * Windows_Client - The on-premises license is for Windows Client.
 *
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
 * The container configuration for the Pool. If specified, setup is performed
 * on each Compute Node in the Pool to allow Tasks to run in containers. All
 * regular Tasks and Job manager Tasks run on this Pool must specify the
 * containerSettings property, and all other Tasks may specify it.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
 * The collection of container Image names. This is the full Image reference,
 * as would be specified to "docker pull". An Image will be sourced from the
 * default Docker registry unless the Image is fully qualified with an
 * alternative registry.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
 * Additional private registries from which containers can be pulled. If any
 * Images must be downloaded from a private registry which requires
 * credentials, then those credentials must be provided here.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
 * The disk encryption configuration for the pool. If specified, encryption is
 * performed on each node in the pool during node provisioning.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
 * The list of disk targets Batch Service will encrypt on the compute node. If
 * omitted, no disks on the compute nodes in the pool will be encrypted. On
 * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
 * "TemporaryDisk" must be specified.
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
 * The number of task slots that can be used to run concurrent tasks on a
 * single compute node in the pool. The default value is 1. The maximum value
 * is the smaller of 4 times the number of cores of the vmSize of the pool or
 * 256.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
 * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
 * the default is spread. Possible values include: 'spread', 'pack'
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
 * The timeout for allocation of Compute Nodes to the Pool. This timeout
 * applies only to manual scaling; it has no effect when enableAutoScale is set
 * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
 * you specify a value less than 5 minutes, the Batch service rejects the
 * request with an error; if you are calling the REST API directly, the HTTP
 * status code is 400 (Bad Request).
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
 * The desired number of dedicated Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
 * The desired number of low-priority Compute Nodes in the Pool. This property
 * must not be specified if enableAutoScale is set to true. If enableAutoScale
 * is set to false, then you must set either targetDedicatedNodes,
 * targetLowPriorityNodes, or both.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
 * Whether the Pool size should automatically adjust over time. If false, at
 * least one of targetDedicateNodes and targetLowPriorityNodes must be
 * specified. If true, the autoScaleFormula element is required. The Pool
 * automatically resizes according to the formula. The default value is false.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
 * The formula for the desired number of Compute Nodes in the Pool. This
 * property must not be specified if enableAutoScale is set to false. It is
 * required if enableAutoScale is set to true. The formula is checked for
 * validity before the Pool is created. If the formula is not valid, the Batch
 * service rejects the request with detailed error information.
 *
 * @param {moment.duration}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
 * The time interval at which to automatically adjust the Pool size according
 * to the autoscale formula. The default value is 15 minutes. The minimum and
 * maximum value are 5 minutes and 168 hours respectively. If you specify a
 * value less than 5 minutes or greater than 168 hours, the Batch service
 * rejects the request with an invalid property value error; if you are calling
 * the REST API directly, the HTTP status code is 400 (Bad Request).
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
 * Whether the Pool permits direct communication between Compute Nodes.
 * Enabling inter-node communication limits the maximum size of the Pool due to
 * deployment restrictions on the Compute Nodes of the Pool. This may result in
 * the Pool not reaching its desired size. The default value is false.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
 * The network configuration for the Pool.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
 * The ARM resource identifier of the virtual network subnet which the Compute
 * Nodes of the Pool will join. This is of the form
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
 * The virtual network must be in the same region and subscription as the Azure
 * Batch Account. The specified subnet should have enough free IP addresses to
 * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
 * have enough free IP addresses, the Pool will partially allocate Nodes and a
 * resize error will occur. The 'MicrosoftAzureBatch' service principal must
 * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
 * (RBAC) role for the specified VNet. The specified subnet must allow
 * communication from the Azure Batch service to be able to schedule Tasks on
 * the Nodes. This can be verified by checking if the specified VNet has any
 * associated Network Security Groups (NSG). If communication to the Nodes in
 * the specified subnet is denied by an NSG, then the Batch service will set
 * the state of the Compute Nodes to unusable. For Pools created with
 * virtualMachineConfiguration only ARM virtual networks
 * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
 * with cloudServiceConfiguration both ARM and classic virtual networks are
 * supported. If the specified VNet has any associated Network Security Groups
 * (NSG), then a few reserved system ports must be enabled for inbound
 * communication. For Pools created with a virtual machine configuration,
 * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
 * Windows. For Pools created with a cloud service configuration, enable ports
 * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
 * on port 443. For more details see:
 * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
 * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
 * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
 * endpoint configuration is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {array}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
 * A list of inbound NAT Pools that can be used to address specific ports on an
 * individual Compute Node externally. The maximum number of inbound NAT Pools
 * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
 * the request fails with HTTP status code 400. This cannot be specified if the
 * IPAddressProvisioningType is NoPublicIPAddresses.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
 * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
 * Public IP configuration property is only supported on Pools with the
 * virtualMachineConfiguration property.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
 * The provisioning type for Public IP Addresses for the Pool. The default
 * value is BatchManaged. Possible values include: 'batchManaged',
 * 'userManaged', 'noPublicIPAddresses'
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
 * The list of public IPs which the Batch service will use when provisioning
 * Compute Nodes. The number of IPs specified here limits the maximum size of
 * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
 * for each public IP. For example, a pool needing 250 dedicated VMs would need
 * at least 3 public IPs specified. Each element of this collection is of the
 * form:
 * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
 * A Task to run on each Compute Node as it joins the Pool. The Task runs when
 * the Compute Node is added to the Pool or when the Compute Node is restarted.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
 * The command line of the StartTask. The command line does not run under a
 * shell, and therefore cannot take advantage of shell features such as
 * environment variable expansion. If you want to take advantage of such
 * features, you should invoke the shell in the command line, for example using
 * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
 * command line refers to file paths, it should use a relative path (relative
 * to the Task working directory), or use the Batch provided environment
 * variable
 * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
 * The settings for the container under which the StartTask runs. When this is
 * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
 * root of Azure Batch directories on the node) are mapped into the container,
 * all Task environment variables are mapped into the container, and the Task
 * command line is executed in the container. Files produced in the container
 * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
 * meaning that Batch file APIs will not be able to access those files.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
 * Additional options to the container create command. These additional options
 * are supplied as arguments to the "docker create" command, in addition to
 * those controlled by the Batch Service.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
 * The Image to use to create the container in which the Task will run. This is
 * the full Image reference, as would be specified to "docker pull". If no tag
 * is provided as part of the Image name, the tag ":latest" is used as a
 * default.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
 * The private registry which contains the container Image. This setting can be
 * omitted if was already provided at Pool creation.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
 * The registry URL. If omitted, the default is "docker.io".
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
 * The user name to log into the registry server.
 *
 * @param {string}
 * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
 * The password to log into the registry server.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
 * The location of the container Task working directory. The default is
 * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
 * 'containerImageDefault'
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
 * A list of files that the Batch service will download to the Compute Node
 * before running the command line.  There is a maximum size for the list of
 * resource files. When the max size is exceeded, the request will fail and the
 * response error code will be RequestEntityTooLarge. If this occurs, the
 * collection of ResourceFiles must be reduced in size. This can be achieved
 * using .zip files, Application Packages, or Docker Containers. Files listed
 * under this element are located in the Task's working directory.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
 * A list of environment variable settings for the StartTask.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
 * The user identity under which the StartTask runs. If omitted, the Task runs
 * as a non-administrative user unique to the Task.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
 * The name of the user identity under which the Task is run. The userName and
 * autoUser properties are mutually exclusive; you must specify one but not
 * both.
 *
 * @param {object}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
 * The auto user under which the Task is run. The userName and autoUser
 * properties are mutually exclusive; you must specify one but not both.
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
 * The scope for the auto user The default value is pool. If the pool is
 * running Windows a value of Task should be specified if stricter isolation
 * between tasks is required. For example, if the task mutates the registry in
 * a way which could impact other tasks, or if certificates have been specified
 * on the pool which should not be accessible by normal tasks but should be
 * accessible by StartTasks. Possible values include: 'task', 'pool'
 *
 * @param {string}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
 * The elevation level of the auto user. The default value is nonAdmin.
 * Possible values include: 'nonAdmin', 'admin'
 *
 * @param {number}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
 * The maximum number of times the Task may be retried. The Batch service
 * retries a Task if its exit code is nonzero. Note that this value
 * specifically controls the number of retries. The Batch service will try the
 * Task once, and may then retry up to this limit. For example, if the maximum
 * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
 * retries). If the maximum retry count is 0, the Batch service does not retry
 * the Task. If the maximum retry count is -1, the Batch service retries the
 * Task without limit.
 *
 * @param {boolean}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
 * Whether the Batch service should wait for the StartTask to complete
 * successfully (that is, to exit with exit code 0) before scheduling any Tasks
 * on the Compute Node. If true and the StartTask fails on a Node, the Batch
 * service retries the StartTask up to its maximum retry count
 * (maxTaskRetryCount). If the Task has still not completed successfully after
 * all retries, then the Batch service marks the Node unusable, and will not
 * schedule Tasks to it. This condition can be detected via the Compute Node
 * state and failure info details. If false, the Batch service will not wait
 * for the StartTask to complete. In this case, other Tasks can start executing
 * on the Compute Node while the StartTask is still running; and even if the
 * StartTask fails, new Tasks will continue to be scheduled on the Compute
 * Node. The default is true.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
 * A list of Certificates to be installed on each Compute Node in the Pool. For
 * Windows Nodes, the Batch service installs the Certificates to the specified
 * Certificate store and location. For Linux Compute Nodes, the Certificates
 * are stored in a directory inside the Task working directory and an
 * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
 * query for this location. For Certificates with visibility of 'remoteUser', a
 * 'certs' directory is created in the user's home directory (e.g.,
 * /home/{user-name}/certs) and Certificates are placed in that directory.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
 * The list of Packages to be installed on each Compute Node in the Pool.
 * Changes to Package references affect all new Nodes joining the Pool, but do
 * not affect Compute Nodes that are already in the Pool until they are
 * rebooted or reimaged. There is a maximum of 10 Package references on any
 * given Pool.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
 * The list of application licenses the Batch service will make available on
 * each Compute Node in the Pool. The list of application licenses must be a
 * subset of available Batch service application licenses. If a license is
 * requested which is not supported, Pool creation will fail. The permitted
 * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
 * additional charge applies for each application license added to the Pool.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
 * The list of user Accounts to be created on each Compute Node in the Pool.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
 * A list of name-value pairs associated with the Pool as metadata. The Batch
 * service does not assign any meaning to metadata; it is solely for the use of
 * user code.
 *
 * @param {array}
 * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
 * A list of file systems to mount on each node in the pool. This supports
 * Azure Files, NFS, CIFS/SMB, and Blobfuse.
 *
 * @param {array} [cloudJobSchedule.jobSpecification.metadata] A list of
 * name-value pairs associated with each Job created under this schedule as
 * metadata. The Batch service does not assign any meaning to metadata; it is
 * solely for the use of user code.
 *
 * @param {array} [cloudJobSchedule.metadata] A list of name-value pairs
 * associated with the schedule as metadata. The Batch service does not assign
 * any meaning to metadata; it is solely for the use of user code.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleAddOptions] Additional parameters for
 * the operation
 *
 * @param {number} [options.jobScheduleAddOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleAddOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleAddOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleAddOptions.ocpDate] The time the request
 * was issued. Client libraries typically set this to the current system clock
 * time; set it explicitly if you are calling the REST API directly.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {null} [result]   - The deserialized result object if an error did not occur.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _add(cloudJobSchedule, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleAddOptions = (options && options.jobScheduleAddOptions !== undefined) ? options.jobScheduleAddOptions : undefined;
  if (cloudJobSchedule === null || cloudJobSchedule === undefined)
  {
    cloudJobSchedule = {};
  }
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (cloudJobSchedule === null || cloudJobSchedule === undefined) {
      throw new Error('cloudJobSchedule cannot be null or undefined.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  try {
    if (jobScheduleAddOptions !== null && jobScheduleAddOptions !== undefined) {
      timeout = jobScheduleAddOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleAddOptions !== null && jobScheduleAddOptions !== undefined) {
      clientRequestId = jobScheduleAddOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleAddOptions !== null && jobScheduleAddOptions !== undefined) {
      returnClientRequestId = jobScheduleAddOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleAddOptions !== null && jobScheduleAddOptions !== undefined) {
      ocpDate = jobScheduleAddOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'POST';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  // Serialize Request
  let requestContent = null;
  let requestModel = null;
  try {
    if (cloudJobSchedule !== null && cloudJobSchedule !== undefined) {
      let requestModelMapper = new client.models['JobScheduleAddParameter']().mapper();
      requestModel = client.serialize(requestModelMapper, cloudJobSchedule, 'cloudJobSchedule');
      requestContent = JSON.stringify(requestModel);
    }
  } catch (error) {
    let serializationError = new Error(`Error "${error.message}" occurred in serializing the ` +
        `payload - ${JSON.stringify(cloudJobSchedule, null, 2)}.`);
    return callback(serializationError);
  }
  httpRequest.body = requestContent;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 201) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Lists all of the Job Schedules in the specified Account.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleListOptions] Additional parameters for
 * the operation
 *
 * @param {string} [options.jobScheduleListOptions.filter] An OData $filter
 * clause. For more information on constructing this filter, see
 * https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-job-schedules.
 *
 * @param {string} [options.jobScheduleListOptions.select] An OData $select
 * clause.
 *
 * @param {string} [options.jobScheduleListOptions.expand] An OData $expand
 * clause.
 *
 * @param {number} [options.jobScheduleListOptions.maxResults] The maximum
 * number of items to return in the response. A maximum of 1000 Job Schedules
 * can be returned.
 *
 * @param {number} [options.jobScheduleListOptions.timeout] The maximum time
 * that the server can spend processing the request, in seconds. The default is
 * 30 seconds.
 *
 * @param {uuid} [options.jobScheduleListOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleListOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleListOptions.ocpDate] The time the request
 * was issued. Client libraries typically set this to the current system clock
 * time; set it explicitly if you are calling the REST API directly.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {object} [result]   - The deserialized result object if an error did not occur.
 *                      See {@link CloudJobScheduleListResult} for more
 *                      information.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _list(options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleListOptions = (options && options.jobScheduleListOptions !== undefined) ? options.jobScheduleListOptions : undefined;
  // Validate
  try {
    if (this.client.batchUrl === null || this.client.batchUrl === undefined || typeof this.client.batchUrl.valueOf() !== 'string') {
      throw new Error('this.client.batchUrl cannot be null or undefined and it must be of type string.');
    }
    if (this.client.apiVersion === null || this.client.apiVersion === undefined || typeof this.client.apiVersion.valueOf() !== 'string') {
      throw new Error('this.client.apiVersion cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let filter;
  let select;
  let expand;
  let maxResults;
  let timeout;
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  try {
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      filter = jobScheduleListOptions.filter;
      if (filter !== null && filter !== undefined && typeof filter.valueOf() !== 'string') {
        throw new Error('filter must be of type string.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      select = jobScheduleListOptions.select;
      if (select !== null && select !== undefined && typeof select.valueOf() !== 'string') {
        throw new Error('select must be of type string.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      expand = jobScheduleListOptions.expand;
      if (expand !== null && expand !== undefined && typeof expand.valueOf() !== 'string') {
        throw new Error('expand must be of type string.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      maxResults = jobScheduleListOptions.maxResults;
      if (maxResults !== null && maxResults !== undefined && typeof maxResults !== 'number') {
        throw new Error('maxResults must be of type number.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      timeout = jobScheduleListOptions.timeout;
      if (timeout !== null && timeout !== undefined && typeof timeout !== 'number') {
        throw new Error('timeout must be of type number.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      clientRequestId = jobScheduleListOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      returnClientRequestId = jobScheduleListOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleListOptions !== null && jobScheduleListOptions !== undefined) {
      ocpDate = jobScheduleListOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let baseUrl = this.client.baseUri;
  let requestUrl = baseUrl + (baseUrl.endsWith('/') ? '' : '/') + 'jobschedules';
  requestUrl = requestUrl.replace('{batchUrl}', this.client.batchUrl);
  let queryParameters = [];
  queryParameters.push('api-version=' + encodeURIComponent(this.client.apiVersion));
  if (filter !== null && filter !== undefined) {
    queryParameters.push('$filter=' + encodeURIComponent(filter));
  }
  if (select !== null && select !== undefined) {
    queryParameters.push('$select=' + encodeURIComponent(select));
  }
  if (expand !== null && expand !== undefined) {
    queryParameters.push('$expand=' + encodeURIComponent(expand));
  }
  if (maxResults !== null && maxResults !== undefined) {
    queryParameters.push('maxresults=' + encodeURIComponent(maxResults.toString()));
  }
  if (timeout !== null && timeout !== undefined) {
    queryParameters.push('timeout=' + encodeURIComponent(timeout.toString()));
  }
  if (queryParameters.length > 0) {
    requestUrl += '?' + queryParameters.join('&');
  }

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'GET';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;
    // Deserialize Response
    if (statusCode === 200) {
      let parsedResponse = null;
      try {
        parsedResponse = JSON.parse(responseBody);
        result = JSON.parse(responseBody);
        if (parsedResponse !== null && parsedResponse !== undefined) {
          let resultMapper = new client.models['CloudJobScheduleListResult']().mapper();
          result = client.deserialize(resultMapper, parsedResponse, 'result');
        }
      } catch (error) {
        let deserializationError = new Error(`Error ${error} occurred in deserializing the responseBody - ${responseBody}`);
        deserializationError.request = msRest.stripRequest(httpRequest);
        deserializationError.response = msRest.stripResponse(response);
        return callback(deserializationError);
      }
    }

    return callback(null, result, httpRequest, response);
  });
}

/**
 * @summary Lists all of the Job Schedules in the specified Account.
 *
 * @param {string} nextPageLink The NextLink from the previous successful call
 * to List operation.
 *
 * @param {object} [options] Optional Parameters.
 *
 * @param {object} [options.jobScheduleListNextOptions] Additional parameters
 * for the operation
 *
 * @param {uuid} [options.jobScheduleListNextOptions.clientRequestId] The
 * caller-generated request identity, in the form of a GUID with no decoration
 * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
 *
 * @param {boolean} [options.jobScheduleListNextOptions.returnClientRequestId]
 * Whether the server should return the client-request-id in the response.
 *
 * @param {date} [options.jobScheduleListNextOptions.ocpDate] The time the
 * request was issued. Client libraries typically set this to the current
 * system clock time; set it explicitly if you are calling the REST API
 * directly.
 *
 * @param {object} [options.customHeaders] Headers that will be added to the
 * request
 *
 * @param {function} callback - The callback.
 *
 * @returns {function} callback(err, result, request, response)
 *
 *                      {Error}  err        - The Error object if an error occurred, null otherwise.
 *
 *                      {object} [result]   - The deserialized result object if an error did not occur.
 *                      See {@link CloudJobScheduleListResult} for more
 *                      information.
 *
 *                      {object} [request]  - The HTTP Request object if an error did not occur.
 *
 *                      {stream} [response] - The HTTP Response stream if an error did not occur.
 */
function _listNext(nextPageLink, options, callback) {
   /* jshint validthis: true */
  let client = this.client;
  if(!callback && typeof options === 'function') {
    callback = options;
    options = null;
  }
  if (!callback) {
    throw new Error('callback cannot be null.');
  }
  let jobScheduleListNextOptions = (options && options.jobScheduleListNextOptions !== undefined) ? options.jobScheduleListNextOptions : undefined;
  // Validate
  try {
    if (nextPageLink === null || nextPageLink === undefined || typeof nextPageLink.valueOf() !== 'string') {
      throw new Error('nextPageLink cannot be null or undefined and it must be of type string.');
    }
    if (this.client.acceptLanguage !== null && this.client.acceptLanguage !== undefined && typeof this.client.acceptLanguage.valueOf() !== 'string') {
      throw new Error('this.client.acceptLanguage must be of type string.');
    }
  } catch (error) {
    return callback(error);
  }
  let clientRequestId;
  let returnClientRequestId;
  let ocpDate;
  try {
    if (jobScheduleListNextOptions !== null && jobScheduleListNextOptions !== undefined) {
      clientRequestId = jobScheduleListNextOptions.clientRequestId;
      if (clientRequestId !== null && clientRequestId !== undefined && !(typeof clientRequestId.valueOf() === 'string' && msRest.isValidUuid(clientRequestId))) {
        throw new Error('clientRequestId must be of type string and must be a valid uuid.');
      }
    }
    if (jobScheduleListNextOptions !== null && jobScheduleListNextOptions !== undefined) {
      returnClientRequestId = jobScheduleListNextOptions.returnClientRequestId;
      if (returnClientRequestId !== null && returnClientRequestId !== undefined && typeof returnClientRequestId !== 'boolean') {
        throw new Error('returnClientRequestId must be of type boolean.');
      }
    }
    if (jobScheduleListNextOptions !== null && jobScheduleListNextOptions !== undefined) {
      ocpDate = jobScheduleListNextOptions.ocpDate;
      if (ocpDate && !(ocpDate instanceof Date ||
          (typeof ocpDate.valueOf() === 'string' && !isNaN(Date.parse(ocpDate))))) {
            throw new Error('ocpDate must be of type date.');
          }
    }
  } catch (error) {
    return callback(error);
  }

  // Construct URL
  let requestUrl = '{nextLink}';
  requestUrl = requestUrl.replace('{nextLink}', nextPageLink);

  // Create HTTP transport objects
  let httpRequest = new WebResource();
  httpRequest.method = 'GET';
  httpRequest.url = requestUrl;
  httpRequest.headers = {};
  // Set Headers
  httpRequest.headers['Content-Type'] = 'application/json; charset=utf-8';
  if (this.client.generateClientRequestId) {
      httpRequest.headers['client-request-id'] = msRestAzure.generateUuid();
  }
  if (this.client.acceptLanguage !== undefined && this.client.acceptLanguage !== null) {
    httpRequest.headers['accept-language'] = this.client.acceptLanguage;
  }
  if (clientRequestId !== undefined && clientRequestId !== null) {
    httpRequest.headers['client-request-id'] = clientRequestId.toString();
  }
  if (returnClientRequestId !== undefined && returnClientRequestId !== null) {
    httpRequest.headers['return-client-request-id'] = returnClientRequestId.toString();
  }
  if (ocpDate !== undefined && ocpDate !== null) {
    httpRequest.headers['ocp-date'] = ocpDate.toUTCString();
  }
  if(options) {
    for(let headerName in options['customHeaders']) {
      if (options['customHeaders'].hasOwnProperty(headerName)) {
        httpRequest.headers[headerName] = options['customHeaders'][headerName];
      }
    }
  }
  httpRequest.body = null;
  // Send Request
  return client.pipeline(httpRequest, (err, response, responseBody) => {
    if (err) {
      return callback(err);
    }
    let statusCode = response.statusCode;
    if (statusCode !== 200) {
      let error = new Error(responseBody);
      error.statusCode = response.statusCode;
      error.request = msRest.stripRequest(httpRequest);
      error.response = msRest.stripResponse(response);
      if (responseBody === '') responseBody = null;
      let parsedErrorResponse;
      try {
        parsedErrorResponse = JSON.parse(responseBody);
        if (parsedErrorResponse) {
          let internalError = null;
          if (parsedErrorResponse.error) internalError = parsedErrorResponse.error;
          error.code = internalError ? internalError.code : parsedErrorResponse.code;
          error.message = internalError ? internalError.message : parsedErrorResponse.message;
        }
        if (parsedErrorResponse !== null && parsedErrorResponse !== undefined) {
          let resultMapper = new client.models['BatchError']().mapper();
          error.body = client.deserialize(resultMapper, parsedErrorResponse, 'error.body');
        }
      } catch (defaultError) {
        error.message = `Error "${defaultError.message}" occurred in deserializing the responseBody ` +
                         `- "${responseBody}" for the default response.`;
        return callback(error);
      }
      return callback(error);
    }
    // Create Result
    let result = null;
    if (responseBody === '') responseBody = null;
    // Deserialize Response
    if (statusCode === 200) {
      let parsedResponse = null;
      try {
        parsedResponse = JSON.parse(responseBody);
        result = JSON.parse(responseBody);
        if (parsedResponse !== null && parsedResponse !== undefined) {
          let resultMapper = new client.models['CloudJobScheduleListResult']().mapper();
          result = client.deserialize(resultMapper, parsedResponse, 'result');
        }
      } catch (error) {
        let deserializationError = new Error(`Error ${error} occurred in deserializing the responseBody - ${responseBody}`);
        deserializationError.request = msRest.stripRequest(httpRequest);
        deserializationError.response = msRest.stripResponse(response);
        return callback(deserializationError);
      }
    }

    return callback(null, result, httpRequest, response);
  });
}

/** Class representing a JobSchedule. */
class JobSchedule {
  /**
   * Create a JobSchedule.
   * @param {BatchServiceClient} client Reference to the service client.
   */
  constructor(client) {
    this.client = client;
    this._exists = _exists;
    this._deleteMethod = _deleteMethod;
    this._get = _get;
    this._patch = _patch;
    this._update = _update;
    this._disable = _disable;
    this._enable = _enable;
    this._terminate = _terminate;
    this._add = _add;
    this._list = _list;
    this._listNext = _listNext;
  }

  /**
   * @summary Checks the specified Job Schedule exists.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule which you want to
   * check.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleExistsOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleExistsOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleExistsOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleExistsOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleExistsOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleExistsOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleExistsOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleExistsOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleExistsOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<Boolean>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  existsWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._exists(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Checks the specified Job Schedule exists.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule which you want to
   * check.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleExistsOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleExistsOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleExistsOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleExistsOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleExistsOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleExistsOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleExistsOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleExistsOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleExistsOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {Boolean} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {boolean} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  exists(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._exists(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._exists(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * @summary Deletes a Job Schedule from the specified Account.
   *
   * When you delete a Job Schedule, this also deletes all Jobs and Tasks under
   * that schedule. When Tasks are deleted, all the files in their working
   * directories on the Compute Nodes are also deleted (the retention period is
   * ignored). The Job Schedule statistics are no longer accessible once the Job
   * Schedule is deleted, though they are still counted towards Account lifetime
   * statistics.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to delete.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleDeleteMethodOptions] Additional
   * parameters for the operation
   *
   * @param {number} [options.jobScheduleDeleteMethodOptions.timeout] The maximum
   * time that the server can spend processing the request, in seconds. The
   * default is 30 seconds.
   *
   * @param {uuid} [options.jobScheduleDeleteMethodOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean}
   * [options.jobScheduleDeleteMethodOptions.returnClientRequestId] Whether the
   * server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleDeleteMethodOptions.ifMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleDeleteMethodOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  deleteMethodWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._deleteMethod(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Deletes a Job Schedule from the specified Account.
   *
   * When you delete a Job Schedule, this also deletes all Jobs and Tasks under
   * that schedule. When Tasks are deleted, all the files in their working
   * directories on the Compute Nodes are also deleted (the retention period is
   * ignored). The Job Schedule statistics are no longer accessible once the Job
   * Schedule is deleted, though they are still counted towards Account lifetime
   * statistics.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to delete.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleDeleteMethodOptions] Additional
   * parameters for the operation
   *
   * @param {number} [options.jobScheduleDeleteMethodOptions.timeout] The maximum
   * time that the server can spend processing the request, in seconds. The
   * default is 30 seconds.
   *
   * @param {uuid} [options.jobScheduleDeleteMethodOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean}
   * [options.jobScheduleDeleteMethodOptions.returnClientRequestId] Whether the
   * server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleDeleteMethodOptions.ifMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleDeleteMethodOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleDeleteMethodOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  deleteMethod(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._deleteMethod(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._deleteMethod(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * Gets information about the specified Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to get.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleGetOptions] Additional parameters for
   * the operation
   *
   * @param {string} [options.jobScheduleGetOptions.select] An OData $select
   * clause.
   *
   * @param {string} [options.jobScheduleGetOptions.expand] An OData $expand
   * clause.
   *
   * @param {number} [options.jobScheduleGetOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleGetOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleGetOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleGetOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {string} [options.jobScheduleGetOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleGetOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleGetOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleGetOptions.ifUnmodifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has not been
   * modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<CloudJobSchedule>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  getWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._get(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * Gets information about the specified Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to get.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleGetOptions] Additional parameters for
   * the operation
   *
   * @param {string} [options.jobScheduleGetOptions.select] An OData $select
   * clause.
   *
   * @param {string} [options.jobScheduleGetOptions.expand] An OData $expand
   * clause.
   *
   * @param {number} [options.jobScheduleGetOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleGetOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleGetOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleGetOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {string} [options.jobScheduleGetOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleGetOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleGetOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleGetOptions.ifUnmodifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has not been
   * modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {CloudJobSchedule} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {object} [result]   - The deserialized result object if an error did not occur.
   *                      See {@link CloudJobSchedule} for more information.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  get(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._get(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._get(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * @summary Updates the properties of the specified Job Schedule.
   *
   * This replaces only the Job Schedule properties specified in the request. For
   * example, if the schedule property is not specified with this request, then
   * the Batch service will keep the existing schedule. Changes to a Job Schedule
   * only impact Jobs created by the schedule after the update has taken place;
   * currently running Jobs are unaffected.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to update.
   *
   * @param {object} jobSchedulePatchParameter The parameters for the request.
   *
   * @param {object} [jobSchedulePatchParameter.schedule] The schedule according
   * to which Jobs will be created. If you do not specify this element, the
   * existing schedule is left unchanged.
   *
   * @param {date} [jobSchedulePatchParameter.schedule.doNotRunUntil] The
   * earliest time at which any Job may be created under this Job Schedule. If
   * you do not specify a doNotRunUntil time, the schedule becomes ready to
   * create Jobs immediately.
   *
   * @param {date} [jobSchedulePatchParameter.schedule.doNotRunAfter] A time
   * after which no Job will be created under this Job Schedule. The schedule
   * will move to the completed state as soon as this deadline is past and there
   * is no active Job under this Job Schedule. If you do not specify a
   * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
   * Schedule will remain active until you explicitly terminate it.
   *
   * @param {moment.duration} [jobSchedulePatchParameter.schedule.startWindow]
   * The time interval, starting from the time at which the schedule indicates a
   * Job should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.schedule.recurrenceInterval] The time interval
   * between the start times of two successive Jobs under the Job Schedule. A Job
   * Schedule can have at most one active Job under it at any given time. Because
   * a Job Schedule can have at most one active Job under it at any given time,
   * if it is time to create a new Job under a Job Schedule, but the previous Job
   * is still running, the Batch service will not create the new Job until the
   * previous Job finishes. If the previous Job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new Job will be
   * scheduled for that interval. For recurring Jobs, you should normally specify
   * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
   * you will need an external process to monitor when Jobs are created, add
   * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
   * default is that the schedule does not recur: one Job is created, within the
   * startWindow after the doNotRunUntil time, and the schedule is complete as
   * soon as that Job finishes. The minimum value is 1 minute. If you specify a
   * lower value, the Batch service rejects the schedule with an error; if you
   * are calling the REST API directly, the HTTP status code is 400 (Bad
   * Request).
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification] The details of
   * the Jobs to be created on this schedule. Updates affect only Jobs that are
   * started after the update has taken place. Any currently active Job continues
   * with the older specification.
   *
   * @param {number} [jobSchedulePatchParameter.jobSpecification.priority] The
   * priority of Jobs created under this schedule. Priority values can range from
   * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
   * highest priority. The default value is 0. This priority is used as the
   * default for all Jobs under the Job Schedule. You can update a Job's priority
   * after it has been created using by using the update Job API.
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.displayName] The
   * display name for Jobs created under this schedule. The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.usesTaskDependencies] Whether
   * Tasks in the Job can define dependencies on each other. The default is
   * false.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.onAllTasksComplete] The action
   * the Batch service should take when all Tasks in a Job created under this
   * schedule are in the completed state. Note that if a Job contains no Tasks,
   * then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.onTaskFailure]
   * The action the Batch service should take when any Task fails in a Job
   * created under this schedule. A Task is considered to have failed if it have
   * failed if has a failureInfo. A failureInfo is set if the Task completes with
   * a non-zero exit code after exhausting its retry count, or if there was an
   * error starting the Task, for example due to a resource file download error.
   * The default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.networkConfiguration.subnetId The
   * ARM resource identifier of the virtual network subnet which Compute Nodes
   * running Tasks from the Job will join for the duration of the Task. This will
   * only work with a VirtualMachineConfiguration Pool. The virtual network must
   * be in the same region and subscription as the Azure Batch Account. The
   * specified subnet should have enough free IP addresses to accommodate the
   * number of Compute Nodes which will run Tasks from the Job. This can be up to
   * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
   * principal must have the 'Classic Virtual Machine Contributor' Role-Based
   * Access Control (RBAC) role for the specified VNet so that Azure Batch
   * service can schedule Tasks on the Nodes. This can be verified by checking if
   * the specified VNet has any associated Network Security Groups (NSG). If
   * communication to the Nodes in the specified subnet is denied by an NSG, then
   * the Batch service will set the state of the Compute Nodes to unusable. This
   * is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.constraints] The
   * execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.constraints.maxWallClockTime]
   * The maximum elapsed time that the Job may run, measured from the time the
   * Job is created. If the Job does not complete within the time limit, the
   * Batch service terminates it and any Tasks that are still running. In this
   * case, the termination reason will be MaxWallClockTimeExpiry. If this
   * property is not specified, there is no time limit on how long the Job may
   * run.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.constraints.maxTaskRetryCount]
   * The maximum number of times each Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try each
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
   * without limit. The default value is 0 (no retries).
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.jobManagerTask]
   * The details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string} jobSchedulePatchParameter.jobSpecification.jobManagerTask.id
   * A string that uniquely identifies the Job Manager Task within the Job. The
   * ID can contain any combination of alphanumeric characters including hyphens
   * and underscores and cannot contain more than 64 characters.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.displayName] The
   * display name of the Job Manager Task. It need not be unique and can contain
   * any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobManagerTask.commandLine The
   * command line of the Job Manager Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.containerSettings]
   * The settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory. There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.outputFiles] A
   * list of files that the Batch service will upload from the Compute Node after
   * running the command line. For multi-instance Tasks, the files will only be
   * uploaded from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.environmentSettings]
   * A list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.constraints]
   * Constraints that apply to the Job Manager Task.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.requiredSlots]
   * The number of scheduling slots that the Task requires to run. The default is
   * 1. A Task can only be scheduled to run on a compute node if the node has
   * enough free scheduling slots available. For multi-instance Tasks, this must
   * be 1.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.userIdentity] The
   * user identity under which the Job Manager Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.runExclusive]
   * Whether the Job Manager Task requires exclusive use of the Compute Node
   * where it runs. If true, no other Tasks will run on the same Node for as long
   * as the Job Manager is running. If false, other Tasks can run simultaneously
   * with the Job Manager on a Compute Node. The Job Manager Task counts normally
   * against the Compute Node's concurrent Task limit, so this is only relevant
   * if the Compute Node allows multiple concurrent Tasks. The default value is
   * true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask] The Job
   * Preparation Task for Jobs created under this schedule. If a Job has a Job
   * Preparation Task, the Batch service will run the Job Preparation Task on a
   * Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.id] A string
   * that uniquely identifies the Job Preparation Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobPreparationTask.commandLine
   * The command line of the Job Preparation Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.containerSettings]
   * The settings for the container under which the Job Preparation Task runs.
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.environmentSettings]
   * A list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.userIdentity]
   * The user identity under which the Job Preparation Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.jobReleaseTask]
   * The Job Release Task for Jobs created under this schedule. The primary
   * purpose of the Job Release Task is to undo changes to Nodes made by the Job
   * Preparation Task. Example activities include deleting local files, or
   * shutting down services that were started as part of Job preparation. A Job
   * Release Task cannot be specified without also specifying a Job Preparation
   * Task for the Job. The Batch service runs the Job Release Task on the Compute
   * Nodes that have run the Job Preparation Task.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.id] A string that
   * uniquely identifies the Job Release Task within the Job. The ID can contain
   * any combination of alphanumeric characters including hyphens and underscores
   * and cannot contain more than 64 characters. If you do not specify this
   * property, the Batch service assigns a default value of 'jobrelease'. No
   * other Task in the Job can have the same ID as the Job Release Task. If you
   * try to submit a Task with the same id, the Batch service rejects the request
   * with error code TaskIdSameAsJobReleaseTask; if you are calling the REST API
   * directly, the HTTP status code is 409 (Conflict).
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobReleaseTask.commandLine The
   * command line of the Job Release Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.containerSettings]
   * The settings for the container under which the Job Release Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.environmentSettings]
   * A list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
   * The maximum elapsed time that the Job Release Task may run on a given
   * Compute Node, measured from the time the Task starts. If the Task does not
   * complete within the time limit, the Batch service terminates it. The default
   * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
   * If you do, the Batch service rejects it with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.retentionTime]
   * The minimum time to retain the Task directory for the Job Release Task on
   * the Compute Node. After this time, the Batch service may delete the Task
   * directory and all its contents. The default is 7 days, i.e. the Task
   * directory will be retained for 7 days unless the Compute Node is removed or
   * the Job is deleted.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.userIdentity] The
   * user identity under which the Job Release Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.commonEnvironmentSettings] A
   * list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} jobSchedulePatchParameter.jobSpecification.poolInfo The Pool
   * on which the Batch service runs the Tasks of Jobs created under this
   * schedule.
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.poolInfo.poolId]
   * The ID of an existing Pool. All the Tasks of the Job will run on the
   * specified Pool. You must ensure that the Pool referenced by this property
   * exists. If the Pool does not exist at the time the Batch service tries to
   * schedule a Job, no Tasks for the Job will run until you create a Pool with
   * that id. Note that the Batch service will not reject the Job request; it
   * will simply not run Tasks until the Pool exists. You must specify either the
   * Pool ID or the auto Pool specification, but not both.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
   * The Pool specification for the auto Pool.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [jobSchedulePatchParameter.jobSpecification.metadata] A list
   * of name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [jobSchedulePatchParameter.metadata] A list of name-value
   * pairs associated with the Job Schedule as metadata. If you do not specify
   * this element, existing metadata is left unchanged.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobSchedulePatchOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobSchedulePatchOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobSchedulePatchOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobSchedulePatchOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobSchedulePatchOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {string} [options.jobSchedulePatchOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobSchedulePatchOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobSchedulePatchOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobSchedulePatchOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  patchWithHttpOperationResponse(jobScheduleId, jobSchedulePatchParameter, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._patch(jobScheduleId, jobSchedulePatchParameter, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Updates the properties of the specified Job Schedule.
   *
   * This replaces only the Job Schedule properties specified in the request. For
   * example, if the schedule property is not specified with this request, then
   * the Batch service will keep the existing schedule. Changes to a Job Schedule
   * only impact Jobs created by the schedule after the update has taken place;
   * currently running Jobs are unaffected.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to update.
   *
   * @param {object} jobSchedulePatchParameter The parameters for the request.
   *
   * @param {object} [jobSchedulePatchParameter.schedule] The schedule according
   * to which Jobs will be created. If you do not specify this element, the
   * existing schedule is left unchanged.
   *
   * @param {date} [jobSchedulePatchParameter.schedule.doNotRunUntil] The
   * earliest time at which any Job may be created under this Job Schedule. If
   * you do not specify a doNotRunUntil time, the schedule becomes ready to
   * create Jobs immediately.
   *
   * @param {date} [jobSchedulePatchParameter.schedule.doNotRunAfter] A time
   * after which no Job will be created under this Job Schedule. The schedule
   * will move to the completed state as soon as this deadline is past and there
   * is no active Job under this Job Schedule. If you do not specify a
   * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
   * Schedule will remain active until you explicitly terminate it.
   *
   * @param {moment.duration} [jobSchedulePatchParameter.schedule.startWindow]
   * The time interval, starting from the time at which the schedule indicates a
   * Job should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.schedule.recurrenceInterval] The time interval
   * between the start times of two successive Jobs under the Job Schedule. A Job
   * Schedule can have at most one active Job under it at any given time. Because
   * a Job Schedule can have at most one active Job under it at any given time,
   * if it is time to create a new Job under a Job Schedule, but the previous Job
   * is still running, the Batch service will not create the new Job until the
   * previous Job finishes. If the previous Job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new Job will be
   * scheduled for that interval. For recurring Jobs, you should normally specify
   * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
   * you will need an external process to monitor when Jobs are created, add
   * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
   * default is that the schedule does not recur: one Job is created, within the
   * startWindow after the doNotRunUntil time, and the schedule is complete as
   * soon as that Job finishes. The minimum value is 1 minute. If you specify a
   * lower value, the Batch service rejects the schedule with an error; if you
   * are calling the REST API directly, the HTTP status code is 400 (Bad
   * Request).
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification] The details of
   * the Jobs to be created on this schedule. Updates affect only Jobs that are
   * started after the update has taken place. Any currently active Job continues
   * with the older specification.
   *
   * @param {number} [jobSchedulePatchParameter.jobSpecification.priority] The
   * priority of Jobs created under this schedule. Priority values can range from
   * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
   * highest priority. The default value is 0. This priority is used as the
   * default for all Jobs under the Job Schedule. You can update a Job's priority
   * after it has been created using by using the update Job API.
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.displayName] The
   * display name for Jobs created under this schedule. The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.usesTaskDependencies] Whether
   * Tasks in the Job can define dependencies on each other. The default is
   * false.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.onAllTasksComplete] The action
   * the Batch service should take when all Tasks in a Job created under this
   * schedule are in the completed state. Note that if a Job contains no Tasks,
   * then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.onTaskFailure]
   * The action the Batch service should take when any Task fails in a Job
   * created under this schedule. A Task is considered to have failed if it have
   * failed if has a failureInfo. A failureInfo is set if the Task completes with
   * a non-zero exit code after exhausting its retry count, or if there was an
   * error starting the Task, for example due to a resource file download error.
   * The default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.networkConfiguration.subnetId The
   * ARM resource identifier of the virtual network subnet which Compute Nodes
   * running Tasks from the Job will join for the duration of the Task. This will
   * only work with a VirtualMachineConfiguration Pool. The virtual network must
   * be in the same region and subscription as the Azure Batch Account. The
   * specified subnet should have enough free IP addresses to accommodate the
   * number of Compute Nodes which will run Tasks from the Job. This can be up to
   * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
   * principal must have the 'Classic Virtual Machine Contributor' Role-Based
   * Access Control (RBAC) role for the specified VNet so that Azure Batch
   * service can schedule Tasks on the Nodes. This can be verified by checking if
   * the specified VNet has any associated Network Security Groups (NSG). If
   * communication to the Nodes in the specified subnet is denied by an NSG, then
   * the Batch service will set the state of the Compute Nodes to unusable. This
   * is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.constraints] The
   * execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.constraints.maxWallClockTime]
   * The maximum elapsed time that the Job may run, measured from the time the
   * Job is created. If the Job does not complete within the time limit, the
   * Batch service terminates it and any Tasks that are still running. In this
   * case, the termination reason will be MaxWallClockTimeExpiry. If this
   * property is not specified, there is no time limit on how long the Job may
   * run.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.constraints.maxTaskRetryCount]
   * The maximum number of times each Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try each
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
   * without limit. The default value is 0 (no retries).
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.jobManagerTask]
   * The details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string} jobSchedulePatchParameter.jobSpecification.jobManagerTask.id
   * A string that uniquely identifies the Job Manager Task within the Job. The
   * ID can contain any combination of alphanumeric characters including hyphens
   * and underscores and cannot contain more than 64 characters.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.displayName] The
   * display name of the Job Manager Task. It need not be unique and can contain
   * any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobManagerTask.commandLine The
   * command line of the Job Manager Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.containerSettings]
   * The settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory. There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.outputFiles] A
   * list of files that the Batch service will upload from the Compute Node after
   * running the command line. For multi-instance Tasks, the files will only be
   * uploaded from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.environmentSettings]
   * A list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.constraints]
   * Constraints that apply to the Job Manager Task.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.requiredSlots]
   * The number of scheduling slots that the Task requires to run. The default is
   * 1. A Task can only be scheduled to run on a compute node if the node has
   * enough free scheduling slots available. For multi-instance Tasks, this must
   * be 1.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.userIdentity] The
   * user identity under which the Job Manager Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.runExclusive]
   * Whether the Job Manager Task requires exclusive use of the Compute Node
   * where it runs. If true, no other Tasks will run on the same Node for as long
   * as the Job Manager is running. If false, other Tasks can run simultaneously
   * with the Job Manager on a Compute Node. The Job Manager Task counts normally
   * against the Compute Node's concurrent Task limit, so this is only relevant
   * if the Compute Node allows multiple concurrent Tasks. The default value is
   * true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask] The Job
   * Preparation Task for Jobs created under this schedule. If a Job has a Job
   * Preparation Task, the Batch service will run the Job Preparation Task on a
   * Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.id] A string
   * that uniquely identifies the Job Preparation Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobPreparationTask.commandLine
   * The command line of the Job Preparation Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.containerSettings]
   * The settings for the container under which the Job Preparation Task runs.
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.environmentSettings]
   * A list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.userIdentity]
   * The user identity under which the Job Preparation Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [jobSchedulePatchParameter.jobSpecification.jobReleaseTask]
   * The Job Release Task for Jobs created under this schedule. The primary
   * purpose of the Job Release Task is to undo changes to Nodes made by the Job
   * Preparation Task. Example activities include deleting local files, or
   * shutting down services that were started as part of Job preparation. A Job
   * Release Task cannot be specified without also specifying a Job Preparation
   * Task for the Job. The Batch service runs the Job Release Task on the Compute
   * Nodes that have run the Job Preparation Task.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.id] A string that
   * uniquely identifies the Job Release Task within the Job. The ID can contain
   * any combination of alphanumeric characters including hyphens and underscores
   * and cannot contain more than 64 characters. If you do not specify this
   * property, the Batch service assigns a default value of 'jobrelease'. No
   * other Task in the Job can have the same ID as the Job Release Task. If you
   * try to submit a Task with the same id, the Batch service rejects the request
   * with error code TaskIdSameAsJobReleaseTask; if you are calling the REST API
   * directly, the HTTP status code is 409 (Conflict).
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.jobReleaseTask.commandLine The
   * command line of the Job Release Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.containerSettings]
   * The settings for the container under which the Job Release Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.environmentSettings]
   * A list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
   * The maximum elapsed time that the Job Release Task may run on a given
   * Compute Node, measured from the time the Task starts. If the Task does not
   * complete within the time limit, the Batch service terminates it. The default
   * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
   * If you do, the Batch service rejects it with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.retentionTime]
   * The minimum time to retain the Task directory for the Job Release Task on
   * the Compute Node. After this time, the Batch service may delete the Task
   * directory and all its contents. The default is 7 days, i.e. the Task
   * directory will be retained for 7 days unless the Compute Node is removed or
   * the Job is deleted.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.jobReleaseTask.userIdentity] The
   * user identity under which the Job Release Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.commonEnvironmentSettings] A
   * list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} jobSchedulePatchParameter.jobSpecification.poolInfo The Pool
   * on which the Batch service runs the Tasks of Jobs created under this
   * schedule.
   *
   * @param {string} [jobSchedulePatchParameter.jobSpecification.poolInfo.poolId]
   * The ID of an existing Pool. All the Tasks of the Job will run on the
   * specified Pool. You must ensure that the Pool referenced by this property
   * exists. If the Pool does not exist at the time the Batch service tries to
   * schedule a Job, no Tasks for the Job will run until you create a Pool with
   * that id. Note that the Batch service will not reject the Job request; it
   * will simply not run Tasks until the Pool exists. You must specify either the
   * Pool ID or the auto Pool specification, but not both.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
   * The Pool specification for the auto Pool.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [jobSchedulePatchParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [jobSchedulePatchParameter.jobSpecification.metadata] A list
   * of name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [jobSchedulePatchParameter.metadata] A list of name-value
   * pairs associated with the Job Schedule as metadata. If you do not specify
   * this element, existing metadata is left unchanged.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobSchedulePatchOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobSchedulePatchOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobSchedulePatchOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobSchedulePatchOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobSchedulePatchOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {string} [options.jobSchedulePatchOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobSchedulePatchOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobSchedulePatchOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobSchedulePatchOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  patch(jobScheduleId, jobSchedulePatchParameter, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._patch(jobScheduleId, jobSchedulePatchParameter, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._patch(jobScheduleId, jobSchedulePatchParameter, options, optionalCallback);
    }
  }

  /**
   * @summary Updates the properties of the specified Job Schedule.
   *
   * This fully replaces all the updatable properties of the Job Schedule. For
   * example, if the schedule property is not specified with this request, then
   * the Batch service will remove the existing schedule. Changes to a Job
   * Schedule only impact Jobs created by the schedule after the update has taken
   * place; currently running Jobs are unaffected.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to update.
   *
   * @param {object} jobScheduleUpdateParameter The parameters for the request.
   *
   * @param {object} jobScheduleUpdateParameter.schedule The schedule according
   * to which Jobs will be created. If you do not specify this element, it is
   * equivalent to passing the default schedule: that is, a single Job scheduled
   * to run immediately.
   *
   * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunUntil] The
   * earliest time at which any Job may be created under this Job Schedule. If
   * you do not specify a doNotRunUntil time, the schedule becomes ready to
   * create Jobs immediately.
   *
   * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunAfter] A time
   * after which no Job will be created under this Job Schedule. The schedule
   * will move to the completed state as soon as this deadline is past and there
   * is no active Job under this Job Schedule. If you do not specify a
   * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
   * Schedule will remain active until you explicitly terminate it.
   *
   * @param {moment.duration} [jobScheduleUpdateParameter.schedule.startWindow]
   * The time interval, starting from the time at which the schedule indicates a
   * Job should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.schedule.recurrenceInterval] The time interval
   * between the start times of two successive Jobs under the Job Schedule. A Job
   * Schedule can have at most one active Job under it at any given time. Because
   * a Job Schedule can have at most one active Job under it at any given time,
   * if it is time to create a new Job under a Job Schedule, but the previous Job
   * is still running, the Batch service will not create the new Job until the
   * previous Job finishes. If the previous Job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new Job will be
   * scheduled for that interval. For recurring Jobs, you should normally specify
   * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
   * you will need an external process to monitor when Jobs are created, add
   * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
   * default is that the schedule does not recur: one Job is created, within the
   * startWindow after the doNotRunUntil time, and the schedule is complete as
   * soon as that Job finishes. The minimum value is 1 minute. If you specify a
   * lower value, the Batch service rejects the schedule with an error; if you
   * are calling the REST API directly, the HTTP status code is 400 (Bad
   * Request).
   *
   * @param {object} jobScheduleUpdateParameter.jobSpecification Details of the
   * Jobs to be created on this schedule. Updates affect only Jobs that are
   * started after the update has taken place. Any currently active Job continues
   * with the older specification.
   *
   * @param {number} [jobScheduleUpdateParameter.jobSpecification.priority] The
   * priority of Jobs created under this schedule. Priority values can range from
   * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
   * highest priority. The default value is 0. This priority is used as the
   * default for all Jobs under the Job Schedule. You can update a Job's priority
   * after it has been created using by using the update Job API.
   *
   * @param {string} [jobScheduleUpdateParameter.jobSpecification.displayName]
   * The display name for Jobs created under this schedule. The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.usesTaskDependencies] Whether
   * Tasks in the Job can define dependencies on each other. The default is
   * false.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.onAllTasksComplete] The action
   * the Batch service should take when all Tasks in a Job created under this
   * schedule are in the completed state. Note that if a Job contains no Tasks,
   * then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [jobScheduleUpdateParameter.jobSpecification.onTaskFailure]
   * The action the Batch service should take when any Task fails in a Job
   * created under this schedule. A Task is considered to have failed if it have
   * failed if has a failureInfo. A failureInfo is set if the Task completes with
   * a non-zero exit code after exhausting its retry count, or if there was an
   * error starting the Task, for example due to a resource file download error.
   * The default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.networkConfiguration.subnetId
   * The ARM resource identifier of the virtual network subnet which Compute
   * Nodes running Tasks from the Job will join for the duration of the Task.
   * This will only work with a VirtualMachineConfiguration Pool. The virtual
   * network must be in the same region and subscription as the Azure Batch
   * Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes which will run Tasks from the Job.
   * This can be up to the number of Compute Nodes in the Pool. The
   * 'MicrosoftAzureBatch' service principal must have the 'Classic Virtual
   * Machine Contributor' Role-Based Access Control (RBAC) role for the specified
   * VNet so that Azure Batch service can schedule Tasks on the Nodes. This can
   * be verified by checking if the specified VNet has any associated Network
   * Security Groups (NSG). If communication to the Nodes in the specified subnet
   * is denied by an NSG, then the Batch service will set the state of the
   * Compute Nodes to unusable. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.constraints]
   * The execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.constraints.maxWallClockTime]
   * The maximum elapsed time that the Job may run, measured from the time the
   * Job is created. If the Job does not complete within the time limit, the
   * Batch service terminates it and any Tasks that are still running. In this
   * case, the termination reason will be MaxWallClockTimeExpiry. If this
   * property is not specified, there is no time limit on how long the Job may
   * run.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.constraints.maxTaskRetryCount]
   * The maximum number of times each Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try each
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
   * without limit. The default value is 0 (no retries).
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobManagerTask]
   * The details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.id A string that
   * uniquely identifies the Job Manager Task within the Job. The ID can contain
   * any combination of alphanumeric characters including hyphens and underscores
   * and cannot contain more than 64 characters.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.displayName] The
   * display name of the Job Manager Task. It need not be unique and can contain
   * any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.commandLine The
   * command line of the Job Manager Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.containerSettings]
   * The settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory. There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.outputFiles] A
   * list of files that the Batch service will upload from the Compute Node after
   * running the command line. For multi-instance Tasks, the files will only be
   * uploaded from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.environmentSettings]
   * A list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.constraints]
   * Constraints that apply to the Job Manager Task.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.requiredSlots]
   * The number of scheduling slots that the Task requires to run. The default is
   * 1. A Task can only be scheduled to run on a compute node if the node has
   * enough free scheduling slots available. For multi-instance Tasks, this must
   * be 1.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.userIdentity]
   * The user identity under which the Job Manager Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.runExclusive]
   * Whether the Job Manager Task requires exclusive use of the Compute Node
   * where it runs. If true, no other Tasks will run on the same Node for as long
   * as the Job Manager is running. If false, other Tasks can run simultaneously
   * with the Job Manager on a Compute Node. The Job Manager Task counts normally
   * against the Compute Node's concurrent Task limit, so this is only relevant
   * if the Compute Node allows multiple concurrent Tasks. The default value is
   * true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask] The Job
   * Preparation Task for Jobs created under this schedule. If a Job has a Job
   * Preparation Task, the Batch service will run the Job Preparation Task on a
   * Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.id] A string
   * that uniquely identifies the Job Preparation Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.commandLine
   * The command line of the Job Preparation Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.containerSettings]
   * The settings for the container under which the Job Preparation Task runs.
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.environmentSettings]
   * A list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.userIdentity]
   * The user identity under which the Job Preparation Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask]
   * The Job Release Task for Jobs created under this schedule. The primary
   * purpose of the Job Release Task is to undo changes to Nodes made by the Job
   * Preparation Task. Example activities include deleting local files, or
   * shutting down services that were started as part of Job preparation. A Job
   * Release Task cannot be specified without also specifying a Job Preparation
   * Task for the Job. The Batch service runs the Job Release Task on the Compute
   * Nodes that have run the Job Preparation Task.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.id] A string
   * that uniquely identifies the Job Release Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other Task in the Job can have the same ID as the Job
   * Release Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.commandLine The
   * command line of the Job Release Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.containerSettings]
   * The settings for the container under which the Job Release Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.environmentSettings]
   * A list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
   * The maximum elapsed time that the Job Release Task may run on a given
   * Compute Node, measured from the time the Task starts. If the Task does not
   * complete within the time limit, the Batch service terminates it. The default
   * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
   * If you do, the Batch service rejects it with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.retentionTime]
   * The minimum time to retain the Task directory for the Job Release Task on
   * the Compute Node. After this time, the Batch service may delete the Task
   * directory and all its contents. The default is 7 days, i.e. the Task
   * directory will be retained for 7 days unless the Compute Node is removed or
   * the Job is deleted.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.userIdentity]
   * The user identity under which the Job Release Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.commonEnvironmentSettings] A
   * list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} jobScheduleUpdateParameter.jobSpecification.poolInfo The
   * Pool on which the Batch service runs the Tasks of Jobs created under this
   * schedule.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.poolId] The ID of an
   * existing Pool. All the Tasks of the Job will run on the specified Pool. You
   * must ensure that the Pool referenced by this property exists. If the Pool
   * does not exist at the time the Batch service tries to schedule a Job, no
   * Tasks for the Job will run until you create a Pool with that id. Note that
   * the Batch service will not reject the Job request; it will simply not run
   * Tasks until the Pool exists. You must specify either the Pool ID or the auto
   * Pool specification, but not both.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
   * The Pool specification for the auto Pool.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [jobScheduleUpdateParameter.jobSpecification.metadata] A list
   * of name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [jobScheduleUpdateParameter.metadata] A list of name-value
   * pairs associated with the Job Schedule as metadata. If you do not specify
   * this element, it takes the default value of an empty list; in effect, any
   * existing metadata is deleted.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleUpdateOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleUpdateOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleUpdateOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleUpdateOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleUpdateOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleUpdateOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  updateWithHttpOperationResponse(jobScheduleId, jobScheduleUpdateParameter, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._update(jobScheduleId, jobScheduleUpdateParameter, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Updates the properties of the specified Job Schedule.
   *
   * This fully replaces all the updatable properties of the Job Schedule. For
   * example, if the schedule property is not specified with this request, then
   * the Batch service will remove the existing schedule. Changes to a Job
   * Schedule only impact Jobs created by the schedule after the update has taken
   * place; currently running Jobs are unaffected.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to update.
   *
   * @param {object} jobScheduleUpdateParameter The parameters for the request.
   *
   * @param {object} jobScheduleUpdateParameter.schedule The schedule according
   * to which Jobs will be created. If you do not specify this element, it is
   * equivalent to passing the default schedule: that is, a single Job scheduled
   * to run immediately.
   *
   * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunUntil] The
   * earliest time at which any Job may be created under this Job Schedule. If
   * you do not specify a doNotRunUntil time, the schedule becomes ready to
   * create Jobs immediately.
   *
   * @param {date} [jobScheduleUpdateParameter.schedule.doNotRunAfter] A time
   * after which no Job will be created under this Job Schedule. The schedule
   * will move to the completed state as soon as this deadline is past and there
   * is no active Job under this Job Schedule. If you do not specify a
   * doNotRunAfter time, and you are creating a recurring Job Schedule, the Job
   * Schedule will remain active until you explicitly terminate it.
   *
   * @param {moment.duration} [jobScheduleUpdateParameter.schedule.startWindow]
   * The time interval, starting from the time at which the schedule indicates a
   * Job should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.schedule.recurrenceInterval] The time interval
   * between the start times of two successive Jobs under the Job Schedule. A Job
   * Schedule can have at most one active Job under it at any given time. Because
   * a Job Schedule can have at most one active Job under it at any given time,
   * if it is time to create a new Job under a Job Schedule, but the previous Job
   * is still running, the Batch service will not create the new Job until the
   * previous Job finishes. If the previous Job does not finish within the
   * startWindow period of the new recurrenceInterval, then no new Job will be
   * scheduled for that interval. For recurring Jobs, you should normally specify
   * a jobManagerTask in the jobSpecification. If you do not use jobManagerTask,
   * you will need an external process to monitor when Jobs are created, add
   * Tasks to the Jobs and terminate the Jobs ready for the next recurrence. The
   * default is that the schedule does not recur: one Job is created, within the
   * startWindow after the doNotRunUntil time, and the schedule is complete as
   * soon as that Job finishes. The minimum value is 1 minute. If you specify a
   * lower value, the Batch service rejects the schedule with an error; if you
   * are calling the REST API directly, the HTTP status code is 400 (Bad
   * Request).
   *
   * @param {object} jobScheduleUpdateParameter.jobSpecification Details of the
   * Jobs to be created on this schedule. Updates affect only Jobs that are
   * started after the update has taken place. Any currently active Job continues
   * with the older specification.
   *
   * @param {number} [jobScheduleUpdateParameter.jobSpecification.priority] The
   * priority of Jobs created under this schedule. Priority values can range from
   * -1000 to 1000, with -1000 being the lowest priority and 1000 being the
   * highest priority. The default value is 0. This priority is used as the
   * default for all Jobs under the Job Schedule. You can update a Job's priority
   * after it has been created using by using the update Job API.
   *
   * @param {string} [jobScheduleUpdateParameter.jobSpecification.displayName]
   * The display name for Jobs created under this schedule. The name need not be
   * unique and can contain any Unicode characters up to a maximum length of
   * 1024.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.usesTaskDependencies] Whether
   * Tasks in the Job can define dependencies on each other. The default is
   * false.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.onAllTasksComplete] The action
   * the Batch service should take when all Tasks in a Job created under this
   * schedule are in the completed state. Note that if a Job contains no Tasks,
   * then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [jobScheduleUpdateParameter.jobSpecification.onTaskFailure]
   * The action the Batch service should take when any Task fails in a Job
   * created under this schedule. A Task is considered to have failed if it have
   * failed if has a failureInfo. A failureInfo is set if the Task completes with
   * a non-zero exit code after exhausting its retry count, or if there was an
   * error starting the Task, for example due to a resource file download error.
   * The default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.networkConfiguration.subnetId
   * The ARM resource identifier of the virtual network subnet which Compute
   * Nodes running Tasks from the Job will join for the duration of the Task.
   * This will only work with a VirtualMachineConfiguration Pool. The virtual
   * network must be in the same region and subscription as the Azure Batch
   * Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes which will run Tasks from the Job.
   * This can be up to the number of Compute Nodes in the Pool. The
   * 'MicrosoftAzureBatch' service principal must have the 'Classic Virtual
   * Machine Contributor' Role-Based Access Control (RBAC) role for the specified
   * VNet so that Azure Batch service can schedule Tasks on the Nodes. This can
   * be verified by checking if the specified VNet has any associated Network
   * Security Groups (NSG). If communication to the Nodes in the specified subnet
   * is denied by an NSG, then the Batch service will set the state of the
   * Compute Nodes to unusable. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.constraints]
   * The execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.constraints.maxWallClockTime]
   * The maximum elapsed time that the Job may run, measured from the time the
   * Job is created. If the Job does not complete within the time limit, the
   * Batch service terminates it and any Tasks that are still running. In this
   * case, the termination reason will be MaxWallClockTimeExpiry. If this
   * property is not specified, there is no time limit on how long the Job may
   * run.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.constraints.maxTaskRetryCount]
   * The maximum number of times each Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try each
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries a Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * Tasks. If the maximum retry count is -1, the Batch service retries Tasks
   * without limit. The default value is 0 (no retries).
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobManagerTask]
   * The details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.id A string that
   * uniquely identifies the Job Manager Task within the Job. The ID can contain
   * any combination of alphanumeric characters including hyphens and underscores
   * and cannot contain more than 64 characters.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.displayName] The
   * display name of the Job Manager Task. It need not be unique and can contain
   * any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobManagerTask.commandLine The
   * command line of the Job Manager Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.containerSettings]
   * The settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory. There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.outputFiles] A
   * list of files that the Batch service will upload from the Compute Node after
   * running the command line. For multi-instance Tasks, the files will only be
   * uploaded from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.environmentSettings]
   * A list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.constraints]
   * Constraints that apply to the Job Manager Task.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.requiredSlots]
   * The number of scheduling slots that the Task requires to run. The default is
   * 1. A Task can only be scheduled to run on a compute node if the node has
   * enough free scheduling slots available. For multi-instance Tasks, this must
   * be 1.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.userIdentity]
   * The user identity under which the Job Manager Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.runExclusive]
   * Whether the Job Manager Task requires exclusive use of the Compute Node
   * where it runs. If true, no other Tasks will run on the same Node for as long
   * as the Job Manager is running. If false, other Tasks can run simultaneously
   * with the Job Manager on a Compute Node. The Job Manager Task counts normally
   * against the Compute Node's concurrent Task limit, so this is only relevant
   * if the Compute Node allows multiple concurrent Tasks. The default value is
   * true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask] The Job
   * Preparation Task for Jobs created under this schedule. If a Job has a Job
   * Preparation Task, the Batch service will run the Job Preparation Task on a
   * Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.id] A string
   * that uniquely identifies the Job Preparation Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.commandLine
   * The command line of the Job Preparation Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.containerSettings]
   * The settings for the container under which the Job Preparation Task runs.
   * When this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line. Files listed under this element are located
   * in the Task's working directory.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.environmentSettings]
   * A list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.userIdentity]
   * The user identity under which the Job Preparation Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask]
   * The Job Release Task for Jobs created under this schedule. The primary
   * purpose of the Job Release Task is to undo changes to Nodes made by the Job
   * Preparation Task. Example activities include deleting local files, or
   * shutting down services that were started as part of Job preparation. A Job
   * Release Task cannot be specified without also specifying a Job Preparation
   * Task for the Job. The Batch service runs the Job Release Task on the Compute
   * Nodes that have run the Job Preparation Task.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.id] A string
   * that uniquely identifies the Job Release Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other Task in the Job can have the same ID as the Job
   * Release Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.commandLine The
   * command line of the Job Release Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.containerSettings]
   * The settings for the container under which the Job Release Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.resourceFiles] A
   * list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files.  When the max size is exceeded, the request will fail and
   * the response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.environmentSettings]
   * A list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.maxWallClockTime]
   * The maximum elapsed time that the Job Release Task may run on a given
   * Compute Node, measured from the time the Task starts. If the Task does not
   * complete within the time limit, the Batch service terminates it. The default
   * value is 15 minutes. You may not specify a timeout longer than 15 minutes.
   * If you do, the Batch service rejects it with an error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.retentionTime]
   * The minimum time to retain the Task directory for the Job Release Task on
   * the Compute Node. After this time, the Batch service may delete the Task
   * directory and all its contents. The default is 7 days, i.e. the Task
   * directory will be retained for 7 days unless the Compute Node is removed or
   * the Job is deleted.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.jobReleaseTask.userIdentity]
   * The user identity under which the Job Release Task runs. If omitted, the
   * Task runs as a non-administrative user unique to the Task.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.commonEnvironmentSettings] A
   * list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} jobScheduleUpdateParameter.jobSpecification.poolInfo The
   * Pool on which the Batch service runs the Tasks of Jobs created under this
   * schedule.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.poolId] The ID of an
   * existing Pool. All the Tasks of the Job will run on the specified Pool. You
   * must ensure that the Pool referenced by this property exists. If the Pool
   * does not exist at the time the Batch service tries to schedule a Job, no
   * Tasks for the Job will run until you create a Pool with that id. Note that
   * the Batch service will not reject the Job request; it will simply not run
   * Tasks until the Pool exists. You must specify either the Pool ID or the auto
   * Pool specification, but not both.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool]
   * The Pool specification for the auto Pool.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [jobScheduleUpdateParameter.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [jobScheduleUpdateParameter.jobSpecification.metadata] A list
   * of name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [jobScheduleUpdateParameter.metadata] A list of name-value
   * pairs associated with the Job Schedule as metadata. If you do not specify
   * this element, it takes the default value of an empty list; in effect, any
   * existing metadata is deleted.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleUpdateOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleUpdateOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleUpdateOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleUpdateOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleUpdateOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleUpdateOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleUpdateOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  update(jobScheduleId, jobScheduleUpdateParameter, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._update(jobScheduleId, jobScheduleUpdateParameter, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._update(jobScheduleId, jobScheduleUpdateParameter, options, optionalCallback);
    }
  }

  /**
   * @summary Disables a Job Schedule.
   *
   * No new Jobs will be created until the Job Schedule is enabled again.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to disable.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleDisableOptions] Additional parameters
   * for the operation
   *
   * @param {number} [options.jobScheduleDisableOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleDisableOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleDisableOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleDisableOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleDisableOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleDisableOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleDisableOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleDisableOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  disableWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._disable(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Disables a Job Schedule.
   *
   * No new Jobs will be created until the Job Schedule is enabled again.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to disable.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleDisableOptions] Additional parameters
   * for the operation
   *
   * @param {number} [options.jobScheduleDisableOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleDisableOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleDisableOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleDisableOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleDisableOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleDisableOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleDisableOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleDisableOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  disable(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._disable(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._disable(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * @summary Enables a Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to enable.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleEnableOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleEnableOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleEnableOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleEnableOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleEnableOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleEnableOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleEnableOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleEnableOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleEnableOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  enableWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._enable(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Enables a Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to enable.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleEnableOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleEnableOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleEnableOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleEnableOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleEnableOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleEnableOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleEnableOptions.ifNoneMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleEnableOptions.ifModifiedSince] A timestamp
   * indicating the last modified time of the resource known to the client. The
   * operation will be performed only if the resource on the service has been
   * modified since the specified time.
   *
   * @param {date} [options.jobScheduleEnableOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  enable(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._enable(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._enable(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * @summary Terminates a Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to terminates.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleTerminateOptions] Additional parameters
   * for the operation
   *
   * @param {number} [options.jobScheduleTerminateOptions.timeout] The maximum
   * time that the server can spend processing the request, in seconds. The
   * default is 30 seconds.
   *
   * @param {uuid} [options.jobScheduleTerminateOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleTerminateOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleTerminateOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleTerminateOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  terminateWithHttpOperationResponse(jobScheduleId, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._terminate(jobScheduleId, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Terminates a Job Schedule.
   *
   * @param {string} jobScheduleId The ID of the Job Schedule to terminates.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleTerminateOptions] Additional parameters
   * for the operation
   *
   * @param {number} [options.jobScheduleTerminateOptions.timeout] The maximum
   * time that the server can spend processing the request, in seconds. The
   * default is 30 seconds.
   *
   * @param {uuid} [options.jobScheduleTerminateOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleTerminateOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {string} [options.jobScheduleTerminateOptions.ifMatch] An ETag value
   * associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service exactly matches the value specified by the client.
   *
   * @param {string} [options.jobScheduleTerminateOptions.ifNoneMatch] An ETag
   * value associated with the version of the resource known to the client. The
   * operation will be performed only if the resource's current ETag on the
   * service does not match the value specified by the client.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ifModifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has been modified since the specified time.
   *
   * @param {date} [options.jobScheduleTerminateOptions.ifUnmodifiedSince] A
   * timestamp indicating the last modified time of the resource known to the
   * client. The operation will be performed only if the resource on the service
   * has not been modified since the specified time.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  terminate(jobScheduleId, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._terminate(jobScheduleId, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._terminate(jobScheduleId, options, optionalCallback);
    }
  }

  /**
   * @summary Adds a Job Schedule to the specified Account.
   *
   * @param {object} cloudJobSchedule The Job Schedule to be added.
   *
   * @param {string} cloudJobSchedule.id A string that uniquely identifies the
   * schedule within the Account. The ID can contain any combination of
   * alphanumeric characters including hyphens and underscores, and cannot
   * contain more than 64 characters. The ID is case-preserving and
   * case-insensitive (that is, you may not have two IDs within an Account that
   * differ only by case).
   *
   * @param {string} [cloudJobSchedule.displayName] The display name for the
   * schedule. The display name need not be unique and can contain any Unicode
   * characters up to a maximum length of 1024.
   *
   * @param {object} cloudJobSchedule.schedule The schedule according to which
   * Jobs will be created.
   *
   * @param {date} [cloudJobSchedule.schedule.doNotRunUntil] The earliest time at
   * which any Job may be created under this Job Schedule. If you do not specify
   * a doNotRunUntil time, the schedule becomes ready to create Jobs immediately.
   *
   * @param {date} [cloudJobSchedule.schedule.doNotRunAfter] A time after which
   * no Job will be created under this Job Schedule. The schedule will move to
   * the completed state as soon as this deadline is past and there is no active
   * Job under this Job Schedule. If you do not specify a doNotRunAfter time, and
   * you are creating a recurring Job Schedule, the Job Schedule will remain
   * active until you explicitly terminate it.
   *
   * @param {moment.duration} [cloudJobSchedule.schedule.startWindow] The time
   * interval, starting from the time at which the schedule indicates a Job
   * should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration} [cloudJobSchedule.schedule.recurrenceInterval] The
   * time interval between the start times of two successive Jobs under the Job
   * Schedule. A Job Schedule can have at most one active Job under it at any
   * given time. Because a Job Schedule can have at most one active Job under it
   * at any given time, if it is time to create a new Job under a Job Schedule,
   * but the previous Job is still running, the Batch service will not create the
   * new Job until the previous Job finishes. If the previous Job does not finish
   * within the startWindow period of the new recurrenceInterval, then no new Job
   * will be scheduled for that interval. For recurring Jobs, you should normally
   * specify a jobManagerTask in the jobSpecification. If you do not use
   * jobManagerTask, you will need an external process to monitor when Jobs are
   * created, add Tasks to the Jobs and terminate the Jobs ready for the next
   * recurrence. The default is that the schedule does not recur: one Job is
   * created, within the startWindow after the doNotRunUntil time, and the
   * schedule is complete as soon as that Job finishes. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object} cloudJobSchedule.jobSpecification The details of the Jobs to
   * be created on this schedule.
   *
   * @param {number} [cloudJobSchedule.jobSpecification.priority] The priority of
   * Jobs created under this schedule. Priority values can range from -1000 to
   * 1000, with -1000 being the lowest priority and 1000 being the highest
   * priority. The default value is 0. This priority is used as the default for
   * all Jobs under the Job Schedule. You can update a Job's priority after it
   * has been created using by using the update Job API.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.displayName] The display
   * name for Jobs created under this schedule. The name need not be unique and
   * can contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {boolean} [cloudJobSchedule.jobSpecification.usesTaskDependencies]
   * Whether Tasks in the Job can define dependencies on each other. The default
   * is false.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.onAllTasksComplete] The
   * action the Batch service should take when all Tasks in a Job created under
   * this schedule are in the completed state. Note that if a Job contains no
   * Tasks, then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [cloudJobSchedule.jobSpecification.onTaskFailure] The action
   * the Batch service should take when any Task fails in a Job created under
   * this schedule. A Task is considered to have failed if it have failed if has
   * a failureInfo. A failureInfo is set if the Task completes with a non-zero
   * exit code after exhausting its retry count, or if there was an error
   * starting the Task, for example due to a resource file download error. The
   * default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object} [cloudJobSchedule.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.networkConfiguration.subnetId The ARM
   * resource identifier of the virtual network subnet which Compute Nodes
   * running Tasks from the Job will join for the duration of the Task. This will
   * only work with a VirtualMachineConfiguration Pool. The virtual network must
   * be in the same region and subscription as the Azure Batch Account. The
   * specified subnet should have enough free IP addresses to accommodate the
   * number of Compute Nodes which will run Tasks from the Job. This can be up to
   * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
   * principal must have the 'Classic Virtual Machine Contributor' Role-Based
   * Access Control (RBAC) role for the specified VNet so that Azure Batch
   * service can schedule Tasks on the Nodes. This can be verified by checking if
   * the specified VNet has any associated Network Security Groups (NSG). If
   * communication to the Nodes in the specified subnet is denied by an NSG, then
   * the Batch service will set the state of the Compute Nodes to unusable. This
   * is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [cloudJobSchedule.jobSpecification.constraints] The
   * execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.constraints.maxWallClockTime] The maximum
   * elapsed time that the Job may run, measured from the time the Job is
   * created. If the Job does not complete within the time limit, the Batch
   * service terminates it and any Tasks that are still running. In this case,
   * the termination reason will be MaxWallClockTimeExpiry. If this property is
   * not specified, there is no time limit on how long the Job may run.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.constraints.maxTaskRetryCount] The
   * maximum number of times each Task may be retried. The Batch service retries
   * a Task if its exit code is nonzero. Note that this value specifically
   * controls the number of retries. The Batch service will try each Task once,
   * and may then retry up to this limit. For example, if the maximum retry count
   * is 3, Batch tries a Task up to 4 times (one initial try and 3 retries). If
   * the maximum retry count is 0, the Batch service does not retry Tasks. If the
   * maximum retry count is -1, the Batch service retries Tasks without limit.
   * The default value is 0 (no retries).
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobManagerTask] The
   * details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.id A string
   * that uniquely identifies the Job Manager Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.displayName] The display
   * name of the Job Manager Task. It need not be unique and can contain any
   * Unicode characters up to a maximum length of 1024.
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.commandLine
   * The command line of the Job Manager Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.containerSettings] The
   * settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.resourceFiles] A list of
   * files that the Batch service will download to the Compute Node before
   * running the command line. Files listed under this element are located in the
   * Task's working directory. There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.outputFiles] A list of
   * files that the Batch service will upload from the Compute Node after running
   * the command line. For multi-instance Tasks, the files will only be uploaded
   * from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.environmentSettings] A
   * list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.constraints] Constraints
   * that apply to the Job Manager Task.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.requiredSlots] The number
   * of scheduling slots that the Task requires to run. The default is 1. A Task
   * can only be scheduled to run on a compute node if the node has enough free
   * scheduling slots available. For multi-instance Tasks, this must be 1.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.userIdentity] The user
   * identity under which the Job Manager Task runs. If omitted, the Task runs as
   * a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.runExclusive] Whether the
   * Job Manager Task requires exclusive use of the Compute Node where it runs.
   * If true, no other Tasks will run on the same Node for as long as the Job
   * Manager is running. If false, other Tasks can run simultaneously with the
   * Job Manager on a Compute Node. The Job Manager Task counts normally against
   * the Compute Node's concurrent Task limit, so this is only relevant if the
   * Compute Node allows multiple concurrent Tasks. The default value is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobPreparationTask] The
   * Job Preparation Task for Jobs created under this schedule. If a Job has a
   * Job Preparation Task, the Batch service will run the Job Preparation Task on
   * a Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.jobPreparationTask.id] A
   * string that uniquely identifies the Job Preparation Task within the Job. The
   * ID can contain any combination of alphanumeric characters including hyphens
   * and underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.jobPreparationTask.commandLine The command
   * line of the Job Preparation Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.containerSettings] The
   * settings for the container under which the Job Preparation Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.resourceFiles] A list
   * of files that the Batch service will download to the Compute Node before
   * running the command line. Files listed under this element are located in the
   * Task's working directory.  There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.environmentSettings] A
   * list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.userIdentity] The user
   * identity under which the Job Preparation Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobReleaseTask] The Job
   * Release Task for Jobs created under this schedule. The primary purpose of
   * the Job Release Task is to undo changes to Nodes made by the Job Preparation
   * Task. Example activities include deleting local files, or shutting down
   * services that were started as part of Job preparation. A Job Release Task
   * cannot be specified without also specifying a Job Preparation Task for the
   * Job. The Batch service runs the Job Release Task on the Compute Nodes that
   * have run the Job Preparation Task.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.jobReleaseTask.id] A
   * string that uniquely identifies the Job Release Task within the Job. The ID
   * can contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other Task in the Job can have the same ID as the Job
   * Release Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobReleaseTask.commandLine
   * The command line of the Job Release Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.containerSettings] The
   * settings for the container under which the Job Release Task runs. When this
   * is specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR
   * (the root of Azure Batch directories on the node) are mapped into the
   * container, all Task environment variables are mapped into the container, and
   * the Task command line is executed in the container. Files produced in the
   * container outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the
   * host disk, meaning that Batch file APIs will not be able to access those
   * files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.resourceFiles] A list of
   * files that the Batch service will download to the Compute Node before
   * running the command line.  There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.environmentSettings] A
   * list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.maxWallClockTime] The
   * maximum elapsed time that the Job Release Task may run on a given Compute
   * Node, measured from the time the Task starts. If the Task does not complete
   * within the time limit, the Batch service terminates it. The default value is
   * 15 minutes. You may not specify a timeout longer than 15 minutes. If you do,
   * the Batch service rejects it with an error; if you are calling the REST API
   * directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.retentionTime] The minimum
   * time to retain the Task directory for the Job Release Task on the Compute
   * Node. After this time, the Batch service may delete the Task directory and
   * all its contents. The default is 7 days, i.e. the Task directory will be
   * retained for 7 days unless the Compute Node is removed or the Job is
   * deleted.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.userIdentity] The user
   * identity under which the Job Release Task runs. If omitted, the Task runs as
   * a non-administrative user unique to the Task.
   *
   * @param {array} [cloudJobSchedule.jobSpecification.commonEnvironmentSettings]
   * A list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} cloudJobSchedule.jobSpecification.poolInfo The Pool on which
   * the Batch service runs the Tasks of Jobs created under this schedule.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.poolInfo.poolId] The ID
   * of an existing Pool. All the Tasks of the Job will run on the specified
   * Pool. You must ensure that the Pool referenced by this property exists. If
   * the Pool does not exist at the time the Batch service tries to schedule a
   * Job, no Tasks for the Job will run until you create a Pool with that id.
   * Note that the Batch service will not reject the Job request; it will simply
   * not run Tasks until the Pool exists. You must specify either the Pool ID or
   * the auto Pool specification, but not both.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool] The
   * Pool specification for the auto Pool.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [cloudJobSchedule.jobSpecification.metadata] A list of
   * name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [cloudJobSchedule.metadata] A list of name-value pairs
   * associated with the schedule as metadata. The Batch service does not assign
   * any meaning to metadata; it is solely for the use of user code.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleAddOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleAddOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleAddOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleAddOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleAddOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<null>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  addWithHttpOperationResponse(cloudJobSchedule, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._add(cloudJobSchedule, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Adds a Job Schedule to the specified Account.
   *
   * @param {object} cloudJobSchedule The Job Schedule to be added.
   *
   * @param {string} cloudJobSchedule.id A string that uniquely identifies the
   * schedule within the Account. The ID can contain any combination of
   * alphanumeric characters including hyphens and underscores, and cannot
   * contain more than 64 characters. The ID is case-preserving and
   * case-insensitive (that is, you may not have two IDs within an Account that
   * differ only by case).
   *
   * @param {string} [cloudJobSchedule.displayName] The display name for the
   * schedule. The display name need not be unique and can contain any Unicode
   * characters up to a maximum length of 1024.
   *
   * @param {object} cloudJobSchedule.schedule The schedule according to which
   * Jobs will be created.
   *
   * @param {date} [cloudJobSchedule.schedule.doNotRunUntil] The earliest time at
   * which any Job may be created under this Job Schedule. If you do not specify
   * a doNotRunUntil time, the schedule becomes ready to create Jobs immediately.
   *
   * @param {date} [cloudJobSchedule.schedule.doNotRunAfter] A time after which
   * no Job will be created under this Job Schedule. The schedule will move to
   * the completed state as soon as this deadline is past and there is no active
   * Job under this Job Schedule. If you do not specify a doNotRunAfter time, and
   * you are creating a recurring Job Schedule, the Job Schedule will remain
   * active until you explicitly terminate it.
   *
   * @param {moment.duration} [cloudJobSchedule.schedule.startWindow] The time
   * interval, starting from the time at which the schedule indicates a Job
   * should be created, within which a Job must be created. If a Job is not
   * created within the startWindow interval, then the 'opportunity' is lost; no
   * Job will be created until the next recurrence of the schedule. If the
   * schedule is recurring, and the startWindow is longer than the recurrence
   * interval, then this is equivalent to an infinite startWindow, because the
   * Job that is 'due' in one recurrenceInterval is not carried forward into the
   * next recurrence interval. The default is infinite. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {moment.duration} [cloudJobSchedule.schedule.recurrenceInterval] The
   * time interval between the start times of two successive Jobs under the Job
   * Schedule. A Job Schedule can have at most one active Job under it at any
   * given time. Because a Job Schedule can have at most one active Job under it
   * at any given time, if it is time to create a new Job under a Job Schedule,
   * but the previous Job is still running, the Batch service will not create the
   * new Job until the previous Job finishes. If the previous Job does not finish
   * within the startWindow period of the new recurrenceInterval, then no new Job
   * will be scheduled for that interval. For recurring Jobs, you should normally
   * specify a jobManagerTask in the jobSpecification. If you do not use
   * jobManagerTask, you will need an external process to monitor when Jobs are
   * created, add Tasks to the Jobs and terminate the Jobs ready for the next
   * recurrence. The default is that the schedule does not recur: one Job is
   * created, within the startWindow after the doNotRunUntil time, and the
   * schedule is complete as soon as that Job finishes. The minimum value is 1
   * minute. If you specify a lower value, the Batch service rejects the schedule
   * with an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object} cloudJobSchedule.jobSpecification The details of the Jobs to
   * be created on this schedule.
   *
   * @param {number} [cloudJobSchedule.jobSpecification.priority] The priority of
   * Jobs created under this schedule. Priority values can range from -1000 to
   * 1000, with -1000 being the lowest priority and 1000 being the highest
   * priority. The default value is 0. This priority is used as the default for
   * all Jobs under the Job Schedule. You can update a Job's priority after it
   * has been created using by using the update Job API.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.displayName] The display
   * name for Jobs created under this schedule. The name need not be unique and
   * can contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {boolean} [cloudJobSchedule.jobSpecification.usesTaskDependencies]
   * Whether Tasks in the Job can define dependencies on each other. The default
   * is false.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.onAllTasksComplete] The
   * action the Batch service should take when all Tasks in a Job created under
   * this schedule are in the completed state. Note that if a Job contains no
   * Tasks, then all Tasks are considered complete. This option is therefore most
   * commonly used with a Job Manager task; if you want to use automatic Job
   * termination without a Job Manager, you should initially set
   * onAllTasksComplete to noaction and update the Job properties to set
   * onAllTasksComplete to terminatejob once you have finished adding Tasks. The
   * default is noaction. Possible values include: 'noAction', 'terminateJob'
   *
   * @param {string} [cloudJobSchedule.jobSpecification.onTaskFailure] The action
   * the Batch service should take when any Task fails in a Job created under
   * this schedule. A Task is considered to have failed if it have failed if has
   * a failureInfo. A failureInfo is set if the Task completes with a non-zero
   * exit code after exhausting its retry count, or if there was an error
   * starting the Task, for example due to a resource file download error. The
   * default is noaction. Possible values include: 'noAction',
   * 'performExitOptionsJobAction'
   *
   * @param {object} [cloudJobSchedule.jobSpecification.networkConfiguration] The
   * network configuration for the Job.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.networkConfiguration.subnetId The ARM
   * resource identifier of the virtual network subnet which Compute Nodes
   * running Tasks from the Job will join for the duration of the Task. This will
   * only work with a VirtualMachineConfiguration Pool. The virtual network must
   * be in the same region and subscription as the Azure Batch Account. The
   * specified subnet should have enough free IP addresses to accommodate the
   * number of Compute Nodes which will run Tasks from the Job. This can be up to
   * the number of Compute Nodes in the Pool. The 'MicrosoftAzureBatch' service
   * principal must have the 'Classic Virtual Machine Contributor' Role-Based
   * Access Control (RBAC) role for the specified VNet so that Azure Batch
   * service can schedule Tasks on the Nodes. This can be verified by checking if
   * the specified VNet has any associated Network Security Groups (NSG). If
   * communication to the Nodes in the specified subnet is denied by an NSG, then
   * the Batch service will set the state of the Compute Nodes to unusable. This
   * is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * If the specified VNet has any associated Network Security Groups (NSG), then
   * a few reserved system ports must be enabled for inbound communication from
   * the Azure Batch service. For Pools created with a Virtual Machine
   * configuration, enable ports 29876 and 29877, as well as port 22 for Linux
   * and port 3389 for Windows. Port 443 is also required to be open for outbound
   * connections for communications to Azure Storage. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {object} [cloudJobSchedule.jobSpecification.constraints] The
   * execution constraints for Jobs created under this schedule.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.constraints.maxWallClockTime] The maximum
   * elapsed time that the Job may run, measured from the time the Job is
   * created. If the Job does not complete within the time limit, the Batch
   * service terminates it and any Tasks that are still running. In this case,
   * the termination reason will be MaxWallClockTimeExpiry. If this property is
   * not specified, there is no time limit on how long the Job may run.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.constraints.maxTaskRetryCount] The
   * maximum number of times each Task may be retried. The Batch service retries
   * a Task if its exit code is nonzero. Note that this value specifically
   * controls the number of retries. The Batch service will try each Task once,
   * and may then retry up to this limit. For example, if the maximum retry count
   * is 3, Batch tries a Task up to 4 times (one initial try and 3 retries). If
   * the maximum retry count is 0, the Batch service does not retry Tasks. If the
   * maximum retry count is -1, the Batch service retries Tasks without limit.
   * The default value is 0 (no retries).
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobManagerTask] The
   * details of a Job Manager Task to be launched when a Job is started under
   * this schedule. If the Job does not specify a Job Manager Task, the user must
   * explicitly add Tasks to the Job using the Task API. If the Job does specify
   * a Job Manager Task, the Batch service creates the Job Manager Task when the
   * Job is created, and will try to schedule the Job Manager Task before
   * scheduling other Tasks in the Job.
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.id A string
   * that uniquely identifies the Job Manager Task within the Job. The ID can
   * contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.displayName] The display
   * name of the Job Manager Task. It need not be unique and can contain any
   * Unicode characters up to a maximum length of 1024.
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobManagerTask.commandLine
   * The command line of the Job Manager Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.containerSettings] The
   * settings for the container under which the Job Manager Task runs. If the
   * Pool that will run this Task has containerConfiguration set, this must be
   * set as well. If the Pool that will run this Task doesn't have
   * containerConfiguration set, this must not be set. When this is specified,
   * all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of
   * Azure Batch directories on the node) are mapped into the container, all Task
   * environment variables are mapped into the container, and the Task command
   * line is executed in the container. Files produced in the container outside
   * of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning
   * that Batch file APIs will not be able to access those files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.resourceFiles] A list of
   * files that the Batch service will download to the Compute Node before
   * running the command line. Files listed under this element are located in the
   * Task's working directory. There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.outputFiles] A list of
   * files that the Batch service will upload from the Compute Node after running
   * the command line. For multi-instance Tasks, the files will only be uploaded
   * from the Compute Node on which the primary Task is executed.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.environmentSettings] A
   * list of environment variable settings for the Job Manager Task.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.constraints] Constraints
   * that apply to the Job Manager Task.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.requiredSlots] The number
   * of scheduling slots that the Task requires to run. The default is 1. A Task
   * can only be scheduled to run on a compute node if the node has enough free
   * scheduling slots available. For multi-instance Tasks, this must be 1.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.killJobOnCompletion]
   * Whether completion of the Job Manager Task signifies completion of the
   * entire Job. If true, when the Job Manager Task completes, the Batch service
   * marks the Job as complete. If any Tasks are still running at this time
   * (other than Job Release), those Tasks are terminated. If false, the
   * completion of the Job Manager Task does not affect the Job status. In this
   * case, you should either use the onAllTasksComplete attribute to terminate
   * the Job, or have a client or user terminate the Job explicitly. An example
   * of this is if the Job Manager creates a set of Tasks but then takes no
   * further role in their execution. The default value is true. If you are using
   * the onAllTasksComplete and onTaskFailure attributes to control Job lifetime,
   * and using the Job Manager Task only to create the Tasks for the Job (not to
   * monitor progress), then it is important to set killJobOnCompletion to false.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.userIdentity] The user
   * identity under which the Job Manager Task runs. If omitted, the Task runs as
   * a non-administrative user unique to the Task.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.runExclusive] Whether the
   * Job Manager Task requires exclusive use of the Compute Node where it runs.
   * If true, no other Tasks will run on the same Node for as long as the Job
   * Manager is running. If false, other Tasks can run simultaneously with the
   * Job Manager on a Compute Node. The Job Manager Task counts normally against
   * the Compute Node's concurrent Task limit, so this is only relevant if the
   * Compute Node allows multiple concurrent Tasks. The default value is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.applicationPackageReferences]
   * A list of Application Packages that the Batch service will deploy to the
   * Compute Node before running the command line. Application Packages are
   * downloaded and deployed to a shared directory, not the Task working
   * directory. Therefore, if a referenced Application Package is already on the
   * Compute Node, and is up to date, then it is not re-downloaded; the existing
   * copy on the Compute Node is used. If a referenced Application Package cannot
   * be installed, for example because the package has been deleted or because
   * download failed, the Task fails.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings]
   * The settings for an authentication token that the Task can use to perform
   * Batch service operations. If this property is set, the Batch service
   * provides the Task with an authentication token which can be used to
   * authenticate Batch service operations without requiring an Account access
   * key. The token is provided via the AZ_BATCH_AUTHENTICATION_TOKEN environment
   * variable. The operations that the Task can carry out using the token depend
   * on the settings. For example, a Task can request Job permissions in order to
   * add other Tasks to the Job, or check the status of the Job or of other Tasks
   * under the Job.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.authenticationTokenSettings.access]
   * The Batch resources to which the token grants access. The authentication
   * token grants access to a limited set of Batch service operations. Currently
   * the only supported value for the access property is 'job', which grants
   * access to all operations related to the Job which contains the Task.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobManagerTask.allowLowPriorityNode]
   * Whether the Job Manager Task may run on a low-priority Compute Node. The
   * default value is true.
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobPreparationTask] The
   * Job Preparation Task for Jobs created under this schedule. If a Job has a
   * Job Preparation Task, the Batch service will run the Job Preparation Task on
   * a Node before starting any Tasks of that Job on that Compute Node.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.jobPreparationTask.id] A
   * string that uniquely identifies the Job Preparation Task within the Job. The
   * ID can contain any combination of alphanumeric characters including hyphens
   * and underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobpreparation'. No other Task in the Job can have the same ID as the Job
   * Preparation Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobPreparationTask;
   * if you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.jobPreparationTask.commandLine The command
   * line of the Job Preparation Task. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.containerSettings] The
   * settings for the container under which the Job Preparation Task runs. When
   * this is specified, all directories recursively below the
   * AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
   * mapped into the container, all Task environment variables are mapped into
   * the container, and the Task command line is executed in the container. Files
   * produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
   * reflected to the host disk, meaning that Batch file APIs will not be able to
   * access those files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.resourceFiles] A list
   * of files that the Batch service will download to the Compute Node before
   * running the command line. Files listed under this element are located in the
   * Task's working directory.  There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.environmentSettings] A
   * list of environment variable settings for the Job Preparation Task.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints]
   * Constraints that apply to the Job Preparation Task.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxWallClockTime]
   * The maximum elapsed time that the Task may run, measured from the time the
   * Task starts. If the Task does not complete within the time limit, the Batch
   * service terminates it. If this is not specified, there is no time limit on
   * how long the Task may run.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.retentionTime]
   * The minimum time to retain the Task directory on the Compute Node where it
   * ran, from the time it completes execution. After this time, the Batch
   * service may delete the Task directory and all its contents. The default is 7
   * days, i.e. the Task directory will be retained for 7 days unless the Compute
   * Node is removed or the Job is deleted.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.constraints.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries for the Task executable due to a
   * nonzero exit code. The Batch service will try the Task once, and may then
   * retry up to this limit. For example, if the maximum retry count is 3, Batch
   * tries the Task up to 4 times (one initial try and 3 retries). If the maximum
   * retry count is 0, the Batch service does not retry the Task after the first
   * attempt. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.waitForSuccess]
   * Whether the Batch service should wait for the Job Preparation Task to
   * complete successfully before scheduling any other Tasks of the Job on the
   * Compute Node. A Job Preparation Task has completed successfully if it exits
   * with exit code 0. If true and the Job Preparation Task fails on a Node, the
   * Batch service retries the Job Preparation Task up to its maximum retry count
   * (as specified in the constraints element). If the Task has still not
   * completed successfully after all retries, then the Batch service will not
   * schedule Tasks of the Job to the Node. The Node remains active and eligible
   * to run Tasks of other Jobs. If false, the Batch service will not wait for
   * the Job Preparation Task to complete. In this case, other Tasks of the Job
   * can start executing on the Compute Node while the Job Preparation Task is
   * still running; and even if the Job Preparation Task fails, new Tasks will
   * continue to be scheduled on the Compute Node. The default value is true.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.userIdentity] The user
   * identity under which the Job Preparation Task runs. If omitted, the Task
   * runs as a non-administrative user unique to the Task on Windows Compute
   * Nodes, or a non-administrative user unique to the Pool on Linux Compute
   * Nodes.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.jobPreparationTask.rerunOnNodeRebootAfterSuccess]
   * Whether the Batch service should rerun the Job Preparation Task after a
   * Compute Node reboots. The Job Preparation Task is always rerun if a Compute
   * Node is reimaged, or if the Job Preparation Task did not complete (e.g.
   * because the reboot occurred while the Task was running). Therefore, you
   * should always write a Job Preparation Task to be idempotent and to behave
   * correctly if run multiple times. The default value is true.
   *
   * @param {object} [cloudJobSchedule.jobSpecification.jobReleaseTask] The Job
   * Release Task for Jobs created under this schedule. The primary purpose of
   * the Job Release Task is to undo changes to Nodes made by the Job Preparation
   * Task. Example activities include deleting local files, or shutting down
   * services that were started as part of Job preparation. A Job Release Task
   * cannot be specified without also specifying a Job Preparation Task for the
   * Job. The Batch service runs the Job Release Task on the Compute Nodes that
   * have run the Job Preparation Task.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.jobReleaseTask.id] A
   * string that uniquely identifies the Job Release Task within the Job. The ID
   * can contain any combination of alphanumeric characters including hyphens and
   * underscores and cannot contain more than 64 characters. If you do not
   * specify this property, the Batch service assigns a default value of
   * 'jobrelease'. No other Task in the Job can have the same ID as the Job
   * Release Task. If you try to submit a Task with the same id, the Batch
   * service rejects the request with error code TaskIdSameAsJobReleaseTask; if
   * you are calling the REST API directly, the HTTP status code is 409
   * (Conflict).
   *
   * @param {string} cloudJobSchedule.jobSpecification.jobReleaseTask.commandLine
   * The command line of the Job Release Task. The command line does not run
   * under a shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.containerSettings] The
   * settings for the container under which the Job Release Task runs. When this
   * is specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR
   * (the root of Azure Batch directories on the node) are mapped into the
   * container, all Task environment variables are mapped into the container, and
   * the Task command line is executed in the container. Files produced in the
   * container outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the
   * host disk, meaning that Batch file APIs will not be able to access those
   * files.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.resourceFiles] A list of
   * files that the Batch service will download to the Compute Node before
   * running the command line.  There is a maximum size for the list of resource
   * files.  When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.environmentSettings] A
   * list of environment variable settings for the Job Release Task.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.maxWallClockTime] The
   * maximum elapsed time that the Job Release Task may run on a given Compute
   * Node, measured from the time the Task starts. If the Task does not complete
   * within the time limit, the Batch service terminates it. The default value is
   * 15 minutes. You may not specify a timeout longer than 15 minutes. If you do,
   * the Batch service rejects it with an error; if you are calling the REST API
   * directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.retentionTime] The minimum
   * time to retain the Task directory for the Job Release Task on the Compute
   * Node. After this time, the Batch service may delete the Task directory and
   * all its contents. The default is 7 days, i.e. the Task directory will be
   * retained for 7 days unless the Compute Node is removed or the Job is
   * deleted.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.jobReleaseTask.userIdentity] The user
   * identity under which the Job Release Task runs. If omitted, the Task runs as
   * a non-administrative user unique to the Task.
   *
   * @param {array} [cloudJobSchedule.jobSpecification.commonEnvironmentSettings]
   * A list of common environment variable settings. These environment variables
   * are set for all Tasks in Jobs created under this schedule (including the Job
   * Manager, Job Preparation and Job Release Tasks). Individual Tasks can
   * override an environment setting specified here by specifying the same
   * setting name with a different value.
   *
   * @param {object} cloudJobSchedule.jobSpecification.poolInfo The Pool on which
   * the Batch service runs the Tasks of Jobs created under this schedule.
   *
   * @param {string} [cloudJobSchedule.jobSpecification.poolInfo.poolId] The ID
   * of an existing Pool. All the Tasks of the Job will run on the specified
   * Pool. You must ensure that the Pool referenced by this property exists. If
   * the Pool does not exist at the time the Batch service tries to schedule a
   * Job, no Tasks for the Job will run until you create a Pool with that id.
   * Note that the Batch service will not reject the Job request; it will simply
   * not run Tasks until the Pool exists. You must specify either the Pool ID or
   * the auto Pool specification, but not both.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification]
   * Characteristics for a temporary 'auto pool'. The Batch service will create
   * this auto Pool when the Job is submitted. If auto Pool creation fails, the
   * Batch service moves the Job to a completed state, and the Pool creation
   * error is set in the Job's scheduling error property. The Batch service
   * manages the lifetime (both creation and, unless keepAlive is specified,
   * deletion) of the auto Pool. Any user actions that affect the lifetime of the
   * auto Pool while the Job is active will result in unexpected behavior. You
   * must specify either the Pool ID or the auto Pool specification, but not
   * both.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.autoPoolIdPrefix]
   * A prefix to be added to the unique identifier when a Pool is automatically
   * created. The Batch service assigns each auto Pool a unique identifier on
   * creation. To distinguish between Pools created for different purposes, you
   * can specify this element to add a prefix to the ID that is assigned. The
   * prefix can be up to 20 characters long.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.poolLifetimeOption
   * The minimum lifetime of created auto Pools, and how multiple Jobs on a
   * schedule are assigned to Pools. Possible values include: 'jobSchedule',
   * 'job'
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.keepAlive]
   * Whether to keep an auto Pool alive after its lifetime expires. If false, the
   * Batch service deletes the Pool once its lifetime (as determined by the
   * poolLifetimeOption setting) expires; that is, when the Job or Job Schedule
   * completes. If true, the Batch service does not delete the Pool
   * automatically. It is up to the user to delete auto Pools created with this
   * option.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool] The
   * Pool specification for the auto Pool.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.displayName]
   * The display name for the Pool. The display name need not be unique and can
   * contain any Unicode characters up to a maximum length of 1024.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.vmSize
   * The size of the virtual machines in the Pool. All virtual machines in a Pool
   * are the same size. For information about available sizes of virtual machines
   * in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
   * (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration]
   * The cloud service configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure PaaS VMs. This property
   * and virtualMachineConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request). This property cannot be specified if the Batch
   * Account was created with its poolAllocationMode property set to
   * 'UserSubscription'.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osFamily
   * The Azure Guest OS family to be installed on the virtual machines in the
   * Pool. Possible values are:
   * 2 - OS Family 2, equivalent to Windows Server 2008 R2 SP1.
   * 3 - OS Family 3, equivalent to Windows Server 2012.
   * 4 - OS Family 4, equivalent to Windows Server 2012 R2.
   * 5 - OS Family 5, equivalent to Windows Server 2016.
   * 6 - OS Family 6, equivalent to Windows Server 2019. For more information,
   * see Azure Guest OS Releases
   * (https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.cloudServiceConfiguration.osVersion]
   * The Azure Guest OS version to be installed on the virtual machines in the
   * Pool. The default value is * which specifies the latest operating system
   * version for the specified OS family.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration]
   * The virtual machine configuration for the Pool. This property must be
   * specified if the Pool needs to be created with Azure IaaS VMs. This property
   * and cloudServiceConfiguration are mutually exclusive and one of the
   * properties must be specified. If neither is specified then the Batch service
   * returns an error; if you are calling the REST API directly, the HTTP status
   * code is 400 (Bad Request).
   *
   * @param {object}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference
   * A reference to the Azure Virtual Machines Marketplace Image or the custom
   * Virtual Machine Image to use.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.publisher]
   * The publisher of the Azure Virtual Machines Marketplace Image. For example,
   * Canonical or MicrosoftWindowsServer.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.offer]
   * The offer type of the Azure Virtual Machines Marketplace Image. For example,
   * UbuntuServer or WindowsServer.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.sku]
   * The SKU of the Azure Virtual Machines Marketplace Image. For example,
   * 18.04-LTS or 2019-Datacenter.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.version]
   * The version of the Azure Virtual Machines Marketplace Image. A value of
   * 'latest' can be specified to select the latest version of an Image. If
   * omitted, the default is 'latest'.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.imageReference.virtualMachineImageId]
   * The ARM resource identifier of the Shared Image Gallery Image. Compute Nodes
   * in the Pool will be created using this Image Id. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}/versions/{VersionId}
   * or
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/galleries/{galleryName}/images/{imageDefinitionName}
   * for always defaulting to the latest image version. This property is mutually
   * exclusive with other ImageReference properties. The Shared Image Gallery
   * Image must have replicas in the same region and must be in the same
   * subscription as the Azure Batch account. If the image version is not
   * specified in the imageId, the latest version will be used. For information
   * about the firewall settings for the Batch Compute Node agent to communicate
   * with the Batch service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.nodeAgentSKUId
   * The SKU of the Batch Compute Node agent to be provisioned on Compute Nodes
   * in the Pool. The Batch Compute Node agent is a program that runs on each
   * Compute Node in the Pool, and provides the command-and-control interface
   * between the Compute Node and the Batch service. There are different
   * implementations of the Compute Node agent, known as SKUs, for different
   * operating systems. You must specify a Compute Node agent SKU which matches
   * the selected Image reference. To get the list of supported Compute Node
   * agent SKUs along with their list of verified Image references, see the 'List
   * supported Compute Node agent SKUs' operation.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration]
   * Windows operating system settings on the virtual machine. This property must
   * not be specified if the imageReference property specifies a Linux OS Image.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.windowsConfiguration.enableAutomaticUpdates]
   * Whether automatic updates are enabled on the virtual machine. If omitted,
   * the default value is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.dataDisks]
   * The configuration for data disks attached to the Compute Nodes in the Pool.
   * This property must be specified if the Compute Nodes in the Pool need to
   * have empty data disks attached to them. This cannot be updated. Each Compute
   * Node gets its own disk (the disk is not a file share). Existing disks cannot
   * be attached, each attached disk is empty. When the Compute Node is removed
   * from the Pool, the disk and all data associated with it is also deleted. The
   * disk is not formatted after being attached, it must be formatted before use
   * - for more information see
   * https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
   * and
   * https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.licenseType]
   * The type of on-premises license to be used when deploying the operating
   * system. This only applies to Images that contain the Windows operating
   * system, and should only be used when you hold valid on-premises licenses for
   * the Compute Nodes which will be deployed. If omitted, no on-premises
   * licensing discount is applied. Values are:
   *
   * Windows_Server - The on-premises license is for Windows Server.
   * Windows_Client - The on-premises license is for Windows Client.
   *
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration]
   * The container configuration for the Pool. If specified, setup is performed
   * on each Compute Node in the Pool to allow Tasks to run in containers. All
   * regular Tasks and Job manager Tasks run on this Pool must specify the
   * containerSettings property, and all other Tasks may specify it.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerImageNames]
   * The collection of container Image names. This is the full Image reference,
   * as would be specified to "docker pull". An Image will be sourced from the
   * default Docker registry unless the Image is fully qualified with an
   * alternative registry.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.containerConfiguration.containerRegistries]
   * Additional private registries from which containers can be pulled. If any
   * Images must be downloaded from a private registry which requires
   * credentials, then those credentials must be provided here.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration]
   * The disk encryption configuration for the pool. If specified, encryption is
   * performed on each node in the pool during node provisioning.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.virtualMachineConfiguration.diskEncryptionConfiguration.targets]
   * The list of disk targets Batch Service will encrypt on the compute node. If
   * omitted, no disks on the compute nodes in the pool will be encrypted. On
   * Linux pool, only "TemporaryDisk" is supported; on Windows pool, "OsDisk" and
   * "TemporaryDisk" must be specified.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSlotsPerNode]
   * The number of task slots that can be used to run concurrent tasks on a
   * single compute node in the pool. The default value is 1. The maximum value
   * is the smaller of 4 times the number of cores of the vmSize of the pool or
   * 256.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy]
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.taskSchedulingPolicy.nodeFillType
   * How Tasks are distributed across Compute Nodes in a Pool. If not specified,
   * the default is spread. Possible values include: 'spread', 'pack'
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.resizeTimeout]
   * The timeout for allocation of Compute Nodes to the Pool. This timeout
   * applies only to manual scaling; it has no effect when enableAutoScale is set
   * to true. The default value is 15 minutes. The minimum value is 5 minutes. If
   * you specify a value less than 5 minutes, the Batch service rejects the
   * request with an error; if you are calling the REST API directly, the HTTP
   * status code is 400 (Bad Request).
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetDedicatedNodes]
   * The desired number of dedicated Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.targetLowPriorityNodes]
   * The desired number of low-priority Compute Nodes in the Pool. This property
   * must not be specified if enableAutoScale is set to true. If enableAutoScale
   * is set to false, then you must set either targetDedicatedNodes,
   * targetLowPriorityNodes, or both.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableAutoScale]
   * Whether the Pool size should automatically adjust over time. If false, at
   * least one of targetDedicateNodes and targetLowPriorityNodes must be
   * specified. If true, the autoScaleFormula element is required. The Pool
   * automatically resizes according to the formula. The default value is false.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleFormula]
   * The formula for the desired number of Compute Nodes in the Pool. This
   * property must not be specified if enableAutoScale is set to false. It is
   * required if enableAutoScale is set to true. The formula is checked for
   * validity before the Pool is created. If the formula is not valid, the Batch
   * service rejects the request with detailed error information.
   *
   * @param {moment.duration}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.autoScaleEvaluationInterval]
   * The time interval at which to automatically adjust the Pool size according
   * to the autoscale formula. The default value is 15 minutes. The minimum and
   * maximum value are 5 minutes and 168 hours respectively. If you specify a
   * value less than 5 minutes or greater than 168 hours, the Batch service
   * rejects the request with an invalid property value error; if you are calling
   * the REST API directly, the HTTP status code is 400 (Bad Request).
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.enableInterNodeCommunication]
   * Whether the Pool permits direct communication between Compute Nodes.
   * Enabling inter-node communication limits the maximum size of the Pool due to
   * deployment restrictions on the Compute Nodes of the Pool. This may result in
   * the Pool not reaching its desired size. The default value is false.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration]
   * The network configuration for the Pool.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.subnetId]
   * The ARM resource identifier of the virtual network subnet which the Compute
   * Nodes of the Pool will join. This is of the form
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/{provider}/virtualNetworks/{network}/subnets/{subnet}.
   * The virtual network must be in the same region and subscription as the Azure
   * Batch Account. The specified subnet should have enough free IP addresses to
   * accommodate the number of Compute Nodes in the Pool. If the subnet doesn't
   * have enough free IP addresses, the Pool will partially allocate Nodes and a
   * resize error will occur. The 'MicrosoftAzureBatch' service principal must
   * have the 'Classic Virtual Machine Contributor' Role-Based Access Control
   * (RBAC) role for the specified VNet. The specified subnet must allow
   * communication from the Azure Batch service to be able to schedule Tasks on
   * the Nodes. This can be verified by checking if the specified VNet has any
   * associated Network Security Groups (NSG). If communication to the Nodes in
   * the specified subnet is denied by an NSG, then the Batch service will set
   * the state of the Compute Nodes to unusable. For Pools created with
   * virtualMachineConfiguration only ARM virtual networks
   * ('Microsoft.Network/virtualNetworks') are supported, but for Pools created
   * with cloudServiceConfiguration both ARM and classic virtual networks are
   * supported. If the specified VNet has any associated Network Security Groups
   * (NSG), then a few reserved system ports must be enabled for inbound
   * communication. For Pools created with a virtual machine configuration,
   * enable ports 29876 and 29877, as well as port 22 for Linux and port 3389 for
   * Windows. For Pools created with a cloud service configuration, enable ports
   * 10100, 20100, and 30100. Also enable outbound connections to Azure Storage
   * on port 443. For more details see:
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.dynamicVNetAssignmentScope]
   * The scope of dynamic vnet assignment. Possible values include: 'none', 'job'
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration]
   * The configuration for endpoints on Compute Nodes in the Batch Pool. Pool
   * endpoint configuration is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {array}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.endpointConfiguration.inboundNATPools
   * A list of inbound NAT Pools that can be used to address specific ports on an
   * individual Compute Node externally. The maximum number of inbound NAT Pools
   * per Batch Pool is 5. If the maximum number of inbound NAT Pools is exceeded
   * the request fails with HTTP status code 400. This cannot be specified if the
   * IPAddressProvisioningType is NoPublicIPAddresses.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration]
   * The Public IPAddress configuration for Compute Nodes in the Batch Pool.
   * Public IP configuration property is only supported on Pools with the
   * virtualMachineConfiguration property.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.provision]
   * The provisioning type for Public IP Addresses for the Pool. The default
   * value is BatchManaged. Possible values include: 'batchManaged',
   * 'userManaged', 'noPublicIPAddresses'
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.networkConfiguration.publicIPAddressConfiguration.ipAddressIds]
   * The list of public IPs which the Batch service will use when provisioning
   * Compute Nodes. The number of IPs specified here limits the maximum size of
   * the Pool - 100 dedicated nodes or 100 low-priority nodes can be allocated
   * for each public IP. For example, a pool needing 250 dedicated VMs would need
   * at least 3 public IPs specified. Each element of this collection is of the
   * form:
   * /subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask]
   * A Task to run on each Compute Node as it joins the Pool. The Task runs when
   * the Compute Node is added to the Pool or when the Compute Node is restarted.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.commandLine
   * The command line of the StartTask. The command line does not run under a
   * shell, and therefore cannot take advantage of shell features such as
   * environment variable expansion. If you want to take advantage of such
   * features, you should invoke the shell in the command line, for example using
   * "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
   * command line refers to file paths, it should use a relative path (relative
   * to the Task working directory), or use the Batch provided environment
   * variable
   * (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings]
   * The settings for the container under which the StartTask runs. When this is
   * specified, all directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the
   * root of Azure Batch directories on the node) are mapped into the container,
   * all Task environment variables are mapped into the container, and the Task
   * command line is executed in the container. Files produced in the container
   * outside of AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk,
   * meaning that Batch file APIs will not be able to access those files.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.containerRunOptions]
   * Additional options to the container create command. These additional options
   * are supplied as arguments to the "docker create" command, in addition to
   * those controlled by the Batch Service.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.imageName
   * The Image to use to create the container in which the Task will run. This is
   * the full Image reference, as would be specified to "docker pull". If no tag
   * is provided as part of the Image name, the tag ":latest" is used as a
   * default.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry]
   * The private registry which contains the container Image. This setting can be
   * omitted if was already provided at Pool creation.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.registryServer]
   * The registry URL. If omitted, the default is "docker.io".
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.userName
   * The user name to log into the registry server.
   *
   * @param {string}
   * cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.registry.password
   * The password to log into the registry server.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.containerSettings.workingDirectory]
   * The location of the container Task working directory. The default is
   * 'taskWorkingDirectory'. Possible values include: 'taskWorkingDirectory',
   * 'containerImageDefault'
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.resourceFiles]
   * A list of files that the Batch service will download to the Compute Node
   * before running the command line.  There is a maximum size for the list of
   * resource files. When the max size is exceeded, the request will fail and the
   * response error code will be RequestEntityTooLarge. If this occurs, the
   * collection of ResourceFiles must be reduced in size. This can be achieved
   * using .zip files, Application Packages, or Docker Containers. Files listed
   * under this element are located in the Task's working directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.environmentSettings]
   * A list of environment variable settings for the StartTask.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity]
   * The user identity under which the StartTask runs. If omitted, the Task runs
   * as a non-administrative user unique to the Task.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.userName]
   * The name of the user identity under which the Task is run. The userName and
   * autoUser properties are mutually exclusive; you must specify one but not
   * both.
   *
   * @param {object}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser]
   * The auto user under which the Task is run. The userName and autoUser
   * properties are mutually exclusive; you must specify one but not both.
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.scope]
   * The scope for the auto user The default value is pool. If the pool is
   * running Windows a value of Task should be specified if stricter isolation
   * between tasks is required. For example, if the task mutates the registry in
   * a way which could impact other tasks, or if certificates have been specified
   * on the pool which should not be accessible by normal tasks but should be
   * accessible by StartTasks. Possible values include: 'task', 'pool'
   *
   * @param {string}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.userIdentity.autoUser.elevationLevel]
   * The elevation level of the auto user. The default value is nonAdmin.
   * Possible values include: 'nonAdmin', 'admin'
   *
   * @param {number}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.maxTaskRetryCount]
   * The maximum number of times the Task may be retried. The Batch service
   * retries a Task if its exit code is nonzero. Note that this value
   * specifically controls the number of retries. The Batch service will try the
   * Task once, and may then retry up to this limit. For example, if the maximum
   * retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
   * retries). If the maximum retry count is 0, the Batch service does not retry
   * the Task. If the maximum retry count is -1, the Batch service retries the
   * Task without limit.
   *
   * @param {boolean}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.startTask.waitForSuccess]
   * Whether the Batch service should wait for the StartTask to complete
   * successfully (that is, to exit with exit code 0) before scheduling any Tasks
   * on the Compute Node. If true and the StartTask fails on a Node, the Batch
   * service retries the StartTask up to its maximum retry count
   * (maxTaskRetryCount). If the Task has still not completed successfully after
   * all retries, then the Batch service marks the Node unusable, and will not
   * schedule Tasks to it. This condition can be detected via the Compute Node
   * state and failure info details. If false, the Batch service will not wait
   * for the StartTask to complete. In this case, other Tasks can start executing
   * on the Compute Node while the StartTask is still running; and even if the
   * StartTask fails, new Tasks will continue to be scheduled on the Compute
   * Node. The default is true.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.certificateReferences]
   * A list of Certificates to be installed on each Compute Node in the Pool. For
   * Windows Nodes, the Batch service installs the Certificates to the specified
   * Certificate store and location. For Linux Compute Nodes, the Certificates
   * are stored in a directory inside the Task working directory and an
   * environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to
   * query for this location. For Certificates with visibility of 'remoteUser', a
   * 'certs' directory is created in the user's home directory (e.g.,
   * /home/{user-name}/certs) and Certificates are placed in that directory.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationPackageReferences]
   * The list of Packages to be installed on each Compute Node in the Pool.
   * Changes to Package references affect all new Nodes joining the Pool, but do
   * not affect Compute Nodes that are already in the Pool until they are
   * rebooted or reimaged. There is a maximum of 10 Package references on any
   * given Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.applicationLicenses]
   * The list of application licenses the Batch service will make available on
   * each Compute Node in the Pool. The list of application licenses must be a
   * subset of available Batch service application licenses. If a license is
   * requested which is not supported, Pool creation will fail. The permitted
   * licenses available on the Pool are 'maya', 'vray', '3dsmax', 'arnold'. An
   * additional charge applies for each application license added to the Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.userAccounts]
   * The list of user Accounts to be created on each Compute Node in the Pool.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.metadata]
   * A list of name-value pairs associated with the Pool as metadata. The Batch
   * service does not assign any meaning to metadata; it is solely for the use of
   * user code.
   *
   * @param {array}
   * [cloudJobSchedule.jobSpecification.poolInfo.autoPoolSpecification.pool.mountConfiguration]
   * A list of file systems to mount on each node in the pool. This supports
   * Azure Files, NFS, CIFS/SMB, and Blobfuse.
   *
   * @param {array} [cloudJobSchedule.jobSpecification.metadata] A list of
   * name-value pairs associated with each Job created under this schedule as
   * metadata. The Batch service does not assign any meaning to metadata; it is
   * solely for the use of user code.
   *
   * @param {array} [cloudJobSchedule.metadata] A list of name-value pairs
   * associated with the schedule as metadata. The Batch service does not assign
   * any meaning to metadata; it is solely for the use of user code.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleAddOptions] Additional parameters for
   * the operation
   *
   * @param {number} [options.jobScheduleAddOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleAddOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleAddOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleAddOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {null} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {null} [result]   - The deserialized result object if an error did not occur.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  add(cloudJobSchedule, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._add(cloudJobSchedule, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._add(cloudJobSchedule, options, optionalCallback);
    }
  }

  /**
   * @summary Lists all of the Job Schedules in the specified Account.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleListOptions] Additional parameters for
   * the operation
   *
   * @param {string} [options.jobScheduleListOptions.filter] An OData $filter
   * clause. For more information on constructing this filter, see
   * https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-job-schedules.
   *
   * @param {string} [options.jobScheduleListOptions.select] An OData $select
   * clause.
   *
   * @param {string} [options.jobScheduleListOptions.expand] An OData $expand
   * clause.
   *
   * @param {number} [options.jobScheduleListOptions.maxResults] The maximum
   * number of items to return in the response. A maximum of 1000 Job Schedules
   * can be returned.
   *
   * @param {number} [options.jobScheduleListOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleListOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleListOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleListOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<CloudJobScheduleListResult>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  listWithHttpOperationResponse(options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._list(options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Lists all of the Job Schedules in the specified Account.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleListOptions] Additional parameters for
   * the operation
   *
   * @param {string} [options.jobScheduleListOptions.filter] An OData $filter
   * clause. For more information on constructing this filter, see
   * https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-job-schedules.
   *
   * @param {string} [options.jobScheduleListOptions.select] An OData $select
   * clause.
   *
   * @param {string} [options.jobScheduleListOptions.expand] An OData $expand
   * clause.
   *
   * @param {number} [options.jobScheduleListOptions.maxResults] The maximum
   * number of items to return in the response. A maximum of 1000 Job Schedules
   * can be returned.
   *
   * @param {number} [options.jobScheduleListOptions.timeout] The maximum time
   * that the server can spend processing the request, in seconds. The default is
   * 30 seconds.
   *
   * @param {uuid} [options.jobScheduleListOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleListOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleListOptions.ocpDate] The time the request
   * was issued. Client libraries typically set this to the current system clock
   * time; set it explicitly if you are calling the REST API directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {CloudJobScheduleListResult} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {object} [result]   - The deserialized result object if an error did not occur.
   *                      See {@link CloudJobScheduleListResult} for more
   *                      information.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  list(options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._list(options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._list(options, optionalCallback);
    }
  }

  /**
   * @summary Lists all of the Job Schedules in the specified Account.
   *
   * @param {string} nextPageLink The NextLink from the previous successful call
   * to List operation.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleListNextOptions] Additional parameters
   * for the operation
   *
   * @param {uuid} [options.jobScheduleListNextOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleListNextOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleListNextOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @returns {Promise} A promise is returned
   *
   * @resolve {HttpOperationResponse<CloudJobScheduleListResult>} - The deserialized result object.
   *
   * @reject {Error} - The error object.
   */
  listNextWithHttpOperationResponse(nextPageLink, options) {
    let client = this.client;
    let self = this;
    return new Promise((resolve, reject) => {
      self._listNext(nextPageLink, options, (err, result, request, response) => {
        let httpOperationResponse = new msRest.HttpOperationResponse(request, response);
        httpOperationResponse.body = result;
        if (err) { reject(err); }
        else { resolve(httpOperationResponse); }
        return;
      });
    });
  }

  /**
   * @summary Lists all of the Job Schedules in the specified Account.
   *
   * @param {string} nextPageLink The NextLink from the previous successful call
   * to List operation.
   *
   * @param {object} [options] Optional Parameters.
   *
   * @param {object} [options.jobScheduleListNextOptions] Additional parameters
   * for the operation
   *
   * @param {uuid} [options.jobScheduleListNextOptions.clientRequestId] The
   * caller-generated request identity, in the form of a GUID with no decoration
   * such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0.
   *
   * @param {boolean} [options.jobScheduleListNextOptions.returnClientRequestId]
   * Whether the server should return the client-request-id in the response.
   *
   * @param {date} [options.jobScheduleListNextOptions.ocpDate] The time the
   * request was issued. Client libraries typically set this to the current
   * system clock time; set it explicitly if you are calling the REST API
   * directly.
   *
   * @param {object} [options.customHeaders] Headers that will be added to the
   * request
   *
   * @param {function} [optionalCallback] - The optional callback.
   *
   * @returns {function|Promise} If a callback was passed as the last parameter
   * then it returns the callback else returns a Promise.
   *
   * {Promise} A promise is returned
   *
   *                      @resolve {CloudJobScheduleListResult} - The deserialized result object.
   *
   *                      @reject {Error} - The error object.
   *
   * {function} optionalCallback(err, result, request, response)
   *
   *                      {Error}  err        - The Error object if an error occurred, null otherwise.
   *
   *                      {object} [result]   - The deserialized result object if an error did not occur.
   *                      See {@link CloudJobScheduleListResult} for more
   *                      information.
   *
   *                      {object} [request]  - The HTTP Request object if an error did not occur.
   *
   *                      {stream} [response] - The HTTP Response stream if an error did not occur.
   */
  listNext(nextPageLink, options, optionalCallback) {
    let client = this.client;
    let self = this;
    if (!optionalCallback && typeof options === 'function') {
      optionalCallback = options;
      options = null;
    }
    if (!optionalCallback) {
      return new Promise((resolve, reject) => {
        self._listNext(nextPageLink, options, (err, result, request, response) => {
          if (err) { reject(err); }
          else { resolve(result); }
          return;
        });
      });
    } else {
      return self._listNext(nextPageLink, options, optionalCallback);
    }
  }

}

module.exports = JobSchedule;
