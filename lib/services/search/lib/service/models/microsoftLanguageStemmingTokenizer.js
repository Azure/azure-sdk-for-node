/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

const models = require('./index');

/**
 * Divides text using language-specific rules and reduces words to their base
 * forms.
 *
 * @extends models['Tokenizer']
 */
class MicrosoftLanguageStemmingTokenizer extends models['Tokenizer'] {
  /**
   * Create a MicrosoftLanguageStemmingTokenizer.
   * @member {number} [maxTokenLength] The maximum token length. Tokens longer
   * than the maximum length are split. Maximum token length that can be used
   * is 300 characters. Tokens longer than 300 characters are first split into
   * tokens of length 300 and then each of those tokens is split based on the
   * max token length set. Default is 255. Default value: 255 .
   * @member {boolean} [isSearchTokenizer] A value indicating how the tokenizer
   * is used. Set to true if used as the search tokenizer, set to false if used
   * as the indexing tokenizer. Default is false. Default value: false .
   * @member {string} [language] The language to use. The default is English.
   * Possible values include: 'arabic', 'bangla', 'bulgarian', 'catalan',
   * 'croatian', 'czech', 'danish', 'dutch', 'english', 'estonian', 'finnish',
   * 'french', 'german', 'greek', 'gujarati', 'hebrew', 'hindi', 'hungarian',
   * 'icelandic', 'indonesian', 'italian', 'kannada', 'latvian', 'lithuanian',
   * 'malay', 'malayalam', 'marathi', 'norwegianBokmaal', 'polish',
   * 'portuguese', 'portugueseBrazilian', 'punjabi', 'romanian', 'russian',
   * 'serbianCyrillic', 'serbianLatin', 'slovak', 'slovenian', 'spanish',
   * 'swedish', 'tamil', 'telugu', 'turkish', 'ukrainian', 'urdu'
   */
  constructor() {
    super();
  }

  /**
   * Defines the metadata of MicrosoftLanguageStemmingTokenizer
   *
   * @returns {object} metadata of MicrosoftLanguageStemmingTokenizer
   *
   */
  mapper() {
    return {
      required: false,
      serializedName: '#Microsoft.Azure.Search.MicrosoftLanguageStemmingTokenizer',
      type: {
        name: 'Composite',
        className: 'MicrosoftLanguageStemmingTokenizer',
        modelProperties: {
          name: {
            required: true,
            serializedName: 'name',
            type: {
              name: 'String'
            }
          },
          odatatype: {
            required: true,
            serializedName: '@odata\\.type',
            type: {
              name: 'String'
            }
          },
          maxTokenLength: {
            required: false,
            serializedName: 'maxTokenLength',
            defaultValue: 255,
            constraints: {
              InclusiveMaximum: 300
            },
            type: {
              name: 'Number'
            }
          },
          isSearchTokenizer: {
            required: false,
            serializedName: 'isSearchTokenizer',
            defaultValue: false,
            type: {
              name: 'Boolean'
            }
          },
          language: {
            required: false,
            serializedName: 'language',
            type: {
              name: 'Enum',
              allowedValues: [ 'arabic', 'bangla', 'bulgarian', 'catalan', 'croatian', 'czech', 'danish', 'dutch', 'english', 'estonian', 'finnish', 'french', 'german', 'greek', 'gujarati', 'hebrew', 'hindi', 'hungarian', 'icelandic', 'indonesian', 'italian', 'kannada', 'latvian', 'lithuanian', 'malay', 'malayalam', 'marathi', 'norwegianBokmaal', 'polish', 'portuguese', 'portugueseBrazilian', 'punjabi', 'romanian', 'russian', 'serbianCyrillic', 'serbianLatin', 'slovak', 'slovenian', 'spanish', 'swedish', 'tamil', 'telugu', 'turkish', 'ukrainian', 'urdu' ]
            }
          }
        }
      }
    };
  }
}

module.exports = MicrosoftLanguageStemmingTokenizer;
